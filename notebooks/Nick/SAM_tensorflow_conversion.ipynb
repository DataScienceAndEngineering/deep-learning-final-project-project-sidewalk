{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOdO02a7L2cs+hARRd/Ou8a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DataScienceAndEngineering/deep-learning-final-project-project-sidewalk/blob/main/notebooks/Nick/SAM_tensorflow_conversion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0cXvVrrlHfL",
        "outputId": "c3d6add3-1d35-43fd-82c0-02657a5fc257"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/facebookresearch/segment-anything.git\n",
            "  Cloning https://github.com/facebookresearch/segment-anything.git to /tmp/pip-req-build-2ed4d3nj\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/segment-anything.git /tmp/pip-req-build-2ed4d3nj\n",
            "  Resolved https://github.com/facebookresearch/segment-anything.git to commit 567662b0fd33ca4b022d94d3b8de896628cd32dd\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: segment-anything\n",
            "  Building wheel for segment-anything (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segment-anything: filename=segment_anything-1.0-py3-none-any.whl size=36610 sha256=8275e4da7b72d2ae0ba881a643dbec970caf82cb881dd9e5e3b751ebd2cc5454\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0be0r7mx/wheels/10/cf/59/9ccb2f0a1bcc81d4fbd0e501680b5d088d690c6cfbc02dc99d\n",
            "Successfully built segment-anything\n",
            "Installing collected packages: segment-anything\n",
            "Successfully installed segment-anything-1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.7.0.72)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (2.0.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.14.1-cp310-cp310-manylinux_2_27_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnx\n",
            "  Downloading onnx-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.22.4)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (8.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.39.3)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.3.3)\n",
            "Collecting coloredlogs\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.11.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx) (4.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Collecting humanfriendly>=9.1\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Installing collected packages: onnx, humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnx-1.13.1 onnxruntime-1.14.1\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/facebookresearch/segment-anything.git\n",
        "!pip install opencv-python pycocotools matplotlib onnxruntime onnx"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from segment_anything import SamPredictor, sam_model_registry\n",
        "import os\n",
        "if not os.path.isfile('/content/sam_vit_h_4b8939.pth'):\n",
        "  !wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n",
        "\n",
        "sam = sam_model_registry[\"vit_h\"](checkpoint='/content/sam_vit_h_4b8939.pth')\n"
      ],
      "metadata": {
        "id": "pNfvTcbHlraz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "dummy_input = np.zeros((1024, 2048, 3))\n",
        "plt.imshow(dummy_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "ZmJtCIU2o_sl",
        "outputId": "33b1d59b-988a-4709-9271-7f564e6c4c72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f56606479d0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "dummy_input = torch.randn(1, 1024, 2048, 3)\n",
        "torch.onnx.export(sam, dummy_input, 'sam.onnx', verbose=False, opset_version=17, input_names='input', output_names='output', export_params=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "QXPgRTWEnBfH",
        "outputId": "45380367-85d0-4748-e02a-15c77de5a134"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============= Diagnostic Run torch.onnx.export version 2.0.0+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-66f7bcd4543a>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdummy_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2048\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sam.onnx'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopset_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'output'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexport_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions)\u001b[0m\n\u001b[1;32m    504\u001b[0m     \"\"\"\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m     _export(\n\u001b[0m\u001b[1;32m    507\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions)\u001b[0m\n\u001b[1;32m   1546\u001b[0m             \u001b[0m_validate_dynamic_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdynamic_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1548\u001b[0;31m             graph, params_dict, torch_out = _model_to_graph(\n\u001b[0m\u001b[1;32m   1549\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, verbose, input_names, output_names, operator_export_type, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[1;32m   1111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pre_trace_quant_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m     \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_jit_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1114\u001b[0m     \u001b[0mparams_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_named_param_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_create_jit_graph\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m     \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_trace_and_get_graph_from_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m     \u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_pass_onnx_lint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m     \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unique_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_trace_and_get_graph_from_model\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m    891\u001b[0m     \u001b[0mprev_autocast_cache_enabled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_autocast_cache_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_autocast_cache_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m     trace_graph, torch_out, inputs_states = torch.jit._get_trace_graph(\n\u001b[0m\u001b[1;32m    894\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36m_get_trace_graph\u001b[0;34m(f, args, kwargs, strict, _force_outplace, return_inputs, _return_inputs_states)\u001b[0m\n\u001b[1;32m   1266\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1268\u001b[0;31m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mONNXTracedModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_force_outplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_return_inputs_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         graph, out = torch._C._create_graph_by_tracing(\n\u001b[0m\u001b[1;32m    128\u001b[0m             \u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0min_vars\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_return_inputs_states\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0minputs_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mouts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrace_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_return_inputs_states\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0minputs_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1486\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1487\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1488\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1489\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1490\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Sam.forward() missing 1 required positional argument: 'multimask_output'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright (c) Meta Platforms, Inc. and affiliates.\n",
        "# All rights reserved.\n",
        "\n",
        "# This source code is licensed under the license found in the\n",
        "# LICENSE file in the root directory of this source tree.\n",
        "\n",
        "import torch\n",
        "\n",
        "from segment_anything import sam_model_registry\n",
        "from segment_anything.utils.onnx import SamOnnxModel\n",
        "\n",
        "import argparse\n",
        "import warnings\n",
        "\n",
        "try:\n",
        "    import onnxruntime  # type: ignore\n",
        "\n",
        "    onnxruntime_exists = True\n",
        "except ImportError:\n",
        "    onnxruntime_exists = False\n",
        "\n",
        "parser = argparse.ArgumentParser(\n",
        "    description=\"Export the SAM prompt encoder and mask decoder to an ONNX model.\"\n",
        ")\n",
        "\n",
        "parser.add_argument(\n",
        "    \"--checkpoint\", type=str, required=True, help=\"The path to the SAM model checkpoint.\"\n",
        ")\n",
        "\n",
        "parser.add_argument(\n",
        "    \"--output\", type=str, required=True, help=\"The filename to save the ONNX model to.\"\n",
        ")\n",
        "\n",
        "parser.add_argument(\n",
        "    \"--model-type\",\n",
        "    type=str,\n",
        "    required=True,\n",
        "    help=\"In ['default', 'vit_h', 'vit_l', 'vit_b']. Which type of SAM model to export.\",\n",
        ")\n",
        "\n",
        "parser.add_argument(\n",
        "    \"--return-single-mask\",\n",
        "    action=\"store_true\",\n",
        "    help=(\n",
        "        \"If true, the exported ONNX model will only return the best mask, \"\n",
        "        \"instead of returning multiple masks. For high resolution images \"\n",
        "        \"this can improve runtime when upscaling masks is expensive.\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "parser.add_argument(\n",
        "    \"--opset\",\n",
        "    type=int,\n",
        "    default=17,\n",
        "    help=\"The ONNX opset version to use. Must be >=11\",\n",
        ")\n",
        "\n",
        "parser.add_argument(\n",
        "    \"--quantize-out\",\n",
        "    type=str,\n",
        "    default=None,\n",
        "    help=(\n",
        "        \"If set, will quantize the model and save it with this name. \"\n",
        "        \"Quantization is performed with quantize_dynamic from onnxruntime.quantization.quantize.\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "parser.add_argument(\n",
        "    \"--gelu-approximate\",\n",
        "    action=\"store_true\",\n",
        "    help=(\n",
        "        \"Replace GELU operations with approximations using tanh. Useful \"\n",
        "        \"for some runtimes that have slow or unimplemented erf ops, used in GELU.\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "parser.add_argument(\n",
        "    \"--use-stability-score\",\n",
        "    action=\"store_true\",\n",
        "    help=(\n",
        "        \"Replaces the model's predicted mask quality score with the stability \"\n",
        "        \"score calculated on the low resolution masks using an offset of 1.0. \"\n",
        "    ),\n",
        ")\n",
        "\n",
        "parser.add_argument(\n",
        "    \"--return-extra-metrics\",\n",
        "    action=\"store_true\",\n",
        "    help=(\n",
        "        \"The model will return five results: (masks, scores, stability_scores, \"\n",
        "        \"areas, low_res_logits) instead of the usual three. This can be \"\n",
        "        \"significantly slower for high resolution outputs.\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "\n",
        "def run_export(\n",
        "    model_type: str,\n",
        "    checkpoint: str,\n",
        "    output: str,\n",
        "    opset: int,\n",
        "    return_single_mask: bool,\n",
        "    gelu_approximate: bool = False,\n",
        "    use_stability_score: bool = False,\n",
        "    return_extra_metrics=False,\n",
        "):\n",
        "    print(\"Loading model...\")\n",
        "    sam = sam_model_registry[model_type](checkpoint=checkpoint)\n",
        "\n",
        "    onnx_model = SamOnnxModel(\n",
        "        model=sam,\n",
        "        return_single_mask=return_single_mask,\n",
        "        use_stability_score=use_stability_score,\n",
        "        return_extra_metrics=return_extra_metrics,\n",
        "    )\n",
        "\n",
        "    if gelu_approximate:\n",
        "        for n, m in onnx_model.named_modules():\n",
        "            if isinstance(m, torch.nn.GELU):\n",
        "                m.approximate = \"tanh\"\n",
        "\n",
        "    dynamic_axes = {\n",
        "        \"point_coords\": {1: \"num_points\"},\n",
        "        \"point_labels\": {1: \"num_points\"},\n",
        "    }\n",
        "\n",
        "    embed_dim = sam.prompt_encoder.embed_dim\n",
        "    embed_size = sam.prompt_encoder.image_embedding_size\n",
        "    mask_input_size = [4 * x for x in embed_size]\n",
        "    dummy_inputs = {\n",
        "        \"image_embeddings\": torch.randn(1, embed_dim, *embed_size, dtype=torch.float),\n",
        "        \"point_coords\": torch.randint(low=0, high=1024, size=(1, 5, 2), dtype=torch.float),\n",
        "        \"point_labels\": torch.randint(low=0, high=4, size=(1, 5), dtype=torch.float),\n",
        "        \"mask_input\": torch.randn(1, 1, *mask_input_size, dtype=torch.float),\n",
        "        \"has_mask_input\": torch.tensor([1], dtype=torch.float),\n",
        "        \"orig_im_size\": torch.tensor([1500, 2250], dtype=torch.float),\n",
        "    }\n",
        "\n",
        "    _ = onnx_model(**dummy_inputs)\n",
        "\n",
        "    output_names = [\"masks\", \"iou_predictions\", \"low_res_masks\"]\n",
        "\n",
        "    with warnings.catch_warnings():\n",
        "        warnings.filterwarnings(\"ignore\", category=torch.jit.TracerWarning)\n",
        "        warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "        with open(output, \"wb\") as f:\n",
        "            print(f\"Exporting onnx model to {output}...\")\n",
        "            torch.onnx.export(\n",
        "                onnx_model,\n",
        "                tuple(dummy_inputs.values()),\n",
        "                f,\n",
        "                export_params=True,\n",
        "                verbose=False,\n",
        "                opset_version=opset,\n",
        "                do_constant_folding=True,\n",
        "                input_names=list(dummy_inputs.keys()),\n",
        "                output_names=output_names,\n",
        "                dynamic_axes=dynamic_axes,\n",
        "            )\n",
        "\n",
        "    if onnxruntime_exists:\n",
        "        ort_inputs = {k: to_numpy(v) for k, v in dummy_inputs.items()}\n",
        "        # set cpu provider default\n",
        "        providers = [\"CPUExecutionProvider\"]\n",
        "        ort_session = onnxruntime.InferenceSession(output, providers=providers)\n",
        "        _ = ort_session.run(None, ort_inputs)\n",
        "        print(\"Model has successfully been run with ONNXRuntime.\")\n",
        "\n",
        "\n",
        "def to_numpy(tensor):\n",
        "    return tensor.cpu().numpy()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    args = parser.parse_args()\n",
        "    run_export(\n",
        "        model_type=args.model_type,\n",
        "        checkpoint=args.checkpoint,\n",
        "        output=args.output,\n",
        "        opset=args.opset,\n",
        "        return_single_mask=args.return_single_mask,\n",
        "        gelu_approximate=args.gelu_approximate,\n",
        "        use_stability_score=args.use_stability_score,\n",
        "        return_extra_metrics=args.return_extra_metrics,\n",
        "    )\n",
        "\n",
        "    if args.quantize_out is not None:\n",
        "        assert onnxruntime_exists, \"onnxruntime is required to quantize the model.\"\n",
        "        from onnxruntime.quantization import QuantType  # type: ignore\n",
        "        from onnxruntime.quantization.quantize import quantize_dynamic  # type: ignore\n",
        "\n",
        "        print(f\"Quantizing model and writing to {args.quantize_out}...\")\n",
        "        quantize_dynamic(\n",
        "            model_input=args.output,\n",
        "            model_output=args.quantize_out,\n",
        "            optimize_model=True,\n",
        "            per_channel=False,\n",
        "            reduce_range=False,\n",
        "            weight_type=QuantType.QUInt8,\n",
        "        )\n",
        "        print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "uNMPWW0vtdYO",
        "outputId": "170524dc-4e4f-4dda-95d9-1590d5d703b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: ipykernel_launcher.py [-h] --checkpoint CHECKPOINT --output OUTPUT\n",
            "                             --model-type MODEL_TYPE [--return-single-mask]\n",
            "                             [--opset OPSET] [--quantize-out QUANTIZE_OUT]\n",
            "                             [--gelu-approximate] [--use-stability-score]\n",
            "                             [--return-extra-metrics]\n",
            "ipykernel_launcher.py: error: the following arguments are required: --checkpoint, --output, --model-type\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        }
      ]
    }
  ]
}