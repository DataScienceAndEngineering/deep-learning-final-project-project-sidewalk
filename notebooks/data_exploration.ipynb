{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1KvaFHIBhaqD5EztOqQqPCs_ZY5wcuEgo",
      "authorship_tag": "ABX9TyMVmvLGVzgZ0NBzIsyn+t/T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DataScienceAndEngineering/deep-learning-final-project-project-sidewalk/blob/nicholas/notebooks/data_exploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "c-R2q1Y1TpyW"
      },
      "outputs": [],
      "source": [
        "#Loading all necessary packages\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import PIL\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Extract the dataset into colab\n",
        "if not os.path.isdir('./leftImg8bit/'):\n",
        "  !unzip ./drive/MyDrive/tensorflow_datasets/downloads/manual/leftImg8bit_trainvaltest.zip\n",
        "if not os.path.isdir('./gtFine/'):\n",
        "  !unzip ./drive/MyDrive/tensorflow_datasets/downloads/manual/gtFine_trainvaltest.zip\n",
        "\n",
        "#Data handling functions\n",
        "def mask_2_image(path):\n",
        "  #Converts the mask path string to the image path file corresponding to the same image\n",
        "  parts = path.split('/')\n",
        "  parts[1] = 'leftImg8bit'\n",
        "  file_name = parts[-1].split('_')\n",
        "  file_name[-1] = 'leftImg8bit.png'\n",
        "  parts[-1] = '_'.join(file_name)\n",
        "  path = '/'.join(parts)\n",
        "  return path\n",
        "  \n",
        "def obtain_paths(subset='train'):\n",
        "  #Returns filepaths of all labels and images which include a sidewalk segmentation\n",
        "  #Additinoally, moves all valid samples into extraction folders\n",
        "  LabelsDir = f'./gtFine/{subset}'\n",
        "  if not os.path.isdir('./extract_labels/'):\n",
        "    os.mkdir('./extract_labels/')\n",
        "    os.mkdir('./extract_images/')\n",
        "  labels_files = []\n",
        "  img_files = []\n",
        "  for root, dirs, files in os.walk(LabelsDir):\n",
        "    for filename in files:\n",
        "      if filename.endswith('labelIds.png'):\n",
        "        f = os.path.join(root, filename)\n",
        "        labels = np.array(PIL.Image.open(f))\n",
        "        if 8 in labels:\n",
        "          labels_files.append(f)\n",
        "          os.rename(f, './extract_labels/' + f.split('/'[-1]))\n",
        "          f = mask_2_image(f)\n",
        "          img_files.append(f)\n",
        "          os.rename(f, './extract_images' + f.split('/')[-1])\n",
        "  return labels_files, img_files\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing mask_2_image function\n",
        "f = './gtFine/train/bochum/bochum_000000_023435_gtFine_labelIds.png'\n",
        "mask_2_image(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "JtNUF3EdQOD1",
        "outputId": "9cb9591e-aa04-4db8-88eb-a3a231d34d91"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./leftImg8bit/train/bochum/bochum_000000_023435_gtFine_leftImg8bit.png'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_masks, train_images = obtain_paths('train')\n",
        "val_masks, val_images = obtain_paths('val')\n",
        "test_masks, test_images = obtain_paths('test')"
      ],
      "metadata": {
        "id": "XDgYGUX1ymdF"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'n_train: {len(train_masks)}')\n",
        "print(f'n_val: {len(val_masks)}')\n",
        "print(f'n_test: {len(test_masks)}')\n"
      ],
      "metadata": {
        "id": "meFJFO7poRkH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "38c3f0ec-51c6-4f3b-ecf9-1096eebad89e"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_train: 2811\n",
            "n_val: 466\n",
            "n_test: 0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./leftImg8bit/train/bochum/bochum_000000_026056_leftImg8bit.png'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_coef(y_true, y_pred):\n",
        "    smooth = 1e-6\n",
        "\n",
        "    y_true_f = tf.keras.layers.Flatten()(y_true)\n",
        "    y_pred_f = tf.keras.layers.Flatten()(y_pred)    \n",
        "\n",
        "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
        "    denom =(tf.reduce_sum(y_pred_f) + tf.reduce_sum(y_true_f) + smooth)\n",
        "    return (2. * intersection + smooth) / denom\n",
        "\n",
        "def dice_score(y_true, y_pred, numLabels=2):\n",
        "    dice=0\n",
        "    for index in range(numLabels):\n",
        "        dice -= dice_coef(y_true[:,:,:,index], y_pred[:,:,:,index])\n",
        "    return numLabels + dice\n"
      ],
      "metadata": {
        "id": "KR3L_XxAuWIG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Input Generator attempt 3\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Create a dataframe with the file paths\n",
        "data = {'filename': train_images, 'mask': train_masks}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Define the ImageDataGenerator for the images\n",
        "image_generator = ImageDataGenerator()\n",
        "\n",
        "# Define the ImageDataGenerator for the masks\n",
        "mask_generator = ImageDataGenerator()\n",
        "\n",
        "# Use the flow_from_dataframe method to load the images and masks\n",
        "batch_size = 8\n",
        "image_height = 256\n",
        "image_width = 512\n",
        "image_color_mode = 'rgb' # or 'grayscale'\n",
        "mask_color_mode = 'grayscale'\n",
        "seed = 42\n",
        "\n",
        "train_generator = image_generator.flow_from_dataframe(\n",
        "    dataframe=df,\n",
        "    directory=None,\n",
        "    x_col='filename',\n",
        "    y_col='mask',\n",
        "    #shuffle=True,\n",
        "    target_size=(image_height, image_width),\n",
        "    batch_size=batch_size,\n",
        "    color_mode=image_color_mode,\n",
        "    class_mode='input',\n",
        "    seed=seed\n",
        ")\n",
        "\n",
        "mask_flow = mask_generator.flow_from_dataframe(\n",
        "    dataframe=df,\n",
        "    directory=None,\n",
        "    x_col='filename',\n",
        "    y_col='mask',\n",
        "    #shuffle=True,\n",
        "    target_size=(image_height, image_width),\n",
        "    batch_size=batch_size,\n",
        "    color_mode=mask_color_mode,\n",
        "    class_mode=None,\n",
        "    seed=seed\n",
        ")\n",
        "\n",
        "#train_generator = MergedGenerators(train_generator, mask_flow)\n",
        "\n",
        "# Use the train_generator to fit your model with the fit_generator method\n",
        "\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "i66DPcfs9oA0",
        "outputId": "b5d8000e-a987-4c84-c4d3-999acef38c5d"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2811 validated image filenames.\n",
            "Found 2811 validated image filenames.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-23fa33f6581f>\u001b[0m in \u001b[0;36m<cell line: 64>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m# Use the train_generator to fit your model with the fit_generator method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip(train_generator, mask_flow)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeQ7puH9E9Vz",
        "outputId": "0e4a60fb-c055-4e4e-f859-49035bb252b4"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<zip at 0x7fb384f38340>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Input generator: Not working, .fit() hanging\n",
        "\n",
        "def mask_processing(mask_path):\n",
        "    #Removes extra segmentations from mask, returning only sidewalk info.\n",
        "    #Input path to mask file, returns image (possibly re-save in new directory_)\n",
        "    mask = tf.io.decode_png(tf.io.read_file(mask_path), channels=1)\n",
        "    new_mask = tf.cast(tf.math.equal(mask, 8), tf.float32)\n",
        "    return new_mask\n",
        "\n",
        "def input_function(image_paths, mask_paths, batch_size):\n",
        "    images = tf.data.Dataset.from_tensor_slices(image_paths)\n",
        "    masks = tf.data.Dataset.from_tensor_slices(mask_paths)\n",
        "\n",
        "    dataset = tf.data.Dataset.zip((images, masks))\n",
        "    dataset = dataset.shuffle(len(image_paths))\n",
        "\n",
        "    dataset = dataset.map(lambda x, y: (tf.io.read_file(x), tf.py_function(mask_processing, [y], tf.float32)))\n",
        "    dataset = dataset.map(lambda x, y: (tf.image.decode_png(x), y))\n",
        "    dataset = dataset.map(lambda x, y: (tf.image.resize(x, [256, 256]), tf.image.resize(y, [256, 256])))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "\n",
        "    dataset = dataset.repeat()\n",
        "    iterator = iter(dataset)\n",
        "\n",
        "    while True:\n",
        "      yield next(iterator)\n",
        "    #return dataset\n",
        "\n",
        "input_fn = lambda: input_function(train_images, train_masks, 32)\n"
      ],
      "metadata": {
        "id": "ufGHoUnLKyJe"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model architecture\n",
        "\n",
        "initial=tf.keras.initializers.glorot_uniform(seed=0)\n",
        "\n",
        "def conv_block(input_layer, n_filters, kernel=(3, 3), padding='same', strides=(1, 1), L2=0):\n",
        "    layer = tf.keras.layers.Conv2D(n_filters, kernel, padding=padding, strides=strides, kernel_initializer = initial, kernel_regularizer=tf.keras.regularizers.l2(L2))(input_layer)\n",
        "    layer = tf.keras.layers.BatchNormalization(center=False,scale=False)(layer)\n",
        "    return tf.keras.layers.Activation('relu')(layer)\n",
        "\n",
        "def conv_up(n_filters, pool_size=(2,2), kernel_size=(2,2), strides=(2, 2), L2=0):\n",
        "    return tf.keras.layers.Conv2DTranspose(filters=n_filters, kernel_size=(2,2), kernel_initializer = initial, strides=strides, kernel_regularizer=tf.keras.regularizers.l2(L2))            \n",
        "\n",
        "    \n",
        "def gen_model(input_shape =  (256, 512, 3), pool_size=(2, 2),initial_learning_rate=1e-5,\n",
        "                      depth=4, n_base_filters=16, activation_name=\"softmax\", L2=0, n_classes=2):\n",
        "        \n",
        "        inputs = tf.keras.layers.Input(input_shape) #Declare input shape\n",
        "        levels = list()\n",
        "        current_layer = tf.keras.layers.Conv2D(n_base_filters, (1, 1), kernel_initializer = initial)(inputs) # initial input layer\n",
        "        \n",
        "        \"\"\" Down slope portion of U-net\"\"\"\n",
        "        # add levels with max pooling\n",
        "        for layer_depth in range(depth): #Creats 2 convolutional blocks per depth unit\n",
        "            layer1 = conv_block(input_layer=current_layer, kernel=(3,3), n_filters=n_base_filters*(layer_depth+1), padding='same', L2=L2)\n",
        "            layer2 = conv_block(input_layer=layer1, kernel=(3,3), n_filters=n_base_filters*(layer_depth+1), padding='same', L2=L2)\n",
        "            if layer_depth < depth - 1: #If the current layer is less then the second to last down sampling\n",
        "                #Apply a pooling layer\n",
        "                current_layer = tf.keras.layers.MaxPooling2D(pool_size=(2,2))(layer2)\n",
        "                levels.append([layer1, layer2, current_layer]) #layers are recorded for reference\n",
        "            else: #If current layer is not less then the second to last, skip the pooling\n",
        "                current_layer = layer2\n",
        "                levels.append([layer1, layer2])\n",
        "\n",
        "        \"\"\" Up slope portion of U-net\"\"\"\n",
        "        for layer_depth in range(depth-2, -1, -1): #Going from the last layer up to 0\n",
        "            \n",
        "            up_convolution = conv_up(pool_size=(2,2), n_filters=n_base_filters*(layer_depth+2), L2=L2)(current_layer)\n",
        "            \n",
        "            concat = tf.keras.layers.concatenate([up_convolution, levels[layer_depth][1]] , axis=-1)\n",
        "            current_layer = conv_block(n_filters=n_base_filters*(layer_depth+1), kernel=(3,3), input_layer=concat, padding='same', L2=L2)\n",
        "            current_layer = conv_block(n_filters=n_base_filters*(layer_depth+1), kernel=(3,3), input_layer=current_layer, padding='same', L2=L2)\n",
        "            \n",
        "        final_convolution = tf.keras.layers.Conv2D(n_classes, (1, 1), kernel_initializer=initial)(current_layer)\n",
        "        act = tf.keras.layers.Activation(activation_name)(final_convolution)\n",
        "        model = tf.keras.Model(inputs=[inputs], outputs=act)\n",
        "        return model\n",
        "\n",
        "model = gen_model()\n",
        "model.compile(loss=dice_coef, optimizer=tf.keras.optimizers.Adam(learning_rate = 0), metrics=['acc'])"
      ],
      "metadata": {
        "id": "IYRGftBiccjr"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# current hands on input_function(), runtime expires and reboots\n",
        "model.fit(input_fn=input_function(train_images, train_masks, 2))"
      ],
      "metadata": {
        "id": "bV0T1nW_wxeR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "e11f9b8d-e944-4fa7-8d89-24a3addc4197"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-b39acd49270e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# current hands on input_function(), runtime expires and reboots\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: fit() got an unexpected keyword argument 'input_fn'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ensuring values of 8 correspond to sidewalk segmentations\n",
        "\n",
        "#cities = ['berlin', 'bielefeld', 'bonn', 'leverkusen', 'mainz', 'munich']\n",
        "#for i in cities:\n",
        "i = 'cologne'\n",
        "tImage = PIL.Image.open(f'./leftImg8bit/train/{i}/{i}_000100_000019_leftImg8bit.png')\n",
        "tMask = PIL.Image.open(f'./gtFine/train/{i}/{i}_000100_000019_gtFine_labelIds.png')\n",
        "Mask = np.array(tMask)\n",
        "Image = np.array(tImage)\n",
        "\n",
        "#Displaying mask and image pair, printing mask value for sidewalk location\n",
        "plt.figure()\n",
        "plt.imshow(Mask)\n",
        "plt.figure()\n",
        "plt.imshow(Image)\n",
        "print(Mask[800,2000])"
      ],
      "metadata": {
        "id": "VMQKb-TNjYfx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}