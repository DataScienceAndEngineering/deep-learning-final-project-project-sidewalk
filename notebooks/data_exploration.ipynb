{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1KvaFHIBhaqD5EztOqQqPCs_ZY5wcuEgo",
      "authorship_tag": "ABX9TyNHXjXcXKbqhHm6XGp+bQMZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DataScienceAndEngineering/deep-learning-final-project-project-sidewalk/blob/nicholas/notebooks/data_exploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-R2q1Y1TpyW"
      },
      "outputs": [],
      "source": [
        "#Loading all necessary packages\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Extract the dataset into colab\n",
        "#!unzip ./drive/MyDrive/tensorflow_datasets/downloads/manual/leftImg8bit_trainvaltest.zip\n",
        "#!unzip ./drive/MyDrive/tensorflow_datasets/downloads/manual/gtFine_trainvaltest.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def obtain_paths(subset='train'):\n",
        "  #Returns filepaths of all labels and images which include a sidewalk segmentation\n",
        "  LabelsDir = f'./gtFine/{subset}'\n",
        "  labels_files = []\n",
        "  img_files = []\n",
        "  for root, dirs, files in os.walk(LabelsDir):\n",
        "    for filename in files:\n",
        "      if filename.endswith('labelIds.png'):\n",
        "        f = os.path.join(root, filename)\n",
        "        labels = np.array(PIL.Image.open(f))\n",
        "        if 8 in labels:\n",
        "          labels_files.append(f)\n",
        "          img_files.append('./leftImg8bit' + f[8:-19] + 'leftImg8bit.png')\n",
        "  return labels_files, img_files\n",
        "\n",
        "train_masks, train_images = obtain_paths('train')\n",
        "val_masks, val_images = obtain_paths('val')\n",
        "test_masks, test_images = obtain_paths('test')"
      ],
      "metadata": {
        "id": "XDgYGUX1ymdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'n_train: {len(train_masks)}')\n",
        "print(f'n_val: {len(val_masks)}')\n",
        "print(f'n_test: {len(test_masks)}')\n"
      ],
      "metadata": {
        "id": "meFJFO7poRkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_coef(y_true, y_pred):\n",
        "    smooth = 1e-6\n",
        "\n",
        "    y_true_f = tf.keras.layers.Flatten()(y_true)\n",
        "    y_pred_f = tf.keras.layers.Flatten()(y_pred)    \n",
        "\n",
        "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
        "    denom =(tf.reduce_sum(y_pred_f) + tf.reduce_sum(y_true_f) + smooth)\n",
        "    return (2. * intersection + smooth) / denom\n",
        "\n",
        "def dice_score(y_true, y_pred, numLabels=2):\n",
        "    \"\"\"This is the loss function to MINIMIZE. A perfect overlap returns 0. Total disagreement returns numeLabels\"\"\"\n",
        "    dice=0\n",
        "    for index in range(numLabels):\n",
        "        dice -= dice_coef(y_true[:,:,:,index], y_pred[:,:,:,index])\n",
        "    return numLabels + dice\n"
      ],
      "metadata": {
        "id": "KR3L_XxAuWIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mask_processing(mask_path):\n",
        "    #Removes extra segmentations from mask, returning only sidewalk info.\n",
        "    #Input path to mask file, returns image (possibly re-save in new directory_)\n",
        "    mask = tf.io.decode_png(tf.io.read_file(mask_path), channels=1)\n",
        "    new_mask = tf.cast(tf.math.equal(mask, 8), tf.float32)\n",
        "    return new_mask\n",
        "\n",
        "def input_function(image_paths, mask_paths, batch_size):\n",
        "    images = tf.data.Dataset.from_tensor_slices(image_paths).map(tf.io.read_file).map(tf.image.decode_png)\n",
        "    masks = tf.data.Dataset.from_tensor_slices(mask_paths).map(mask_processing)\n",
        "    \n",
        "    # Combine the image and mask datasets\n",
        "    dataset = tf.data.Dataset.zip({\"input\": images, \"output\": masks})\n",
        "    \n",
        "    # Shuffle and batch the data\n",
        "    dataset = dataset.shuffle(len(image_paths)).batch(batch_size)\n",
        "    example = next(iter(dataset))\n",
        "    image, mask = example[0], example[1]\n",
        "    \n",
        "    return image\n",
        "    #return dataset\n",
        "\n",
        "input_fn = lambda: input_function(train_images, train_masks, 32)\n"
      ],
      "metadata": {
        "id": "ufGHoUnLKyJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model architecture\n",
        "\n",
        "initial=tf.keras.initializers.glorot_uniform(seed=0)\n",
        "\n",
        "def conv_block(input_layer, n_filters, kernel=(3, 3), padding='same', strides=(1, 1), L2=0):\n",
        "    layer = tf.keras.layers.Conv2D(n_filters, kernel, padding=padding, strides=strides, kernel_initializer = initial, kernel_regularizer=tf.keras.regularizers.l2(L2))(input_layer)\n",
        "    layer = tf.keras.layers.BatchNormalization(center=False,scale=False)(layer)\n",
        "    return tf.keras.layers.Activation('relu')(layer)\n",
        "\n",
        "def conv_up(n_filters, pool_size=(2,2), kernel_size=(2,2), strides=(2, 2), L2=0):\n",
        "    return tf.keras.layers.Conv2DTranspose(filters=n_filters, kernel_size=(2,2), kernel_initializer = initial, strides=strides, kernel_regularizer=tf.keras.regularizers.l2(L2))            \n",
        "\n",
        "    \n",
        "def gen_model(input_shape =  (1024, 2048, 3), pool_size=(2, 2),initial_learning_rate=1e-5,\n",
        "                      depth=4, n_base_filters=16, activation_name=\"softmax\", L2=0, n_classes=2):\n",
        "        \n",
        "        inputs = tf.keras.layers.Input(input_shape) #Declare input shape\n",
        "        levels = list()\n",
        "        current_layer = tf.keras.layers.Conv2D(n_base_filters, (1, 1), kernel_initializer = initial)(inputs) # initial input layer\n",
        "        \n",
        "        \"\"\" Down slope portion of U-net\"\"\"\n",
        "        # add levels with max pooling\n",
        "        for layer_depth in range(depth): #Creats 2 convolutional blocks per depth unit\n",
        "            layer1 = conv_block(input_layer=current_layer, kernel=(3,3), n_filters=n_base_filters*(layer_depth+1), padding='same', L2=L2)\n",
        "            layer2 = conv_block(input_layer=layer1, kernel=(3,3), n_filters=n_base_filters*(layer_depth+1), padding='same', L2=L2)\n",
        "            if layer_depth < depth - 1: #If the current layer is less then the second to last down sampling\n",
        "                #Apply a pooling layer\n",
        "                current_layer = tf.keras.layers.MaxPooling2D(pool_size=(2,2))(layer2)\n",
        "                levels.append([layer1, layer2, current_layer]) #layers are recorded for reference\n",
        "            else: #If current layer is not less then the second to last, skip the pooling\n",
        "                current_layer = layer2\n",
        "                levels.append([layer1, layer2])\n",
        "\n",
        "        \"\"\" Up slope portion of U-net\"\"\"\n",
        "        for layer_depth in range(depth-2, -1, -1): #Going from the last layer up to 0\n",
        "            \n",
        "            up_convolution = conv_up(pool_size=(2,2), n_filters=n_base_filters*(layer_depth+2), L2=L2)(current_layer)\n",
        "            \n",
        "            concat = tf.keras.layers.concatenate([up_convolution, levels[layer_depth][1]] , axis=-1)\n",
        "            current_layer = conv_block(n_filters=n_base_filters*(layer_depth+1), kernel=(3,3), input_layer=concat, padding='same', L2=L2)\n",
        "            current_layer = conv_block(n_filters=n_base_filters*(layer_depth+1), kernel=(3,3), input_layer=current_layer, padding='same', L2=L2)\n",
        "            \n",
        "        final_convolution = tf.keras.layers.Conv2D(n_classes, (1, 1), kernel_initializer=initial)(current_layer)\n",
        "        act = tf.keras.layers.Activation(activation_name)(final_convolution)\n",
        "        model = tf.keras.Model(inputs=[inputs], outputs=act)\n",
        "        return model\n",
        "\n",
        "model = gen_model()\n",
        "model.compile(loss=dice_score, optimizer=tf.keras.optimizers.Adam(learning_rate = 0), metrics=['acc'])"
      ],
      "metadata": {
        "id": "IYRGftBiccjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(input_function(train_images, train_masks, 32))"
      ],
      "metadata": {
        "id": "bV0T1nW_wxeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ensuring values of 8 correspond to sidewalk segmentations\n",
        "\n",
        "#cities = ['berlin', 'bielefeld', 'bonn', 'leverkusen', 'mainz', 'munich']\n",
        "#for i in cities:\n",
        "i = 'cologne'\n",
        "tImage = PIL.Image.open(f'./leftImg8bit/train/{i}/{i}_000100_000019_leftImg8bit.png')\n",
        "tMask = PIL.Image.open(f'./gtFine/train/{i}/{i}_000100_000019_gtFine_labelIds.png')\n",
        "Mask = np.array(tMask)\n",
        "Image = np.array(tImage)\n",
        "\n",
        "#Displaying mask and image pair, printing mask value for sidewalk location\n",
        "plt.figure()\n",
        "plt.imshow(Mask)\n",
        "plt.figure()\n",
        "plt.imshow(Image)\n",
        "print(Mask[800,2000])"
      ],
      "metadata": {
        "id": "VMQKb-TNjYfx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}