{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "hazyGcpGH8qS",
        "rvGsEQ-ZzA_T",
        "cCsykJ2qUSY7",
        "1rZorVuzutIt"
      ],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DataScienceAndEngineering/deep-learning-final-project-project-sidewalk/blob/rabiul/notebooks%20/Rabiul/Baseline_RandomForest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading Libraries"
      ],
      "metadata": {
        "id": "7QcascrI7M07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "1SS4YIzG2fV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import cv2\n",
        "import os\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from skimage.filters import roberts, sobel, scharr, prewitt\n",
        "from scipy import ndimage as nd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from google.colab import drive\n",
        "import pickle\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "PO2TnZE37PmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading data and model \n",
        "!gdown --id 1-3gbEPrVnD0YZ38ZixZrRjo3y2-NeOgr -O test.csv\n",
        "!gdown --id 1TRDaaX13CqHE8xzIXKPnhLEhniWlUR9a -O train.csv\n",
        "!gdown --id 1-14yL80KGLJzF2D6j3BXTH1dLa2knz_W -O model.sav"
      ],
      "metadata": {
        "id": "iYZPEFo99R5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = pickle.load(open('/content/model.sav', 'rb'))"
      ],
      "metadata": {
        "id": "vBhe37Xg9SZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_data('/content/train.csv', '/content/test.csv')\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "1rvqpXEQ9Sp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(rf_accuracy(model, X_test,y_test))"
      ],
      "metadata": {
        "id": "3mBoEgmf9Znl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(rf_accuracy(model, X_train,y_train))"
      ],
      "metadata": {
        "id": "ytQBfmK79S5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "GrwWFosL6HVO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Loading Data"
      ],
      "metadata": {
        "id": "fYPpYVlJ7ALs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#downloading preprocessed data\n",
        "!gdown --id 12rNfOiM4allOn8t4l0ErpvgmA9hEZPh2 -O processed_labels.zip\n",
        "!gdown --id 145Ul0rdbQcX98lQz8IO5eOtI0ZlvKwz6 -O processed_images.zip"
      ],
      "metadata": {
        "id": "nlkvBNXItiHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#unzipping the preprocessed data to local dir\n",
        "!unzip /content/processed_images.zip\n",
        "!unzip /content/processed_labels.zip"
      ],
      "metadata": {
        "id": "iRtqOCbcvSTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-Processing Data Step 1"
      ],
      "metadata": {
        "id": "tCDqzox07E_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#path to the directory for both image and label data \n",
        "img_path = '/content/content/processed_images/*'\n",
        "lab_path = '/content/content/processed_labels/*'\n",
        "#one sample data point\n",
        "#/content/content/processed_images/aachen_000000_000019.png\n",
        "#/content/content/processed_labels/aachen_000000_000019.png"
      ],
      "metadata": {
        "id": "AgJMIX2_dDHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the data indo a list, numpy array\n",
        "%%time\n",
        "train_images = glob.glob(img_path)\n",
        "train_labels = glob.glob(lab_path)\n",
        "print(len(train_images),len(train_labels))\n"
      ],
      "metadata": {
        "id": "4ZMBHtR1veez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n=40\n",
        "m=2310"
      ],
      "metadata": {
        "id": "9JKgRGjYrjCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = np.array(x_train['gray'].values)\n",
        "t = t.reshape(int(t.shape[0]/40000),40000)\n",
        "display_img(t[0].reshape(200,200))"
      ],
      "metadata": {
        "id": "FdtUv0ZEwS1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test and train images \n",
        "x_train = create_train_image_df(train_images[:n])\n",
        "x_test = create_test_image_df(train_images[2300:m])\n",
        "print(x_train.shape,x_test.shape )\n",
        "x_train.head()"
      ],
      "metadata": {
        "id": "J1yBL0DknMZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.head(2)"
      ],
      "metadata": {
        "id": "sW4cyfqJnMec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating train mask image Data Frame\n",
        "%%time\n",
        "dim = (200,200)\n",
        "y_train = pd.DataFrame()\n",
        "\n",
        "for label_dir in train_labels[:n]:\n",
        "  df2 = pd.DataFrame()\n",
        "  lab = cv2.imread(label_dir, 0)\n",
        "  #lab = cv2.resize(lab, dim).reshape(-1)\n",
        "  df2['label'] = cv2.resize(lab, dim).reshape(-1) \n",
        "  y_train = pd.concat([y_train, df2])\n",
        "print(y_train.shape)\n",
        "y_train.head(2)"
      ],
      "metadata": {
        "id": "FJeuq2KZrU4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating test mask image Data Frame\n",
        "%%time\n",
        "dim = (200,200)\n",
        "y_test = pd.DataFrame()\n",
        "\n",
        "for label_dir in train_labels[2300:m]:\n",
        "  df2 = pd.DataFrame()\n",
        "  lab = cv2.imread(label_dir, 0)\n",
        "  #lab = cv2.resize(lab, dim).reshape(-1)\n",
        "  df2['label'] = cv2.resize(lab, dim).reshape(-1) \n",
        "  y_test = pd.concat([y_test, df2])\n",
        "print(y_test.shape)\n",
        "y_test.head(2)"
      ],
      "metadata": {
        "id": "_67502CwqnKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.concat([x_train, y_train], axis=1)\n",
        "print(df_train.shape)\n",
        "df_train.head(2)"
      ],
      "metadata": {
        "id": "gsuVHFS2qnPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.concat([x_test, y_test], axis=1)\n",
        "print(df_test.shape)\n",
        "df_test.head(2)"
      ],
      "metadata": {
        "id": "C5eM82vR1Hnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_train.shape)\n",
        "print(df_test.shape)"
      ],
      "metadata": {
        "id": "APQbBEFg1aRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/DL_Project"
      ],
      "metadata": {
        "id": "dPHqaN4g8job"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#only execute this cell to save the preprocessed dataframe to google drive \n",
        "df_train.to_csv('df_train.csv', index=False)\n",
        "df_test.to_csv('df_test.csv', index=False)\n",
        "#Changing directory back to \"Content\"\n"
      ],
      "metadata": {
        "id": "x8SZLWEi7If3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content"
      ],
      "metadata": {
        "id": "WRuWlUbn8tcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PreProcess Data Step 2"
      ],
      "metadata": {
        "id": "TKTRjTQq_R6B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#print(df_train.shape)\n",
        "#print(df_test.shape)\n",
        "print(df_train.shape, df_test.shape)"
      ],
      "metadata": {
        "id": "JjO1GlhE1fq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Execute this cell only if you want to use GPU and GPU is setup\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "id": "pVkRepNvCu3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Execute this cell only if you want to remove all zero value where label = 0. \n",
        "df_train = df_train[df_train.label != 0]\n",
        "df_test = df_test[df_test.label != 0]\n",
        "print(df_train.shape, df_test.shape)"
      ],
      "metadata": {
        "id": "tc6AFIEj1f0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_Train = df_train.drop(labels = [\"label\"], axis=1)\n",
        "Y_Train = df_train[\"label\"].values\n",
        "\n",
        "X_Test = df_test.drop(labels = [\"label\"], axis=1)\n",
        "Y_Test = df_test[\"label\"].values\n",
        "\n",
        "\n",
        "print((X_Train.shape, Y_Train.shape),(X_Test.shape, Y_Test.shape))"
      ],
      "metadata": {
        "id": "T177MN4P2eGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_Train = LabelEncoder().fit_transform(Y_Train)\n",
        "Y_Test = LabelEncoder().fit_transform(Y_Test)\n",
        "print(Y_Train.shape, Y_Test.shape)"
      ],
      "metadata": {
        "id": "8FEgcJoo2ePK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL"
      ],
      "metadata": {
        "id": "YYZ0a30I6NNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier(n_estimators=100, criterion='entropy', max_depth=None, \n",
        "                            min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
        "                            max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
        "                            bootstrap=True, oob_score=False, n_jobs=None, random_state=2, \n",
        "                            verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, \n",
        "                            max_samples=None)"
      ],
      "metadata": {
        "id": "WIIIcyUUzTY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FIT & Save Model"
      ],
      "metadata": {
        "id": "gB-kE0C26Zqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/DL_Project"
      ],
      "metadata": {
        "id": "0bhiHlMjqT3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "## Train the model on training data\n",
        "model.fit(X_Train, Y_Train)"
      ],
      "metadata": {
        "id": "il3_TV0q29MC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save the trained model as pickle string to google drive for future use \n",
        "filename = \"rf_model2_withzero.sav\"\n",
        "pickle.dump(model, open(filename, 'wb'))\n",
        "#Changing directory back to \"Content\"\n",
        "cd /content"
      ],
      "metadata": {
        "id": "euEnyJ0KH8hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict"
      ],
      "metadata": {
        "id": "bhz6ChqizydG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_test = model.predict(X_Test)"
      ],
      "metadata": {
        "id": "0auJH93AgVHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Testing Accuracy = \", metrics.accuracy_score(Y_Test, prediction_test))"
      ],
      "metadata": {
        "id": "vt7LxLRO0jJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred = prediction_test.reshape(int(prediction_test.shape[0]/40000),40000)\n",
        "Y_true = Y_Test.reshape(int(Y_Test.shape[0]/40000),40000)\n",
        "print(Y_true.shape,Y_pred.shape )"
      ],
      "metadata": {
        "id": "xSsXPBvc1XjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Testing Accuracy = \", metrics.accuracy_score(Y_true[0].reshape(200,200), Y_pred[0].reshape(200,200)))"
      ],
      "metadata": {
        "id": "wcVE4OgS6EEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import jaccard_score"
      ],
      "metadata": {
        "id": "I8-O9m_zjOEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Training Accuracy = \", jaccard_score(Y_true, Y_pred,average='micro'))"
      ],
      "metadata": {
        "id": "_cF0vQENjQ28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3lovB0fgt-5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "WoXAEEd0sJk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gabor_feature_extraction(img, lamda, gamma):\n",
        "  kernel = cv2.getGaborKernel((8, 8), 1, 0, lamda, gamma, 0, ktype=cv2.CV_32F)\n",
        "  gabor_img = cv2.filter2D(img, cv2.CV_8UC3, kernel)\n",
        "  return gabor_img.reshape(-1,1)/255\n"
      ],
      "metadata": {
        "id": "-vv5vreOsLXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(img):\n",
        "  #function will accept a numpy.ndarray\n",
        "\n",
        "  #GAUSSIAN blur 1\n",
        "  gblur = cv2.GaussianBlur(img, (5,5),7)\n",
        "  #Laplacian\n",
        "  laplacian = cv2.Laplacian(img, cv2.CV_64F, ksize=7) \n",
        "  #SOBEL\n",
        "  sobele = cv2.Sobel(img,cv2.CV_64F, 0,1,ksize=5)\n",
        "  #CANNY \n",
        "  cany = cv2.Canny(np.uint8(sobele), 100,200)\n",
        "\n",
        "  #return cany\n",
        "  return (gblur.reshape(-1)/255,laplacian.reshape(-1)/255,sobele.reshape(-1)/255,cany.reshape(-1)/255)"
      ],
      "metadata": {
        "id": "CZ_JrjPPsLz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image_org(img):\n",
        "  #GAUSSIAN blur 1\n",
        "  blur1 = nd.gaussian_filter(img, sigma=3)\n",
        "  #GAUSSIAN blur2\n",
        "  blur2 = nd.gaussian_filter(img, sigma=7)\n",
        "  #SOBEL\n",
        "  sobele = sobel(blur2)\n",
        "  #CANNY \n",
        "  cany = cv2.Canny(np.uint8(sobele), 100,200)\n",
        "  #return cany\n",
        "  return (blur1.reshape(-1,1),blur2.reshape(-1,1),sobele.reshape(-1,1),cany.reshape(-1,1))"
      ],
      "metadata": {
        "id": "BVCA-uLQsL2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_img(img):\n",
        "  fig = plt.figure(figsize=(8,8))\n",
        "  ax = fig.add_subplot(111)\n",
        "  ax.imshow(img,cmap='gray')"
      ],
      "metadata": {
        "id": "00mkCqMssL5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_img(image_path):\n",
        "  return cv2.imread(image_path, 0).astype(np.float32)/255\n"
      ],
      "metadata": {
        "id": "1ocjCADFplBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_one_test_image(image_dir):\n",
        "  img = cv2.imread(image_dir, 0)\n",
        "  g1 = img/255\n",
        "  _,thresh3  = cv2.threshold(img, 80, 255, cv2.THRESH_BINARY_INV)\n",
        "  binay_inv = thresh3/255\n",
        "  adaptive_thresh = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,11, 11)/255\n",
        "  gb1 = gabor_feature_extraction(img,.8, .05 )/255\n",
        "  gb2 = gabor_feature_extraction(img,1.6, .5 )/255\n",
        "  blur, laplacian, sobel, cany = preprocess_image(img)\n",
        "  return np.hstack((g1.reshape(-1,1), binay_inv.reshape(-1,1), adaptive_thresh.reshape(-1,1), \n",
        "                    gb1.reshape(-1,1), gb2.reshape(-1,1), blur.reshape(-1,1), \n",
        "                    laplacian.reshape(-1,1), sobel.reshape(-1,1), cany.reshape(-1,1)))\n"
      ],
      "metadata": {
        "id": "1zQxJi2WplEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_one_test_image_df(image_dir):\n",
        "  dim = (200,200)\n",
        "  test_df = pd.DataFrame()\n",
        "  img = cv2.imread(image_dir, 0)\n",
        "  img = cv2.resize(img, dim)\n",
        "  g1 = img/255\n",
        "  _,thresh3  = cv2.threshold(img, 80, 255, cv2.THRESH_BINARY_INV)\n",
        "  binay_inv = thresh3/255\n",
        "  adaptive_thresh = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,11, 11)/255\n",
        "  gb1 = gabor_feature_extraction(img,.8, .05 )/255\n",
        "  gb2 = gabor_feature_extraction(img,1.6, .5 )/255\n",
        "  blur, laplacian, sobel, cany = preprocess_image(img)\n",
        "\n",
        "  test_df['gray']= g1.reshape(-1)\n",
        "  test_df['binay_inv']= binay_inv.reshape(-1)\n",
        "  test_df['adaptive_thresh']=adaptive_thresh.reshape(-1)\n",
        "  test_df['gabor1'] = gabor_feature_extraction(img,.8, .05 ).reshape(-1)\n",
        "  test_df['gabor2'] = gabor_feature_extraction(img,1.6, .5 ).reshape(-1)\n",
        "  test_df['blur'], test_df['laplacian'], test_df['sobelx'], test_df['canny'] = blur.reshape(-1), laplacian.reshape(-1), sobel.reshape(-1), cany.reshape(-1)\n",
        "\n",
        "  return test_df\n"
      ],
      "metadata": {
        "id": "rx5nfg_-plH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_one_test_image_df_a(image_dir):\n",
        "  #this function is getting an image as an input \n",
        "  test_df = pd.DataFrame()\n",
        "  #img = cv2.imread(image_dir, 0)\n",
        "  img = image_dir\n",
        "  g1 = img/255\n",
        "  _,thresh3  = cv2.threshold(img, 80, 255, cv2.THRESH_BINARY_INV)\n",
        "  binay_inv = thresh3/255\n",
        "  adaptive_thresh = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,11, 11)/255\n",
        "  gb1 = gabor_feature_extraction(img,.8, .05 )/255\n",
        "  gb2 = gabor_feature_extraction(img,1.6, .5 )/255\n",
        "  blur, laplacian, sobel, cany = preprocess_image(img)\n",
        "\n",
        "  test_df['gray']= g1.reshape(-1)\n",
        "  test_df['binay_inv']= binay_inv.reshape(-1)\n",
        "  test_df['adaptive_thresh']=adaptive_thresh.reshape(-1)\n",
        "  test_df['gabor1'] = gabor_feature_extraction(img,.8, .05 ).reshape(-1)\n",
        "  test_df['gabor2'] = gabor_feature_extraction(img,1.6, .5 ).reshape(-1)\n",
        "  test_df['blur'], test_df['laplacian'], test_df['sobelx'], test_df['canny'] = blur.reshape(-1), laplacian.reshape(-1), sobel.reshape(-1), cany.reshape(-1)\n",
        "\n",
        "  return test_df"
      ],
      "metadata": {
        "id": "qvBiGJ_nek2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_images(img, gt, pred):\n",
        "    if pred is not None:\n",
        "        fig, axes = plt.subplots(1, 3, figsize=(12, 8))\n",
        "    else:\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(8, 8))\n",
        "\n",
        "    axes[0].imshow(img)\n",
        "    axes[0].set_title('Actual Image')\n",
        "\n",
        "    axes[1].imshow(gt)\n",
        "    axes[1].set_title('Masked Image')\n",
        "    \n",
        "    if pred is not None:\n",
        "        axes[2].imshow(pred)\n",
        "        axes[2].set_title('Predicted Image')"
      ],
      "metadata": {
        "id": "L5OnUvljBEEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(X,filters,block):\n",
        "    # resiudal block with dilated convolutions\n",
        "    # add skip connection at last after doing convoluion\n",
        "\n",
        "    b = 'block_'+str(block)+'_'\n",
        "    f1,f2,f3 = filters\n",
        "    X_skip = X\n",
        "\n",
        "    # block_a\n",
        "    X = Conv2D(filters=f1,kernel_size=(1,1),dilation_rate=(1,1),\n",
        "               padding='same',kernel_initializer='he_normal',name=b+'a')(X)\n",
        "    X = BatchNormalization(name=b+'batch_norm_a')(X)\n",
        "    X = LeakyReLU(alpha=0.2,name=b+'leakyrelu_a')(X)\n",
        "    # block_b\n",
        "    X = Conv2D(filters=f2,kernel_size=(3,3),dilation_rate=(2,2),\n",
        "               padding='same',kernel_initializer='he_normal',name=b+'b')(X)\n",
        "    X = BatchNormalization(name=b+'batch_norm_b')(X)\n",
        "    X = LeakyReLU(alpha=0.2,name=b+'leakyrelu_b')(X)\n",
        "    # block_c\n",
        "    X = Conv2D(filters=f3,kernel_size=(1,1),dilation_rate=(1,1),\n",
        "               padding='same',kernel_initializer='he_normal',name=b+'c')(X)\n",
        "    X = BatchNormalization(name=b+'batch_norm_c')(X)\n",
        "    # skip_conv\n",
        "    X_skip = Conv2D(filters=f3,kernel_size=(3,3),padding='same',name=b+'skip_conv')(X_skip)\n",
        "    X_skip = BatchNormalization(name=b+'batch_norm_skip_conv')(X_skip)\n",
        "    # block_c + skip_conv\n",
        "    X = Add(name=b+'add')([X,X_skip])\n",
        "    X = ReLU(name=b+'relu')(X)\n",
        "    return X\n",
        "    \n",
        "def base_feature_maps(input_layer):\n",
        "    # base covolution module to get input image feature maps \n",
        "    \n",
        "    # block_1\n",
        "    base = conv_block(input_layer,[16,16,32],'1')\n",
        "    # block_2\n",
        "    base = conv_block(base,[16,16,32],'2')\n",
        "    return base\n",
        "\n",
        "def pyramid_feature_maps(input_layer):\n",
        "    # pyramid pooling module\n",
        "    \n",
        "    base = base_feature_maps(input_layer)\n",
        "    # red\n",
        "    red = GlobalAveragePooling2D(name='red_pool')(base)\n",
        "    red = tf.keras.layers.Reshape((1,1,32))(red)\n",
        "    red = Conv2D(filters=32,kernel_size=(1,1),name='red_1_by_1')(red)\n",
        "    red = UpSampling2D(size=128,interpolation='bilinear',name='red_upsampling')(red)\n",
        "    red = tf.image.resize(red, [IMG_SIZE, IMG_SIZE])\n",
        "    # yellow\n",
        "    yellow = AveragePooling2D(pool_size=(2,2),name='yellow_pool')(base)\n",
        "    yellow = Conv2D(filters=32,kernel_size=(1,1),name='yellow_1_by_1')(yellow)\n",
        "    yellow = UpSampling2D(size=2,interpolation='bilinear',name='yellow_upsampling')(yellow)\n",
        "    yellow = tf.image.resize(yellow, [IMG_SIZE, IMG_SIZE])\n",
        "    # blue\n",
        "    blue = AveragePooling2D(pool_size=(4,4),name='blue_pool')(base)\n",
        "    blue = Conv2D(filters=32,kernel_size=(1,1),name='blue_1_by_1')(blue)\n",
        "    blue = UpSampling2D(size=4,interpolation='bilinear',name='blue_upsampling')(blue)\n",
        "    blue = tf.image.resize(blue, [IMG_SIZE, IMG_SIZE])\n",
        "    # green\n",
        "    green = AveragePooling2D(pool_size=(8,8),name='green_pool')(base)\n",
        "    green = Conv2D(filters=32,kernel_size=(1,1),name='green_1_by_1')(green)\n",
        "    green = UpSampling2D(size=8,interpolation='bilinear',name='green_upsampling')(green)\n",
        "    green = tf.image.resize(green, [IMG_SIZE, IMG_SIZE])\n",
        "    # base + red + yellow + blue + green\n",
        "    return tf.keras.layers.concatenate([base,red,yellow,blue,green])\n",
        "\n",
        "def last_conv_module(input_layer):\n",
        "    X = pyramid_feature_maps(input_layer)\n",
        "    X = Conv2D(filters=3,kernel_size=3,padding='same',name='last_conv_3_by_3')(X)\n",
        "    X = BatchNormalization(name='last_conv_3_by_3_batch_norm')(X)\n",
        "    X = Activation('sigmoid',name='last_conv_relu')(X)\n",
        "    return X"
      ],
      "metadata": {
        "id": "LnYFbrjZBM02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot(history):\n",
        "  acc = history.history['accuracy']\n",
        "  val_acc = history.history['val_accuracy']\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  epochs = range(1,len(acc)+1)\n",
        "\n",
        "  plt.title('Training and validation accuracy')\n",
        "  plt.plot(epochs, acc, color='blue', label='Train')\n",
        "  plt.plot(epochs, val_acc, color='orange', label='Val')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.legend()\n",
        "\n",
        "  _ = plt.figure()\n",
        "  plt.title('Training and validation loss')\n",
        "  plt.plot(epochs, loss, color='blue', label='Train')\n",
        "  plt.plot(epochs, val_loss, color='orange', label='Val')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()"
      ],
      "metadata": {
        "id": "h3aNpbOIBZ44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_test_image_df(train_images,n):\n",
        "  '''provide a list of image directory and n= number of image'''\n",
        "  image_df = pd.DataFrame()\n",
        "  for img_dir in train_images[:n]:\n",
        "    image_df = pd.concat([image_df, generate_one_test_image_df(img_dir)])\n",
        "  return image_df"
      ],
      "metadata": {
        "id": "M8iJi35OBZ7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_train_image_df(train_images):\n",
        "  '''provide a list of image directory and n= number of image you want , test image starts from 2300'''\n",
        "  image_df = pd.DataFrame()\n",
        "  for img_dir in train_images:\n",
        "    image_df = pd.concat([image_df, generate_one_test_image_df(img_dir)])\n",
        "  print('train', image_df.shape)\n",
        "  return image_df\n",
        "\n",
        "def create_test_image_df(train_images):\n",
        "  import pandas as pd\n",
        "  '''provide a list of image directory and n= number of image'''\n",
        "  image_df = pd.DataFrame()\n",
        "  for img_dir in train_images:\n",
        "    single_img_df = generate_one_test_image_df(img_dir)\n",
        "    image_df = pd.concat([image_df,single_img_df ])\n",
        "  print('test', image_df.shape)\n",
        "  return image_df"
      ],
      "metadata": {
        "id": "P_SA7aY0jisz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_data(df_train, df_test):\n",
        "  '''df_train, df_test > provide both test and train df with image data and label data'''\n",
        "  df_train = pd.read_csv(df_train) \n",
        "  df_test = pd.read_csv(df_test) \n",
        "  X_Train = df_train.drop(labels = [\"label\"], axis=1)\n",
        "  Y_Train = df_train[\"label\"].values\n",
        "\n",
        "  X_Test = df_test.drop(labels = [\"label\"], axis=1)\n",
        "  Y_Test = df_test[\"label\"].values\n",
        "\n",
        "  Y_Train = LabelEncoder().fit_transform(Y_Train)\n",
        "  Y_Test = LabelEncoder().fit_transform(Y_Test)\n",
        "\n",
        "  return X_Train,X_Test, Y_Train, Y_Test"
      ],
      "metadata": {
        "id": "Bd90XMhevRZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rf_accuracy(model, X, Y):\n",
        "  'provide the randomforest model, X: test/train data, y: test/train label '\n",
        "  prediction_test = model.predict(X)\n",
        "  Y_pred = prediction_test.reshape(int(prediction_test.shape[0]/40000),40000)\n",
        "  Y_true = Y.reshape(int(Y.shape[0]/40000),40000)\n",
        "  return metrics.accuracy_score(Y_true[0].reshape(200,200), Y_pred[0].reshape(200,200))"
      ],
      "metadata": {
        "id": "3l-k6ezk9Hyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# WIP"
      ],
      "metadata": {
        "id": "hazyGcpGH8qS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = np.array(train_img)\n",
        "train_labels = np.array(train_lab)\n",
        "print(train_images.shape, train_labels.shape)"
      ],
      "metadata": {
        "id": "Ka5m9Kbod0aB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test_img = cv2.imread('/content/content/processed_images/aachen_000000_000019.png', 0)\n",
        "#test_lab = cv2.imread('/content/content/processed_labels/aachen_000000_000019.png',0)\n",
        "\n",
        "test_img = train_images[210].reshape(dim)\n",
        "test_lab= train_labels[210].reshape(dim)\n",
        "train_img = train_images[68].reshape(dim)\n",
        "train_lab= train_labels[68].reshape(dim)"
      ],
      "metadata": {
        "id": "9bdOk11K4r0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_img(test_img)"
      ],
      "metadata": {
        "id": "8FuDK6pwdZqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_img(test_lab)"
      ],
      "metadata": {
        "id": "UmFmEaP2dZ0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fX = generate_one_test_image_df(train_images[201])\n",
        "fX_test = generate_one_test_image_df_a(test_img)\n",
        "fX_test.shape"
      ],
      "metadata": {
        "id": "BpX87NLRIAAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fX = generate_one_test_image_df(train_images[201])\n",
        "fX_train = generate_one_test_image_df_a(train_img)\n",
        "fX_train.shape"
      ],
      "metadata": {
        "id": "DxEeQ1ukgPXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print((X_Train.shape, Y_Train.shape),(X_Test.shape, Y_Test.shape))\n",
        "#prediction_test = model.predict(fX)"
      ],
      "metadata": {
        "id": "4IrroKTu29O3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H5josExmOXi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2"
      ],
      "metadata": {
        "id": "rvGsEQ-ZzA_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_img = []\n",
        "dim = (200,200)\n",
        "for img in train_images:\n",
        "  m = cv2.imread(img, 0)\n",
        "  train_img.append(cv2.resize(m, dim).reshape(-1))\n",
        "print(len(train_img), train_img[0].shape)"
      ],
      "metadata": {
        "id": "bbW2YZ5ISEeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_img(train_img[0].reshape(dim))"
      ],
      "metadata": {
        "id": "wT8dMhUNTtgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = np.array(train_img)"
      ],
      "metadata": {
        "id": "6QBdTPFzgCZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_img), type(train_img[0]),train_img[0].shape"
      ],
      "metadata": {
        "id": "Cljs6ngRLZFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_images), type(train_images[0]),train_images[0].shape"
      ],
      "metadata": {
        "id": "dAqs6PNuLZIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gLo7qDKTLZLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_lab = []\n",
        "dim = (200,200)\n",
        "for img in train_labels:\n",
        "  m = cv2.imread(img, 0)\n",
        "  train_lab.append(cv2.resize(m, dim).reshape(-1))\n",
        "print(len(train_lab), train_lab[0].shape)"
      ],
      "metadata": {
        "id": "O9MdCuVsS6iW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_lab)\n",
        "train_labels = np.array(train_lab)\n",
        "train_labels.shape"
      ],
      "metadata": {
        "id": "FQkH6Swzzj6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = np.array(train_img)\n",
        "train_labels = np.array(train_lab)\n",
        "print(train_images.shape, train_labels.shape)"
      ],
      "metadata": {
        "id": "Wz_UDUT_U_xX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_img(train_lab[0].reshape(dim))"
      ],
      "metadata": {
        "id": "B7ZDQ9xcS6k2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_images = np.array(train_img)\n",
        "#train_labels = np.array(train_lab)\n",
        "print(train_images.shape, train_labels.shape)\n",
        "print(int(train_images.shape[0]*.7))"
      ],
      "metadata": {
        "id": "jHPgNFi7VkLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dim = (200,200)"
      ],
      "metadata": {
        "id": "fAnkb82TKZiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a data frame with test data image - using a numpy array\n",
        "def create_img_df(img_array, dim):\n",
        "  df_image = pd.DataFrame()\n",
        "  train_img = []\n",
        "\n",
        "for img in train_images:\n",
        "  m = cv2.imread(img, 0)\n",
        "  train_img.append(cv2.resize(m, dim).reshape(-1))\n",
        "print(len(train_img), train_img[0].shape)\n",
        "\n",
        "  df_image = pd.DataFrame() \n",
        "  for img in img_array[:100]:\n",
        "    df1 = pd.DataFrame()\n",
        "    #img = cv2.imread(image, 0)\n",
        "    df1['gray']= img/255\n",
        "    #df1['Image_Name'] = image.split('/')[-1]\n",
        "\n",
        "    _,thresh2  = cv2.threshold(img, 80, 255, cv2.THRESH_BINARY_INV)\n",
        "    thresh2 = thresh2/255\n",
        "    df1['binay_inv']= thresh2.reshape(-1)\n",
        "    df1['adaptive_thresh']=(cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,11, 11)/255).reshape(-1)\n",
        "    df1['gabor1'] = gabor_feature_extraction(img,.8, .05 ).reshape(-1)\n",
        "    df1['gabor2'] = gabor_feature_extraction(img,1.6, .5 ).reshape(-1)\n",
        "    df1['blur'], df1['laplacian'], df1['sobelx'], df1['canny'] = preprocess_image(img)\n",
        "    df_image = pd.concat([df_image, df1])\n",
        "    return df_image\n",
        "train_image = create_img_df(train_images)\n",
        "test_image = create_img_df(train_images)\n",
        "print(df_image.shape)"
      ],
      "metadata": {
        "id": "JyiSW3GnjnVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating test mask image Data Frame\n",
        "%%time\n",
        "df_mask = pd.DataFrame() \n",
        "for mask in train_labels[:100]:\n",
        "  df2 = pd.DataFrame()\n",
        "  #msk = cv2.imread(mask, 0)\n",
        "  df2['label'] = mask #msk.reshape(-1) \n",
        "  #df2['Mask_Name'] = mask.split('/')[-1]  \n",
        "  df_mask = pd.concat([df_mask, df2])\n",
        "print(df_mask.shape)"
      ],
      "metadata": {
        "id": "TsuGEz7ywxkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_image.head()"
      ],
      "metadata": {
        "id": "twuGHANAwxp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_mask.head()"
      ],
      "metadata": {
        "id": "0RgYil_50lAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([df_image, df_mask], axis=1)\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "f4ygZJZZ1_T9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1"
      ],
      "metadata": {
        "id": "cCsykJ2qUSY7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Now, add a column in the data frame for the Labels\n",
        "#For this, we need to import the labeled image\n",
        "labeled_img = cv2.imread(lab)\n",
        "#Remember that you can load an image with partial labels \n",
        "#But, drop the rows with unlabeled data\n",
        "\n",
        "labeled_img = cv2.cvtColor(labeled_img, cv2.COLOR_BGR2GRAY)\n",
        "labeled_img1 = labeled_img.reshape(-1)\n"
      ],
      "metadata": {
        "id": "Kl8rpgFVwCdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_img1.shape"
      ],
      "metadata": {
        "id": "Y9hXL4e6vPiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "Y = LabelEncoder().fit_transform(labeled_img1)"
      ],
      "metadata": {
        "id": "AhA6nqbPvPtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y.shape"
      ],
      "metadata": {
        "id": "L03PnDg0vibh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ")"
      ],
      "metadata": {
        "id": "rCWw0O_hviiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_img_data = df.drop(labels = [\"Labels\"], axis=1) #Use for prediction\n",
        "#df.to_csv(\"Gabor.csv\")\n",
        "df = df[df.Labels != 0]"
      ],
      "metadata": {
        "id": "5mpc7b02wCg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the dependent variable that needs to be predicted (labels)\n",
        "Y = df[\"Labels\"].values\n",
        "\n",
        "#Encode Y values to 0, 1, 2, 3, .... (NOt necessary but makes it easy to use other tools like ROC plots)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "Y = LabelEncoder().fit_transform(Y)\n",
        "\n",
        "\n",
        "#Define the independent variables\n",
        "X = df.drop(labels = [\"Labels\"], axis=1) "
      ],
      "metadata": {
        "id": "CclVYTGmLjCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split data into train and test to verify accuracy after fitting the model. \n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=20)\n",
        "\n"
      ],
      "metadata": {
        "id": "QFzYSLgeLjFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features.shape, Y.shape"
      ],
      "metadata": {
        "id": "kyHdtZiHv0Ld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IfK64jjZv0N-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LvcDxVq6v0Q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# Instantiate model with n number of decision trees\n",
        "model = RandomForestClassifier(n_estimators = 20, random_state = 42)\n",
        "\n",
        "# Train the model on training data\n",
        "model.fit(features, Y)"
      ],
      "metadata": {
        "id": "3UlI1atsLjIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_list = list(X.columns)\n",
        "feature_imp = pd.Series(model.feature_importances_,index=feature_list).sort_values(ascending=False)\n",
        "print(feature_imp)"
      ],
      "metadata": {
        "id": "pwrd_OXDLjLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_RF = model.predict(features)"
      ],
      "metadata": {
        "id": "DEErx15mwJ7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_RF.shape"
      ],
      "metadata": {
        "id": "zr4VigQVwJ-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(prediction_RF.reshape(gray.shape))"
      ],
      "metadata": {
        "id": "4g9LO-otwKBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lab = cv2.imread('/content/content/processed_labels/aachen_000159_000019.png',0)\n",
        "print(lab.shape)"
      ],
      "metadata": {
        "id": "jMRK2XxfwKE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(lab)"
      ],
      "metadata": {
        "id": "f2_mkt9DwKHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img1 = train_images[11]\n",
        "lab1 = train_labels[11]\n",
        "lab1 = cv2.imread(lab1,0)\n",
        "img1 = cv2.imread(img1,0)\n",
        "print(lab1.shape, img1.shape)"
      ],
      "metadata": {
        "id": "a7H4Wgw4xFus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(img1)"
      ],
      "metadata": {
        "id": "BLzXet14xFxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(lab1)"
      ],
      "metadata": {
        "id": "O_6nPirExF0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VytN3dk4xF3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evl"
      ],
      "metadata": {
        "id": "xB6BhtLyx2oo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gabor1 = gabor_feature_extraction(img1,.8, .05 )\n",
        "gabor2 = gabor_feature_extraction(img1,1.6, .5 )\n",
        "blur1, blur2, sobele, canny = preprocess_image(img1)\n",
        "print(blur1.shape, blur2.shape, sobele.shape, canny.shape )\n",
        "print(gabor1.shape, gabor2.shape)"
      ],
      "metadata": {
        "id": "KWf9sj7exF6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = np.hstack((gray1, gabor1, gabor2, blur1, blur2, sobele, canny))\n",
        "features.shape"
      ],
      "metadata": {
        "id": "s8wExb7xxF9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lab1.shape"
      ],
      "metadata": {
        "id": "ckhw-2B4xGAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B3c1qsFPxGCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0SbpT0zQxGFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_RF = model.predict(features)"
      ],
      "metadata": {
        "id": "U3Tzh2FzMZfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(prediction_RF.reshape(gray.shape))"
      ],
      "metadata": {
        "id": "J362DmiZyRnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(lab1)"
      ],
      "metadata": {
        "id": "JHtj_ry9yRqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2f1A5kXCyRs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K8U6UNDryRvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "#Print the prediction accuracy\n",
        "#Check accuracy on test dataset. If this is too low compared to train it indicates overfitting on training data.\n",
        "print (\"Accuracy using Random Forest= \", metrics.accuracy_score(y_test, prediction_RF))"
      ],
      "metadata": {
        "id": "zZc0OU7cMbSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = load_img('/content/aachen_000000_000019.png')\n",
        "display_img(i)"
      ],
      "metadata": {
        "id": "0LUuK4FXMbYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "0WUMhdD1SnST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PjK6cjZlMbaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "/content/content/processed_images/dusseldorf_000143_000019.png\n",
        "/content/content/processed_labels/dusseldorf_000143_000019.png"
      ],
      "metadata": {
        "id": "C6kaCKy-pTJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, lab"
      ],
      "metadata": {
        "id": "36ps1Q3Zo8RB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n"
      ],
      "metadata": {
        "id": "NjbUst4ppUde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(img):\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    \n",
        "    # Apply Canny edge detection\n",
        "    edges = cv2.Canny(gray, 100, 200)\n",
        "    \n",
        "    # Apply Gaussian blur to reduce noise\n",
        "    blur = cv2.GaussianBlur(edges, (5, 5), 0)\n",
        "    \n",
        "    return blur"
      ],
      "metadata": {
        "id": "Frgj8ryJpnzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def npreprocess_image(img):\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY).reshape(-1,1)\n",
        "    sobels = sobel(gray)\n",
        "    \n",
        "    # Apply Canny edge detection\n",
        "    edges = cv2.Canny(gray, 100, 200)\n",
        "    \n",
        "    # Apply Gaussian blur to reduce noise\n",
        "    blur = cv2.GaussianBlur(edges, (5, 5), 0)\n",
        "    \n",
        "    return np.hstack((gray, sobels,edges,blur))"
      ],
      "metadata": {
        "id": "fA5NZfMH4RLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(img):\n",
        "    # Extract RGB color features\n",
        "    r, g, b = cv2.split(img)\n",
        "    features = np.dstack((r, g, b)).reshape(-1, 3)\n",
        "    \n",
        "    # Extract texture features using Gabor filter\n",
        "    kernel = cv2.getGaborKernel((5, 5), 4, np.pi/4, 8, 0.5, 0, ktype=cv2.CV_32F)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    filtered = cv2.filter2D(gray, cv2.CV_8UC3, kernel)\n",
        "    texture_features = filtered.reshape(-1, 1)\n",
        "    \n",
        "    # Combine color and texture features\n",
        "    features = np.hstack((features, texture_features))\n",
        "    \n",
        "    return features"
      ],
      "metadata": {
        "id": "MNK_9amPpn2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def segment_image(img):\n",
        "    # Preprocess the image\n",
        "    preprocessed = preprocess_image(img)\n",
        "    \n",
        "    # Extract features from the preprocessed image\n",
        "    features = extract_features(img)\n",
        "    \n",
        "    # Cluster the features using k-means\n",
        "    kmeans = KMeans(n_clusters=3, random_state=0).fit(features)\n",
        "    labels = kmeans.labels_.reshape(preprocessed.shape[:2])\n",
        "    \n",
        "    # Train a Random Forest classifier on the labeled features\n",
        "    flat_features = features.reshape(-1, features.shape[-1])\n",
        "    clf = RandomForestClassifier(n_estimators=50, random_state=0)\n",
        "    clf.fit(flat_features, labels.ravel())\n",
        "    \n",
        "    # Predict the segmentation for the preprocessed image\n",
        "    flat_preprocessed = preprocessed.reshape(-1, preprocessed.shape[-1])\n",
        "    segmentation = clf.predict(flat_preprocessed).reshape(preprocessed.shape[:2])\n",
        "    \n",
        "    # Convert the segmentation to a binary mask\n",
        "    mask = np.zeros_like(segmentation)\n",
        "    mask[segmentation == 1] = 255\n",
        "    \n",
        "    return mask"
      ],
      "metadata": {
        "id": "MTV8Bwogpn5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load an example image\n",
        "img = cv2.imread('/content/content/processed_images/dusseldorf_000143_000019.png')"
      ],
      "metadata": {
        "id": "VrAQ7mHypn8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Preprocess the image\n",
        "preprocessed = preprocess_image(img)\n",
        "npreprocessed = npreprocess_image(img)\n",
        "print(preprocessed.shape, npreprocessed.shape)"
      ],
      "metadata": {
        "id": "lVe4LTA5qEQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract features from the preprocessed image\n",
        "features = extract_features(img)\n",
        "features.shape"
      ],
      "metadata": {
        "id": "5v8BzWOFqXiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cluster the features using k-means\n",
        "kmeans = KMeans(n_clusters=21, random_state=0).fit(features)\n",
        "labels = kmeans.labels_.reshape(preprocessed.shape[:2])\n",
        "labels.shape"
      ],
      "metadata": {
        "id": "BO842IGgque-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed.shape[:2]"
      ],
      "metadata": {
        "id": "mkjs7aUW7B-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cluster the features using k-means\n",
        "kmeans = KMeans(n_clusters=21, random_state=0).fit(features)\n",
        "labels = kmeans.labels_.reshape(npreprocessed.shape[:2])\n",
        "labels.shape"
      ],
      "metadata": {
        "id": "kghPRnmb646b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels[10]"
      ],
      "metadata": {
        "id": "VXwwckSZqukV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flat_features = features.reshape(-1, features.shape[-1])\n",
        "print(flat_features.shape)"
      ],
      "metadata": {
        "id": "60nrFxflrAeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = RandomForestClassifier(n_estimators=50, random_state=0)"
      ],
      "metadata": {
        "id": "YknkhHYarAg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels.ravel().shape"
      ],
      "metadata": {
        "id": "h1_R3Qg5rbDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(flat_features, labels.ravel())"
      ],
      "metadata": {
        "id": "aKCSNj5orTrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "flat_features = features.reshape(-1, features.shape[-1])\n",
        "print(flat_features.shape)"
      ],
      "metadata": {
        "id": "GGlnvVdvtnRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the segmentation for the preprocessed image\n",
        "#flat_preprocessed = preprocessed.reshape(-1, preprocessed.shape[-1])\n",
        "flat_preprocessed = preprocessed.reshape(-1, preprocessed.shape[-1])\n",
        "flat_preprocessed.shape"
      ],
      "metadata": {
        "id": "rCBwrZHFrvIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#segmentation = clf.predict(flat_preprocessed).reshape(preprocessed.shape[:2])   \n",
        "segmentation = clf.predict(npreprocessed)\n",
        "\n",
        "segmentation.shape"
      ],
      "metadata": {
        "id": "FX0Uh4X1rvLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "segmentation = segmentation.reshape(preprocessed.shape[:2]) \n",
        "segmentation.shape"
      ],
      "metadata": {
        "id": "jLoAL_-B8MOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(segmentation)"
      ],
      "metadata": {
        "id": "fTqG6RYyyx0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the segmentation to a binary mask\n",
        "mask = np.zeros_like(segmentation)\n",
        "mask[segmentation == 1] = 255"
      ],
      "metadata": {
        "id": "4pN7FMSGrvNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "segmentation = clf.predict(flat_preprocessed).reshape(preprocessed.shape[:2])\n",
        "\n",
        "# Convert the segmentation to a binary mask\n",
        "mask = np.zeros_like(segmentation)\n",
        "mask[segmentation == 1] = 255\n"
      ],
      "metadata": {
        "id": "baRZGRcQqXos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9nkXV8BWqETg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Segment the image\n",
        "##mask = segment_image(img)\n",
        "\n"
      ],
      "metadata": {
        "id": "X5ZiZgNvpn_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask.shape, img.shape"
      ],
      "metadata": {
        "id": "MFgTMFQ1vVLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(img)"
      ],
      "metadata": {
        "id": "i3WpiOBhve49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(mask)"
      ],
      "metadata": {
        "id": "6fOz8ihjvi8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the results\n",
        "cv2.imshow('Input Image', img)\n",
        "cv2.imshow('Segmentation Mask', mask)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "Si-OjAnbpoDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IabTxXxZzG_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8LwvkhEKzHCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(img):\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY).reshape(-1,1)\n",
        "    sobels = sobel(gray)\n",
        "    \n",
        "    # Apply Canny edge detection\n",
        "    edges = cv2.Canny(gray, 100, 200)\n",
        "    \n",
        "    # Apply Gaussian blur to reduce noise\n",
        "    blur = cv2.GaussianBlur(edges, (5, 5), 0)\n",
        "    \n",
        "    return np.hstack((gray, sobels,edges,blur))"
      ],
      "metadata": {
        "id": "Gn5vTQ1PzHFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = preprocess_image(img)\n"
      ],
      "metadata": {
        "id": "5DotSurPzHgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.shape"
      ],
      "metadata": {
        "id": "_uLTyRMq4MJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "gray.shape\n",
        "g= gray.reshape(-1, 1)\n",
        "g.shape"
      ],
      "metadata": {
        "id": "bn-WZ2uzzHi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SOBEL\n",
        "s = sobel(g)\n",
        "#s = s.reshape(-1,1)\n",
        "s.shape"
      ],
      "metadata": {
        "id": "V8SVnV8u1cwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Apply Canny edge detection\n",
        "edges = cv2.Canny(gray, 100, 200)\n",
        "edges.shape\n",
        "e= edges.reshape(-1,1)"
      ],
      "metadata": {
        "id": "5DYpoSydzayC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blur = cv2.GaussianBlur(edges, (5, 5), 0)\n",
        "blur.shape\n",
        "b= blur.reshape(-1,1)"
      ],
      "metadata": {
        "id": "ll2Hyh0GzHli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blur.reshape(-1).shape"
      ],
      "metadata": {
        "id": "n58EgUl7zXBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blur.shape"
      ],
      "metadata": {
        "id": "4pvRXRxz0AOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = np.hstack((g, e,b,s))\n",
        "f.shape"
      ],
      "metadata": {
        "id": "qNcEAGUqzyAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "segmentation = clf.predict(f).reshape(preprocessed.shape[:2])\n",
        "    "
      ],
      "metadata": {
        "id": "t-uNC0GM0HAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask = np.zeros_like(segmentation)\n",
        "mask[segmentation == 1] = 255"
      ],
      "metadata": {
        "id": "7kAOVmzQ2Jp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(mask)"
      ],
      "metadata": {
        "id": "P_1kiryS2Jsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lab = train_label[0]\n",
        "lab = cv2.imread(lab, 0)\n"
      ],
      "metadata": {
        "id": "jroX29UB46pe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(lab)\n"
      ],
      "metadata": {
        "id": "74qm9w5p2Jvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    segmentation = clf.predict(flat_preprocessed).reshape(preprocessed.shape[:2])\n",
        "    \n",
        "    # Convert the segmentation to a binary mask\n",
        "    mask = np.zeros_like(segmentation)\n",
        "    mask[segmentation == 1] = 255\n",
        "    \n",
        "    return mask\n",
        "\n",
        "# Load an example image\n",
        "img = cv2.imread('example.jpg')\n",
        "\n",
        "# Segment the image\n",
        "mask = segment_image(img)\n",
        "\n",
        "# Display the results\n",
        "cv2.imshow('Input Image', img)\n",
        "cv2.imshow('Segmentation Mask', mask)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "5af0w3bl2Jyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F2rbJri5sJMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3"
      ],
      "metadata": {
        "id": "1rZorVuzutIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = np.hstack((gray1, gabor1, gabor2, blur1, blur2, sobele, canny))\n",
        "features.shape"
      ],
      "metadata": {
        "id": "MyyaujZTt-73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KFCVnmesvvzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a data frame with test data image - using a numpy array\n",
        "%%time\n",
        "a = []\n",
        "for img in train_images[:10]:\n",
        "  m = img.reshape(-1,1)\n",
        "\n",
        "  _,thresh2  = cv2.threshold(img, 80, 255, cv2.THRESH_BINARY_INV)\n",
        "  thresh2 = thresh2.reshape(-1,1)\n",
        "\n",
        "  adaptive_thresh=(cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,11, 11)/255).reshape(-1,1)\n",
        "  f = np.hstack((m, thresh2, adaptive_thresh))\n",
        "  a.append(f)\n"
      ],
      "metadata": {
        "id": "lbfkHiYmt-_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(a)"
      ],
      "metadata": {
        "id": "BE6bOUFxvpQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b = np.array(a)"
      ],
      "metadata": {
        "id": "xQG6oVm3vxcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b.shape"
      ],
      "metadata": {
        "id": "yw15lyKhv3Pe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import training classifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "## Instantiate model with n number of decision trees\n",
        "rf = RandomForestClassifier(n_estimators = 50, random_state = 42)"
      ],
      "metadata": {
        "id": "MDE6oXb2v3yW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, Y)"
      ],
      "metadata": {
        "id": "TuUAaOnwwGr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = load_img('/content/content/processed_labels/aachen_000000_000019.png')"
      ],
      "metadata": {
        "id": "bvmNQgVawGwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_img(a)"
      ],
      "metadata": {
        "id": "XaegmaCOKENP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(a)"
      ],
      "metadata": {
        "id": "ZjTT0ecGKHds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pnf0BBV5KPmZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}