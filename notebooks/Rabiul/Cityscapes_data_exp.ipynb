{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DataScienceAndEngineering/deep-learning-final-project-project-sidewalk/blob/rabiul/notebooks/Rabiul/Cityscapes_data_exp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PX5satu0Mg5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "b5Wmn2-ho3KI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Lib"
      ],
      "metadata": {
        "id": "XGHyHnxfMiFF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGYGKh7-n0l2"
      },
      "outputs": [],
      "source": [
        "#\n",
        "%%time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import PIL\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "from os.path import join, isdir\n",
        "from os import listdir, rmdir\n",
        "from shutil import move, rmtree, make_archive\n",
        "\n",
        "import cv2\n",
        "import glob\n",
        "import pickle\n",
        "\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers import Dense, Input, Dropout, Activation, Flatten, BatchNormalization, ReLU, LeakyReLU, concatenate\n",
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, AveragePooling2D, GlobalAveragePooling2D, Add"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#drive.mount('/gdrive')\n",
        "drive_root = '/content/drive/MyDrive/DL_Project/'\n",
        "\n",
        "\n",
        "COLAB_DIR = '/content/'\n",
        "GT_DIR = COLAB_DIR + 'gtFine/'\n",
        "IMG_DIR = COLAB_DIR + 'leftImg8bit/'"
      ],
      "metadata": {
        "id": "VAJX94nU0S5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initial Data processing"
      ],
      "metadata": {
        "id": "3IYRCuZwIZMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!gdown --id 1mIDcIT_7vP9cQDl_D8zgX9g4Pe18-g5q -O leftImg8bit_trainvaltest.zip\n",
        "!gdown --id 1ExL_qMIykksn_kpxZxi5DvltBgX-gHVn -O gtFine_trainvaltest.zip"
      ],
      "metadata": {
        "id": "l_PwhDStpdyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!unzip /content/drive/MyDrive/DL_Project/Data/gtFine_trainvaltest.zip\n",
        "!unzip /content/drive/MyDrive/DL_Project/Data/leftImg8bit_trainvaltest.zip"
      ],
      "metadata": {
        "id": "BjA41h_PoLsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "device = torch.device(device)\n",
        "print(device)"
      ],
      "metadata": {
        "id": "TKoj0JvQuaP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# collapse child directories\n",
        "for parent in listdir(GT_DIR):\n",
        "    parent_dir = GT_DIR + parent\n",
        "    for child in listdir(parent_dir):\n",
        "        if isdir(join(parent_dir, child)):\n",
        "            keep = glob.glob(join(parent_dir, child) + '/*_gtFine_color.png')\n",
        "            keep = [f.split('/')[-1] for f in keep]\n",
        "            for filename in list(set(listdir(join(parent_dir, child))) & set(keep)):\n",
        "                move(join(parent_dir, child, filename), join(parent_dir, filename))\n",
        "            rmtree(join(parent_dir, child))\n",
        "\n",
        "for parent in listdir(IMG_DIR):\n",
        "    parent_dir = IMG_DIR + parent\n",
        "    for child in listdir(parent_dir):\n",
        "        if isdir(join(parent_dir, child)):\n",
        "            for filename in listdir(join(parent_dir, child)):\n",
        "                move(join(parent_dir, child, filename), join(parent_dir, filename))\n",
        "            rmtree(join(parent_dir, child))"
      ],
      "metadata": {
        "id": "cymFa4ZEz9eM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# process anr archive image in smaller size\n",
        "IMG_SHAPE = 299, 299\n",
        "\n",
        "gt_train_paths = [GT_DIR+'train/' + path for path in listdir(GT_DIR+'train/')]\n",
        "gt_test_paths = [GT_DIR+'test/' + path for path in listdir(GT_DIR+'test/')]\n",
        "gt_val_paths = [GT_DIR+'val/' + path for path in listdir(GT_DIR+'val/')]\n",
        "gt_paths = gt_train_paths + gt_test_paths + gt_val_paths\n",
        "\n",
        "im_train_paths = [IMG_DIR+'train/' + path for path in listdir(IMG_DIR+'train/')]\n",
        "im_test_paths = [IMG_DIR+'test/' + path for path in listdir(IMG_DIR+'test/')]\n",
        "im_val_paths = [IMG_DIR+'val/' + path for path in listdir(IMG_DIR+'val/')]\n",
        "im_paths = im_train_paths + im_test_paths + im_val_paths\n",
        "\n",
        "def resize_image(path):\n",
        "    img = Image.open(path)\n",
        "    img.thumbnail(IMG_SHAPE)\n",
        "    out_file = join(path)\n",
        "    img.save(out_file, 'PNG')\n",
        "\n",
        "for img in gt_paths + im_paths:\n",
        "    resize_image(img)\n",
        "#saving the data for future use, avoding pre_processing task over and over \n",
        "make_archive('gtFine', 'zip', GT_DIR) \n",
        "make_archive('leftImg', 'zip', IMG_DIR)"
      ],
      "metadata": {
        "id": "Bs4aHv_O2Eyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Re-Load Pre_processed Data"
      ],
      "metadata": {
        "id": "vEaBXVZxM5-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#PreProcessed data is located in my personal Google Drive, its publically available. anyone can download it. \n",
        "!gdown --id 1kkmpZOGdncxjI6NEvFmZh85Wn2nrW3rK -O gtFine.zip\n",
        "!gdown --id 14MXcx8G3yRLljLb1K0PYX7yCl5viPP-8 -O leftImg.zip\n"
      ],
      "metadata": {
        "id": "gZT9OeDfTpWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!unzip /content/gtFine.zip -d '/content/gtFine/'\n",
        "!unzip /content/leftImg.zip -d '/content/leftImg/'"
      ],
      "metadata": {
        "id": "JR3X6yg6WCZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize image pixels\n",
        "%%time\n",
        "IMG_SIZE = 299\n",
        "BATCH_SIZE = 32\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "GT_DIR = COLAB_DIR + 'gtFine/'\n",
        "IMG_DIR = COLAB_DIR + 'leftImg/'\n",
        "\n",
        "def load_and_preprocess_image(path):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE])\n",
        "    img /= 255.0\n",
        "    return img\n",
        "\n",
        "def get_image_paths(dir):\n",
        "    return sorted([dir + path for path in listdir(dir)])\n",
        "\n",
        "# create tf.Dataset objects\n",
        "gt_train_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(GT_DIR+'train/'))\n",
        "gt_val_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(GT_DIR+'val/'))\n",
        "gt_test_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(GT_DIR+'test/'))\n",
        "\n",
        "gt_train_ds = gt_train_ds.map(load_and_preprocess_image)\n",
        "gt_val_ds = gt_val_ds.map(load_and_preprocess_image)\n",
        "gt_test_ds = gt_test_ds.map(load_and_preprocess_image)\n",
        "\n",
        "im_train_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(IMG_DIR+'train/'))\n",
        "im_val_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(IMG_DIR+'val/'))\n",
        "im_test_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(IMG_DIR+'test/'))\n",
        "\n",
        "im_train_ds = im_train_ds.map(load_and_preprocess_image)\n",
        "im_val_ds = im_val_ds.map(load_and_preprocess_image)\n",
        "im_test_ds = im_test_ds.map(load_and_preprocess_image)"
      ],
      "metadata": {
        "id": "L0w8jSOaZJix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s_B27b8NZJlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize Data"
      ],
      "metadata": {
        "id": "F69-KQ5xZcZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_images(img, gt, pred):\n",
        "    if pred is not None:\n",
        "        fig, axes = plt.subplots(1, 3, figsize=(12, 8))\n",
        "    else:\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(8, 8))\n",
        "\n",
        "    axes[0].imshow(img)\n",
        "    axes[0].set_title('Actual Image')\n",
        "\n",
        "    axes[1].imshow(gt)\n",
        "    axes[1].set_title('Masked Image')\n",
        "    \n",
        "    if pred is not None:\n",
        "        axes[2].imshow(pred)\n",
        "        axes[2].set_title('Predicted Image')"
      ],
      "metadata": {
        "id": "brniAA9N2E7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for img, gt in list(zip(im_train_ds.take(2), gt_train_ds.take(2))):\n",
        "    visualize_images(img, gt, None)"
      ],
      "metadata": {
        "id": "7oMIb8aA2E-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PQcLkHWe2FBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "bqOkQFb6O8Gk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(X,filters,block):\n",
        "    # resiudal block with dilated convolutions\n",
        "    # add skip connection at last after doing convoluion\n",
        "\n",
        "    b = 'block_'+str(block)+'_'\n",
        "    f1,f2,f3 = filters\n",
        "    X_skip = X\n",
        "\n",
        "    # block_a\n",
        "    X = Conv2D(filters=f1,kernel_size=(1,1),dilation_rate=(1,1),\n",
        "               padding='same',kernel_initializer='he_normal',name=b+'a')(X)\n",
        "    X = BatchNormalization(name=b+'batch_norm_a')(X)\n",
        "    X = LeakyReLU(alpha=0.2,name=b+'leakyrelu_a')(X)\n",
        "    # block_b\n",
        "    X = Conv2D(filters=f2,kernel_size=(3,3),dilation_rate=(2,2),\n",
        "               padding='same',kernel_initializer='he_normal',name=b+'b')(X)\n",
        "    X = BatchNormalization(name=b+'batch_norm_b')(X)\n",
        "    X = LeakyReLU(alpha=0.2,name=b+'leakyrelu_b')(X)\n",
        "    # block_c\n",
        "    X = Conv2D(filters=f3,kernel_size=(1,1),dilation_rate=(1,1),\n",
        "               padding='same',kernel_initializer='he_normal',name=b+'c')(X)\n",
        "    X = BatchNormalization(name=b+'batch_norm_c')(X)\n",
        "    # skip_conv\n",
        "    X_skip = Conv2D(filters=f3,kernel_size=(3,3),padding='same',name=b+'skip_conv')(X_skip)\n",
        "    X_skip = BatchNormalization(name=b+'batch_norm_skip_conv')(X_skip)\n",
        "    # block_c + skip_conv\n",
        "    X = Add(name=b+'add')([X,X_skip])\n",
        "    X = ReLU(name=b+'relu')(X)\n",
        "    return X\n",
        "    \n",
        "def base_feature_maps(input_layer):\n",
        "    # base covolution module to get input image feature maps \n",
        "    \n",
        "    # block_1\n",
        "    base = conv_block(input_layer,[16,16,32],'1')\n",
        "    # block_2\n",
        "    base = conv_block(base,[16,16,32],'2')\n",
        "    return base\n",
        "\n",
        "def pyramid_feature_maps(input_layer):\n",
        "    # pyramid pooling module\n",
        "    \n",
        "    base = base_feature_maps(input_layer)\n",
        "    # red\n",
        "    red = GlobalAveragePooling2D(name='red_pool')(base)\n",
        "    red = tf.keras.layers.Reshape((1,1,32))(red)\n",
        "    red = Conv2D(filters=32,kernel_size=(1,1),name='red_1_by_1')(red)\n",
        "    red = UpSampling2D(size=128,interpolation='bilinear',name='red_upsampling')(red)\n",
        "    red = tf.image.resize(red, [IMG_SIZE, IMG_SIZE])\n",
        "    # yellow\n",
        "    yellow = AveragePooling2D(pool_size=(2,2),name='yellow_pool')(base)\n",
        "    yellow = Conv2D(filters=32,kernel_size=(1,1),name='yellow_1_by_1')(yellow)\n",
        "    yellow = UpSampling2D(size=2,interpolation='bilinear',name='yellow_upsampling')(yellow)\n",
        "    yellow = tf.image.resize(yellow, [IMG_SIZE, IMG_SIZE])\n",
        "    # blue\n",
        "    blue = AveragePooling2D(pool_size=(4,4),name='blue_pool')(base)\n",
        "    blue = Conv2D(filters=32,kernel_size=(1,1),name='blue_1_by_1')(blue)\n",
        "    blue = UpSampling2D(size=4,interpolation='bilinear',name='blue_upsampling')(blue)\n",
        "    blue = tf.image.resize(blue, [IMG_SIZE, IMG_SIZE])\n",
        "    # green\n",
        "    green = AveragePooling2D(pool_size=(8,8),name='green_pool')(base)\n",
        "    green = Conv2D(filters=32,kernel_size=(1,1),name='green_1_by_1')(green)\n",
        "    green = UpSampling2D(size=8,interpolation='bilinear',name='green_upsampling')(green)\n",
        "    green = tf.image.resize(green, [IMG_SIZE, IMG_SIZE])\n",
        "    # base + red + yellow + blue + green\n",
        "    return tf.keras.layers.concatenate([base,red,yellow,blue,green])\n",
        "\n",
        "def last_conv_module(input_layer):\n",
        "    X = pyramid_feature_maps(input_layer)\n",
        "    X = Conv2D(filters=3,kernel_size=3,padding='same',name='last_conv_3_by_3')(X)\n",
        "    X = BatchNormalization(name='last_conv_3_by_3_batch_norm')(X)\n",
        "    X = Activation('sigmoid',name='last_conv_relu')(X)\n",
        "    return X"
      ],
      "metadata": {
        "id": "DzhcVr512FEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "input_shape = list(im_train_ds.take(1))[0].shape\n",
        "input_layer = tf.keras.Input(shape=input_shape, name='input')\n",
        "output_layer = last_conv_module(input_layer)\n",
        "\n",
        "model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Tqitrrk_2FHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yVlsnYWt2FKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "SmDb8up8PE0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train_ds = tf.data.Dataset.zip((im_train_ds, gt_train_ds))\n",
        "train_ds = train_ds.cache().batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "val_ds = tf.data.Dataset.zip((im_val_ds, gt_val_ds))\n",
        "val_ds = val_ds.cache().batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "test_ds = tf.data.Dataset.zip((im_test_ds, gt_test_ds))\n",
        "test_ds = test_ds.cache().batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "oejnRf5xPB3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "checkpoint_path = drive_root+'pspnet/cp.ckpt'\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2)\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics='accuracy')\n",
        "history = model.fit(train_ds, validation_data=val_ds, epochs=5, \n",
        "                    callbacks=[cp_callback, es_callback])\n",
        "model.save(drive_root + 'pspnet_trained.h5')"
      ],
      "metadata": {
        "id": "a1lSg-v1PB5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot(history):\n",
        "  acc = history.history['accuracy']\n",
        "  val_acc = history.history['val_accuracy']\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  epochs = range(1,len(acc)+1)\n",
        "\n",
        "  plt.title('Training and validation accuracy')\n",
        "  plt.plot(epochs, acc, color='blue', label='Train')\n",
        "  plt.plot(epochs, val_acc, color='orange', label='Val')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.legend()\n",
        "\n",
        "  _ = plt.figure()\n",
        "  plt.title('Training and validation loss')\n",
        "  plt.plot(epochs, loss, color='blue', label='Train')\n",
        "  plt.plot(epochs, val_loss, color='orange', label='Val')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  \n",
        "plot(history)"
      ],
      "metadata": {
        "id": "SZLKNl64OPdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(test_ds)\n",
        "print('Test Data Accuracy: ', acc)"
      ],
      "metadata": {
        "id": "7hFaFPxrOPgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9974eucIOPjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JoHjsrt5OWfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_test_ds = model.predict(train_ds)\n",
        "\n",
        "for img, gt, pred in list(zip(im_train_ds.take(5), gt_train_ds.take(5), pred_test_ds)):\n",
        "    visualize_images(img, gt, pred)"
      ],
      "metadata": {
        "id": "JdlYznsLOWh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gqAdFTBp6yJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3omd4nxE6yLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HlIDcrX56yQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fsv4S3QD6yS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unet"
      ],
      "metadata": {
        "id": "eV-sB9U56ycv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# normalize image pixels\n",
        "IMG_SIZE1 =200\n",
        "IMG_SIZE2 =256\n",
        "BATCH_SIZE = 32\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "GT_DIR = COLAB_DIR + 'gtFine/'\n",
        "IMG_DIR = COLAB_DIR + 'leftImg/'\n",
        "def load_and_preprocess_image(path):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, [IMG_SIZE1, IMG_SIZE2])\n",
        "    img /= 255.0\n",
        "    return img\n",
        "\n",
        "def get_image_paths(dir):\n",
        "    return sorted([dir + path for path in listdir(dir)])\n",
        "\n",
        "# data transformation using K-means\n",
        "def LayersToRGBImage(img):\n",
        "    colors = [(255,0,0), (0,255,0), (0,0,255), (255,255,0), (255,0,255), \n",
        "              (0,255,255), (255,255,255), (200,50,0),(50,200,0), (50,0,200), \n",
        "              (200,200,50), (0,50,200), (0,200,50), (0,0,0)]\n",
        "    \n",
        "    nimg = np.zeros((img.shape[0], img.shape[1], 3))\n",
        "    for i in range(img.shape[2]):\n",
        "        c = img[:,:,i]\n",
        "        col = colors[i]\n",
        "        \n",
        "        for j in range(3):\n",
        "            nimg[:,:,j]+=col[j]*c\n",
        "    nimg = nimg/255.0\n",
        "    return nimg\n",
        "    \n",
        "def train_kmeans(K=7):\n",
        "    colors = []\n",
        "    kmeans_gt_train_paths = [GT_DIR + 'train/' + path for path in listdir(GT_DIR + 'train/')[:20]]\n",
        "    kmeans_gt_train_ds = tf.data.Dataset.from_tensor_slices(kmeans_gt_train_paths)\n",
        "    kmeans_gt_train_ds = kmeans_gt_train_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "    for seg in kmeans_gt_train_ds:\n",
        "        colors.append(tf.reshape(seg, (seg.shape[0]*seg.shape[1], 3) ))\n",
        "    colors = tf.concat(colors, 0) \n",
        "    print(\"Training K means on colors data of shape :\",colors.shape)\n",
        "    km = KMeans(K)\n",
        "    km.fit(colors)\n",
        "    print(\"\\nK-means clustering trained\\n\", km)\n",
        "    return km\n",
        "\n",
        "# Traing a k-means classifier\n",
        "km=train_kmeans(13)\n",
        "\n",
        "def load_and_preprocess_segment(path):\n",
        "    seg = load_and_preprocess_image(path)\n",
        "    s = tf.reshape(seg, (seg.shape[0]*seg.shape[1],3))\n",
        "    s = km.predict(s)\n",
        "    s = tf.reshape(s, (seg.shape[0], seg.shape[1]))\n",
        "    n = len(km.cluster_centers_)\n",
        "    cls = np.zeros((seg.shape[0], seg.shape[1], n))\n",
        "    for i in range(n):\n",
        "        m = np.copy(s)\n",
        "        m[m!=i] = 0\n",
        "        m[m!=0] = 1\n",
        "        cls[:,:,i]=m\n",
        "\n",
        "    seg = tf.convert_to_tensor(cls, dtype=tf.float32)\n",
        "    return seg"
      ],
      "metadata": {
        "id": "wfXs3RS36z_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# train data\n",
        "im_train_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(IMG_DIR+'train/'))\n",
        "im_train_ds = im_train_ds.map(load_and_preprocess_image)\n",
        "gt_train_paths = get_image_paths(GT_DIR+'train/')\n",
        "gt_train_ds = map(load_and_preprocess_segment, gt_train_paths)"
      ],
      "metadata": {
        "id": "rpni2k_Q_zwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "gt_train_ds = tf.data.Dataset.from_tensor_slices([a for a in gt_train_ds])"
      ],
      "metadata": {
        "id": "jWcRsrdg_z7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KfOA-fAmA4px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yAeQ6kT2A4sT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SiicXBgOA4uz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# train data\n",
        "im_train_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(IMG_DIR+'train/'))\n",
        "im_train_ds = im_train_ds.map(load_and_preprocess_image)\n",
        "\n",
        "gt_train_paths = get_image_paths(GT_DIR+'train/')\n",
        "gt_train_ds = map(load_and_preprocess_segment, gt_train_paths)\n",
        "gt_train_ds = tf.data.Dataset.from_tensor_slices([a for a in gt_train_ds])\n",
        "train_ds = tf.data.Dataset.zip((im_train_ds, gt_train_ds))\n",
        "train_ds = train_ds.cache().batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "print('Training Data:\\n# of batches, Input batch shape, Ouput batch shape')\n",
        "print(len(train_ds), next(iter(train_ds))[0].shape, next(iter(train_ds))[1].shape)"
      ],
      "metadata": {
        "id": "uS8i9DCT7ss9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# val data\n",
        "im_val_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(IMG_DIR+'val/'))\n",
        "im_val_ds = im_val_ds.map(load_and_preprocess_image)\n",
        "\n",
        "gt_val_paths = get_image_paths(GT_DIR+'val/')\n",
        "gt_val_ds = map(load_and_preprocess_segment, gt_val_paths)\n",
        "gt_val_ds = tf.data.Dataset.from_tensor_slices([a for a in gt_val_ds])\n",
        "val_ds = tf.data.Dataset.zip((im_val_ds, gt_val_ds))\n",
        "val_ds = val_ds.cache().batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "\n",
        "print('Validation Data:\\n# of batches, Input batch shape, Ouput batch shape')\n",
        "print(len(val_ds), next(iter(val_ds))[0].shape, next(iter(val_ds))[1].shape)"
      ],
      "metadata": {
        "id": "UVjHuYz47syg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# test data\n",
        "im_test_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(IMG_DIR+'test/'))\n",
        "im_test_ds = im_test_ds.map(load_and_preprocess_image)\n",
        "\n",
        "gt_test_paths = get_image_paths(GT_DIR+'test/')\n",
        "gt_test_ds = map(load_and_preprocess_segment, gt_test_paths)\n",
        "gt_test_ds = tf.data.Dataset.from_tensor_slices([a for a in gt_test_ds])\n",
        "test_ds = tf.data.Dataset.zip((im_test_ds, gt_test_ds))\n",
        "test_ds = test_ds.cache().batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "print('Testing Data:\\n# of batches, Input batch shape, Ouput batch shape')\n",
        "print(len(test_ds), next(iter(test_ds))[0].shape, next(iter(test_ds))[1].shape)"
      ],
      "metadata": {
        "id": "gfQiIyNX7s1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time"
      ],
      "metadata": {
        "id": "qe3MSTYI7s4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UmGQ-e9Stfr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8oz-BgnStfuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline Model"
      ],
      "metadata": {
        "id": "td5Cz67Htf3U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Lib"
      ],
      "metadata": {
        "id": "7QcascrI7M07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import cv2\n",
        "import os\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from skimage.filters import roberts, sobel, scharr, prewitt\n",
        "from scipy import ndimage as nd"
      ],
      "metadata": {
        "id": "PO2TnZE37PmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Loading Data"
      ],
      "metadata": {
        "id": "fYPpYVlJ7ALs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!gdown --id 12rNfOiM4allOn8t4l0ErpvgmA9hEZPh2 -O processed_labels.zip\n",
        "!gdown --id 145Ul0rdbQcX98lQz8IO5eOtI0ZlvKwz6 -O processed_images.zip"
      ],
      "metadata": {
        "id": "nlkvBNXItiHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!unzip /content/processed_images.zip\n",
        "!unzip /content/processed_labels.zip"
      ],
      "metadata": {
        "id": "iRtqOCbcvSTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-Processing Data"
      ],
      "metadata": {
        "id": "tCDqzox07E_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = '/content/content/processed_images/*'\n",
        "lab_path = '/content/content/processed_labels/*'"
      ],
      "metadata": {
        "id": "J8gwWlhN8Oq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the data indo a list, numpy array\n",
        "%%time\n",
        "train_images = glob.glob(img_path)\n",
        "train_labels = glob.glob(lab_path)\n",
        "\n",
        "print(len(train_images))\n",
        "print(len(train_labels))"
      ],
      "metadata": {
        "id": "4ZMBHtR1veez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = train_images[0]\n",
        "lab = train_labels[0]\n",
        "print(img)\n",
        "print(lab)"
      ],
      "metadata": {
        "id": "1vO6BgyV9GM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LgkXw5oJwqBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread(img)\n",
        "print(img, img.shape)"
      ],
      "metadata": {
        "id": "OKDINCu39JXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img.shape"
      ],
      "metadata": {
        "id": "taAzxviw-2Mh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(img)"
      ],
      "metadata": {
        "id": "VHJ02pK7gjvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
      ],
      "metadata": {
        "id": "jjoK7ggjs5qn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(gray)"
      ],
      "metadata": {
        "id": "dHmo2njrs5s1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gimg1 = gabor_feature_extraction(img,.8, .05 )\n",
        "gimg2 = gabor_feature_extraction(img,1.6, .5 )"
      ],
      "metadata": {
        "id": "qD7kbFMxlb7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(gimg2.reshape(img.shape))\n"
      ],
      "metadata": {
        "id": "HZsPj0zdls85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(gimg1.reshape(img.shape))"
      ],
      "metadata": {
        "id": "eDqoQRmRl6yF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(img)"
      ],
      "metadata": {
        "id": "HWZLvuuqlnU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jnADeMeE-8jV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blur1, blur2, sobele, canny = preprocess_image(img)\n",
        "print(blur1.shape, blur2.shape, sobele.shape, canny.shape )"
      ],
      "metadata": {
        "id": "VzVLyCJy-8lz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(blur1.reshape(img.shape))"
      ],
      "metadata": {
        "id": "fqTeZ9fKscEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(blur2.reshape(img.shape))"
      ],
      "metadata": {
        "id": "VjDMK7OsscHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(sobele.reshape(img.shape))"
      ],
      "metadata": {
        "id": "o15G5zWXscKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(canny.reshape(img.shape))"
      ],
      "metadata": {
        "id": "YehHPGr5scNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# WIP"
      ],
      "metadata": {
        "id": "QTblRQ9nuNoC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gray1 = gray.reshape(-1,1)\n",
        "gray1.shape"
      ],
      "metadata": {
        "id": "AlYBnsKTuhr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gabor1 = gabor_feature_extraction(gray,.8, .05 )\n",
        "gabor2 = gabor_feature_extraction(gray,1.6, .5 )\n",
        "gabor1.shape, gabor2.shape"
      ],
      "metadata": {
        "id": "GHdiV81uscP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blur1, blur2, sobele, canny = preprocess_image(gray)\n",
        "print(blur1.shape, blur2.shape, sobele.shape, canny.shape )"
      ],
      "metadata": {
        "id": "rfHspCxLscSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    r, g, b = cv2.split(img)\n",
        "    features = np.dstack((r, g, b)).reshape(-1, 3)"
      ],
      "metadata": {
        "id": "nhslMmH7qSBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = np.hstack((gray1, gabor1, gabor2, blur1, blur2, sobele, canny))\n",
        "features.shape"
      ],
      "metadata": {
        "id": "GLBC7DwEuRLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iXartJViuRRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RZT269yzuRUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jZMWqcRDuRW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for directory_path in glob.glob(\"images/natural/train/*\"):\n",
        "    label = directory_path.split(\"\\\\\")[-1]\n",
        "    print(label)\n",
        "    for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
        "        print(img_path)\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_COLOR) #Reading color images\n",
        "        img = cv2.resize(img, (SIZE, SIZE)) #Resize images\n",
        "        #img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) #Optional step. Change BGR to RGB\n",
        "        train_images.append(img)\n",
        "        train_labels.append(label)\n",
        "        \n",
        "train_images = np.array(train_images)\n",
        "train_labels = np.array(train_labels)"
      ],
      "metadata": {
        "id": "aSL8N958wCa4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now, add a column in the data frame for the Labels\n",
        "#For this, we need to import the labeled image\n",
        "labeled_img = cv2.imread(lab)\n",
        "#Remember that you can load an image with partial labels \n",
        "#But, drop the rows with unlabeled data\n",
        "\n",
        "labeled_img = cv2.cvtColor(labeled_img, cv2.COLOR_BGR2GRAY)\n",
        "labeled_img1 = labeled_img.reshape(-1)\n"
      ],
      "metadata": {
        "id": "Kl8rpgFVwCdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_img1.shape"
      ],
      "metadata": {
        "id": "Y9hXL4e6vPiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "Y = LabelEncoder().fit_transform(labeled_img1)"
      ],
      "metadata": {
        "id": "AhA6nqbPvPtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y.shape"
      ],
      "metadata": {
        "id": "L03PnDg0vibh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ")"
      ],
      "metadata": {
        "id": "rCWw0O_hviiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_img_data = df.drop(labels = [\"Labels\"], axis=1) #Use for prediction\n",
        "#df.to_csv(\"Gabor.csv\")\n",
        "df = df[df.Labels != 0]"
      ],
      "metadata": {
        "id": "5mpc7b02wCg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the dependent variable that needs to be predicted (labels)\n",
        "Y = df[\"Labels\"].values\n",
        "\n",
        "#Encode Y values to 0, 1, 2, 3, .... (NOt necessary but makes it easy to use other tools like ROC plots)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "Y = LabelEncoder().fit_transform(Y)\n",
        "\n",
        "\n",
        "#Define the independent variables\n",
        "X = df.drop(labels = [\"Labels\"], axis=1) "
      ],
      "metadata": {
        "id": "CclVYTGmLjCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split data into train and test to verify accuracy after fitting the model. \n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=20)\n",
        "\n"
      ],
      "metadata": {
        "id": "QFzYSLgeLjFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features.shape, Y.shape"
      ],
      "metadata": {
        "id": "kyHdtZiHv0Ld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IfK64jjZv0N-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LvcDxVq6v0Q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# Instantiate model with n number of decision trees\n",
        "model = RandomForestClassifier(n_estimators = 20, random_state = 42)\n",
        "\n",
        "# Train the model on training data\n",
        "model.fit(features, Y)"
      ],
      "metadata": {
        "id": "3UlI1atsLjIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_list = list(X.columns)\n",
        "feature_imp = pd.Series(model.feature_importances_,index=feature_list).sort_values(ascending=False)\n",
        "print(feature_imp)"
      ],
      "metadata": {
        "id": "pwrd_OXDLjLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_RF = model.predict(features)"
      ],
      "metadata": {
        "id": "DEErx15mwJ7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_RF.shape"
      ],
      "metadata": {
        "id": "zr4VigQVwJ-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(prediction_RF.reshape(gray.shape))"
      ],
      "metadata": {
        "id": "4g9LO-otwKBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lab = cv2.imread('/content/content/processed_labels/aachen_000159_000019.png',0)\n",
        "print(lab.shape)"
      ],
      "metadata": {
        "id": "jMRK2XxfwKE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(lab)"
      ],
      "metadata": {
        "id": "f2_mkt9DwKHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img1 = train_images[11]\n",
        "lab1 = train_labels[11]\n",
        "lab1 = cv2.imread(lab1,0)\n",
        "img1 = cv2.imread(img1,0)\n",
        "print(lab1.shape, img1.shape)"
      ],
      "metadata": {
        "id": "a7H4Wgw4xFus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(img1)"
      ],
      "metadata": {
        "id": "BLzXet14xFxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(lab1)"
      ],
      "metadata": {
        "id": "O_6nPirExF0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VytN3dk4xF3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evl"
      ],
      "metadata": {
        "id": "xB6BhtLyx2oo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gabor1 = gabor_feature_extraction(img1,.8, .05 )\n",
        "gabor2 = gabor_feature_extraction(img1,1.6, .5 )\n",
        "blur1, blur2, sobele, canny = preprocess_image(img1)\n",
        "print(blur1.shape, blur2.shape, sobele.shape, canny.shape )\n",
        "print(gabor1.shape, gabor2.shape)"
      ],
      "metadata": {
        "id": "KWf9sj7exF6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = np.hstack((gray1, gabor1, gabor2, blur1, blur2, sobele, canny))\n",
        "features.shape"
      ],
      "metadata": {
        "id": "s8wExb7xxF9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lab1.shape"
      ],
      "metadata": {
        "id": "ckhw-2B4xGAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B3c1qsFPxGCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0SbpT0zQxGFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_RF = model.predict(features)"
      ],
      "metadata": {
        "id": "U3Tzh2FzMZfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(prediction_RF.reshape(gray.shape))"
      ],
      "metadata": {
        "id": "J362DmiZyRnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(lab1)"
      ],
      "metadata": {
        "id": "JHtj_ry9yRqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2f1A5kXCyRs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K8U6UNDryRvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "#Print the prediction accuracy\n",
        "#Check accuracy on test dataset. If this is too low compared to train it indicates overfitting on training data.\n",
        "print (\"Accuracy using Random Forest= \", metrics.accuracy_score(y_test, prediction_RF))"
      ],
      "metadata": {
        "id": "zZc0OU7cMbSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0LUuK4FXMbYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PjK6cjZlMbaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# new approach"
      ],
      "metadata": {
        "id": "XoDeUCnxtFBB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "/content/content/processed_images/dusseldorf_000143_000019.png\n",
        "/content/content/processed_labels/dusseldorf_000143_000019.png"
      ],
      "metadata": {
        "id": "C6kaCKy-pTJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, lab"
      ],
      "metadata": {
        "id": "36ps1Q3Zo8RB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n"
      ],
      "metadata": {
        "id": "NjbUst4ppUde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(img):\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    \n",
        "    # Apply Canny edge detection\n",
        "    edges = cv2.Canny(gray, 100, 200)\n",
        "    \n",
        "    # Apply Gaussian blur to reduce noise\n",
        "    blur = cv2.GaussianBlur(edges, (5, 5), 0)\n",
        "    \n",
        "    return blur"
      ],
      "metadata": {
        "id": "Frgj8ryJpnzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def npreprocess_image(img):\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY).reshape(-1,1)\n",
        "    sobels = sobel(gray)\n",
        "    \n",
        "    # Apply Canny edge detection\n",
        "    edges = cv2.Canny(gray, 100, 200)\n",
        "    \n",
        "    # Apply Gaussian blur to reduce noise\n",
        "    blur = cv2.GaussianBlur(edges, (5, 5), 0)\n",
        "    \n",
        "    return np.hstack((gray, sobels,edges,blur))"
      ],
      "metadata": {
        "id": "fA5NZfMH4RLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(img):\n",
        "    # Extract RGB color features\n",
        "    r, g, b = cv2.split(img)\n",
        "    features = np.dstack((r, g, b)).reshape(-1, 3)\n",
        "    \n",
        "    # Extract texture features using Gabor filter\n",
        "    kernel = cv2.getGaborKernel((5, 5), 4, np.pi/4, 8, 0.5, 0, ktype=cv2.CV_32F)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    filtered = cv2.filter2D(gray, cv2.CV_8UC3, kernel)\n",
        "    texture_features = filtered.reshape(-1, 1)\n",
        "    \n",
        "    # Combine color and texture features\n",
        "    features = np.hstack((features, texture_features))\n",
        "    \n",
        "    return features"
      ],
      "metadata": {
        "id": "MNK_9amPpn2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def segment_image(img):\n",
        "    # Preprocess the image\n",
        "    preprocessed = preprocess_image(img)\n",
        "    \n",
        "    # Extract features from the preprocessed image\n",
        "    features = extract_features(img)\n",
        "    \n",
        "    # Cluster the features using k-means\n",
        "    kmeans = KMeans(n_clusters=3, random_state=0).fit(features)\n",
        "    labels = kmeans.labels_.reshape(preprocessed.shape[:2])\n",
        "    \n",
        "    # Train a Random Forest classifier on the labeled features\n",
        "    flat_features = features.reshape(-1, features.shape[-1])\n",
        "    clf = RandomForestClassifier(n_estimators=50, random_state=0)\n",
        "    clf.fit(flat_features, labels.ravel())\n",
        "    \n",
        "    # Predict the segmentation for the preprocessed image\n",
        "    flat_preprocessed = preprocessed.reshape(-1, preprocessed.shape[-1])\n",
        "    segmentation = clf.predict(flat_preprocessed).reshape(preprocessed.shape[:2])\n",
        "    \n",
        "    # Convert the segmentation to a binary mask\n",
        "    mask = np.zeros_like(segmentation)\n",
        "    mask[segmentation == 1] = 255\n",
        "    \n",
        "    return mask"
      ],
      "metadata": {
        "id": "MTV8Bwogpn5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load an example image\n",
        "img = cv2.imread('/content/content/processed_images/dusseldorf_000143_000019.png')"
      ],
      "metadata": {
        "id": "VrAQ7mHypn8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Preprocess the image\n",
        "preprocessed = preprocess_image(img)\n",
        "npreprocessed = npreprocess_image(img)\n",
        "print(preprocessed.shape, npreprocessed.shape)"
      ],
      "metadata": {
        "id": "lVe4LTA5qEQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract features from the preprocessed image\n",
        "features = extract_features(img)\n",
        "features.shape"
      ],
      "metadata": {
        "id": "5v8BzWOFqXiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cluster the features using k-means\n",
        "kmeans = KMeans(n_clusters=21, random_state=0).fit(features)\n",
        "labels = kmeans.labels_.reshape(preprocessed.shape[:2])\n",
        "labels.shape"
      ],
      "metadata": {
        "id": "BO842IGgque-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed.shape[:2]"
      ],
      "metadata": {
        "id": "mkjs7aUW7B-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cluster the features using k-means\n",
        "kmeans = KMeans(n_clusters=21, random_state=0).fit(features)\n",
        "labels = kmeans.labels_.reshape(npreprocessed.shape[:2])\n",
        "labels.shape"
      ],
      "metadata": {
        "id": "kghPRnmb646b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels[10]"
      ],
      "metadata": {
        "id": "VXwwckSZqukV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flat_features = features.reshape(-1, features.shape[-1])\n",
        "print(flat_features.shape)"
      ],
      "metadata": {
        "id": "60nrFxflrAeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = RandomForestClassifier(n_estimators=50, random_state=0)"
      ],
      "metadata": {
        "id": "YknkhHYarAg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels.ravel().shape"
      ],
      "metadata": {
        "id": "h1_R3Qg5rbDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(flat_features, labels.ravel())"
      ],
      "metadata": {
        "id": "aKCSNj5orTrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "flat_features = features.reshape(-1, features.shape[-1])\n",
        "print(flat_features.shape)"
      ],
      "metadata": {
        "id": "GGlnvVdvtnRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the segmentation for the preprocessed image\n",
        "#flat_preprocessed = preprocessed.reshape(-1, preprocessed.shape[-1])\n",
        "flat_preprocessed = preprocessed.reshape(-1, preprocessed.shape[-1])\n",
        "flat_preprocessed.shape"
      ],
      "metadata": {
        "id": "rCBwrZHFrvIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#segmentation = clf.predict(flat_preprocessed).reshape(preprocessed.shape[:2])   \n",
        "segmentation = clf.predict(npreprocessed)\n",
        "\n",
        "segmentation.shape"
      ],
      "metadata": {
        "id": "FX0Uh4X1rvLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "segmentation = segmentation.reshape(preprocessed.shape[:2]) \n",
        "segmentation.shape"
      ],
      "metadata": {
        "id": "jLoAL_-B8MOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(segmentation)"
      ],
      "metadata": {
        "id": "fTqG6RYyyx0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the segmentation to a binary mask\n",
        "mask = np.zeros_like(segmentation)\n",
        "mask[segmentation == 1] = 255"
      ],
      "metadata": {
        "id": "4pN7FMSGrvNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "segmentation = clf.predict(flat_preprocessed).reshape(preprocessed.shape[:2])\n",
        "\n",
        "# Convert the segmentation to a binary mask\n",
        "mask = np.zeros_like(segmentation)\n",
        "mask[segmentation == 1] = 255\n"
      ],
      "metadata": {
        "id": "baRZGRcQqXos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9nkXV8BWqETg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Segment the image\n",
        "##mask = segment_image(img)\n",
        "\n"
      ],
      "metadata": {
        "id": "X5ZiZgNvpn_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask.shape, img.shape"
      ],
      "metadata": {
        "id": "MFgTMFQ1vVLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(img)"
      ],
      "metadata": {
        "id": "i3WpiOBhve49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(mask)"
      ],
      "metadata": {
        "id": "6fOz8ihjvi8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the results\n",
        "cv2.imshow('Input Image', img)\n",
        "cv2.imshow('Segmentation Mask', mask)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "Si-OjAnbpoDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IabTxXxZzG_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8LwvkhEKzHCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(img):\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY).reshape(-1,1)\n",
        "    sobels = sobel(gray)\n",
        "    \n",
        "    # Apply Canny edge detection\n",
        "    edges = cv2.Canny(gray, 100, 200)\n",
        "    \n",
        "    # Apply Gaussian blur to reduce noise\n",
        "    blur = cv2.GaussianBlur(edges, (5, 5), 0)\n",
        "    \n",
        "    return np.hstack((gray, sobels,edges,blur))"
      ],
      "metadata": {
        "id": "Gn5vTQ1PzHFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = preprocess_image(img)\n"
      ],
      "metadata": {
        "id": "5DotSurPzHgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.shape"
      ],
      "metadata": {
        "id": "_uLTyRMq4MJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "gray.shape\n",
        "g= gray.reshape(-1, 1)\n",
        "g.shape"
      ],
      "metadata": {
        "id": "bn-WZ2uzzHi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SOBEL\n",
        "s = sobel(g)\n",
        "#s = s.reshape(-1,1)\n",
        "s.shape"
      ],
      "metadata": {
        "id": "V8SVnV8u1cwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Apply Canny edge detection\n",
        "edges = cv2.Canny(gray, 100, 200)\n",
        "edges.shape\n",
        "e= edges.reshape(-1,1)"
      ],
      "metadata": {
        "id": "5DYpoSydzayC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blur = cv2.GaussianBlur(edges, (5, 5), 0)\n",
        "blur.shape\n",
        "b= blur.reshape(-1,1)"
      ],
      "metadata": {
        "id": "ll2Hyh0GzHli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blur.reshape(-1).shape"
      ],
      "metadata": {
        "id": "n58EgUl7zXBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blur.shape"
      ],
      "metadata": {
        "id": "4pvRXRxz0AOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = np.hstack((g, e,b,s))\n",
        "f.shape"
      ],
      "metadata": {
        "id": "qNcEAGUqzyAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "segmentation = clf.predict(f).reshape(preprocessed.shape[:2])\n",
        "    "
      ],
      "metadata": {
        "id": "t-uNC0GM0HAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask = np.zeros_like(segmentation)\n",
        "mask[segmentation == 1] = 255"
      ],
      "metadata": {
        "id": "7kAOVmzQ2Jp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(mask)"
      ],
      "metadata": {
        "id": "P_1kiryS2Jsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lab = train_label[0]\n",
        "lab = cv2.imread(lab, 0)\n"
      ],
      "metadata": {
        "id": "jroX29UB46pe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(lab)\n"
      ],
      "metadata": {
        "id": "74qm9w5p2Jvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    segmentation = clf.predict(flat_preprocessed).reshape(preprocessed.shape[:2])\n",
        "    \n",
        "    # Convert the segmentation to a binary mask\n",
        "    mask = np.zeros_like(segmentation)\n",
        "    mask[segmentation == 1] = 255\n",
        "    \n",
        "    return mask\n",
        "\n",
        "# Load an example image\n",
        "img = cv2.imread('example.jpg')\n",
        "\n",
        "# Segment the image\n",
        "mask = segment_image(img)\n",
        "\n",
        "# Display the results\n",
        "cv2.imshow('Input Image', img)\n",
        "cv2.imshow('Segmentation Mask', mask)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "5af0w3bl2Jyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F2rbJri5sJMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "WoXAEEd0sJk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gabor_feature_extraction(img, lamda, gamma):\n",
        "  kernel = cv2.getGaborKernel((8, 8), 1, 0, lamda, gamma, 0, ktype=cv2.CV_32F)\n",
        "  gabor_img = cv2.filter2D(img, cv2.CV_8UC3, kernel)\n",
        "  return gabor_img.reshape(-1,1)\n"
      ],
      "metadata": {
        "id": "-vv5vreOsLXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(img):\n",
        "  #GAUSSIAN blur 1\n",
        "  blur1 = nd.gaussian_filter(img, sigma=3)\n",
        "  #GAUSSIAN blur2\n",
        "  blur2 = nd.gaussian_filter(img, sigma=7)\n",
        "  #SOBEL\n",
        "  sobele = sobel(blur2)\n",
        "  #CANNY \n",
        "  cany = cv2.Canny(np.uint8(sobele), 100,200)\n",
        "  #return cany\n",
        "  return (blur1.reshape(-1),blur2.reshape(-1),sobele.reshape(-1),cany.reshape(-1))"
      ],
      "metadata": {
        "id": "CZ_JrjPPsLz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image_org(img):\n",
        "  #GAUSSIAN blur 1\n",
        "  blur1 = nd.gaussian_filter(img, sigma=3)\n",
        "  #GAUSSIAN blur2\n",
        "  blur2 = nd.gaussian_filter(img, sigma=7)\n",
        "  #SOBEL\n",
        "  sobele = sobel(blur2)\n",
        "  #CANNY \n",
        "  cany = cv2.Canny(np.uint8(sobele), 100,200)\n",
        "  #return cany\n",
        "  return (blur1.reshape(-1,1),blur2.reshape(-1,1),sobele.reshape(-1,1),cany.reshape(-1,1))"
      ],
      "metadata": {
        "id": "BVCA-uLQsL2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_img(img):\n",
        "  fig = plt.figure(figsize=(15,15))\n",
        "  ax = fig.add_subplot(111)\n",
        "  ax.imshow(img,cmap='gray')"
      ],
      "metadata": {
        "id": "00mkCqMssL5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_img(image_path):\n",
        "  return cv2.imread(image_path, 0).astype(np.float32)/255\n"
      ],
      "metadata": {
        "id": "1ocjCADFplBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1zQxJi2WplEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rx5nfg_-plH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#New Approach"
      ],
      "metadata": {
        "id": "EDp0BG_4jURb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_dataset = pd.DataFrame() "
      ],
      "metadata": {
        "id": "mo8LaR7ksL7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images[200]"
      ],
      "metadata": {
        "id": "bYag8bSX2Zlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_images = glob.glob(img_path)\n",
        "#train_labels = glob.glob(lab_path)\n",
        "print(len(train_images))\n",
        "print(len(train_labels))\n",
        "print(int(len(train_images)*.7))"
      ],
      "metadata": {
        "id": "1KL1J4e-jZZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = cv2.imread(train_images[200], 0)"
      ],
      "metadata": {
        "id": "lOIB53qgkn8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(m, cmap='gray')"
      ],
      "metadata": {
        "id": "fs0eA3zUk_va"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Thresholding\n",
        "ret,thresh1  = cv2.threshold(m, 125, 255, cv2.THRESH_BINARY)\n",
        "plt.imshow(thresh1, cmap='gray')"
      ],
      "metadata": {
        "id": "N0EDEwQ7m-QU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xu5WAo3lnQEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Thresholding\n",
        "ret,thresh2  = cv2.threshold(m, 125, 255, cv2.THRESH_BINARY_INV)\n",
        "plt.imshow(thresh2, cmap='gray')"
      ],
      "metadata": {
        "id": "xS9np2H5oXs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_img(thresh2)"
      ],
      "metadata": {
        "id": "0xEbhYNEpoMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "th2 = cv2.adaptiveThreshold(m, 255, cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,11, 8)\n",
        "display_img(th2)"
      ],
      "metadata": {
        "id": "ZiJiPpJ4poPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ret,thresh2  = cv2.threshold(m, 125, 255, cv2.THRESH_BINARY_INV)"
      ],
      "metadata": {
        "id": "NHLJMuDspoSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m1 = load_img(train_images[200])\n",
        "display_img(m1)"
      ],
      "metadata": {
        "id": "kIbGHfldpoVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gm = np.power(m1,4)\n",
        "display_img(gm)"
      ],
      "metadata": {
        "id": "My88VgdXpoYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv2blur = cv2.blur(m1, ksize=(5,5))\n",
        "display_img(cv2blur)"
      ],
      "metadata": {
        "id": "clpm6_mYuJRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gblur = cv2.GaussianBlur(m1, (5,5),8)\n",
        "display_img(gblur)"
      ],
      "metadata": {
        "id": "OT3ZwF0ruJSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mblur = cv2.medianBlur(m1,5)\n",
        "display_img(mblur)"
      ],
      "metadata": {
        "id": "jJUa5p5cuJVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s1 = cv2.Sobel(m1,cv2.CV_64F, 1,0,ksize=5)\n",
        "display_img(s1)"
      ],
      "metadata": {
        "id": "biQJb7OKwAsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cany = cv2.Canny(np.uint8(sobele), 100,200)"
      ],
      "metadata": {
        "id": "wWStsqH5wAvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c1 = cv2.Canny(np.uint8(s1), 100,200)\n",
        "display_img(c1)"
      ],
      "metadata": {
        "id": "1Xc9Zm7XwAyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "laplacian = cv2.Laplacian(m1, cv2.CV_64F, ksize=7) \n",
        "display_img(laplacian)"
      ],
      "metadata": {
        "id": "a0_GK38XwA0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "laplacian.shape"
      ],
      "metadata": {
        "id": "MSfiDd88uJX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b4xEwD79pobI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image_dir):\n",
        "  #loading the image and normalize it \n",
        "  m1 = load_img(image_dir)\n",
        "\n",
        "  #GAUSSIAN blur 1\n",
        "  gblur = cv2.GaussianBlur(m1, (5,5),7)\n",
        "  #Laplacian\n",
        "  laplacian = cv2.Laplacian(m1, cv2.CV_64F, ksize=7) \n",
        "  #SOBEL\n",
        "  sobele = cv2.Sobel(m1,cv2.CV_64F, 0,1,ksize=5)\n",
        "  #CANNY \n",
        "  cany = cv2.Canny(np.uint8(s1), 100,200)\n",
        "\n",
        "  #return cany\n",
        "  return (gblur.reshape(-1),laplacian.reshape(-1),sobele.reshape(-1),cany.reshape(-1))"
      ],
      "metadata": {
        "id": "bLYjkoJ9k_ym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b = nd.gaussian_filter(m, sigma=3)\n",
        "plt.imshow(b)"
      ],
      "metadata": {
        "id": "rJVkHLUCk_1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#SOBEL\n",
        "s = sobel(b)\n",
        "plt.imshow(s)\n"
      ],
      "metadata": {
        "id": "KNe9NpCak_7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  #CANNY \n",
        "c= cv2.Canny(np.uint8(s), 100,200)\n",
        "plt.imshow(c,cmap='gray')"
      ],
      "metadata": {
        "id": "RHg7UihDk_-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.max(c,cmap='gray')"
      ],
      "metadata": {
        "id": "4xp6MxqslABb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QjVW4Wm2lAEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zdwTiM2AlAHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a data frame with test data image \n",
        "df_image = pd.DataFrame() \n",
        "for image in train_images[:200]:\n",
        "  df1 = pd.DataFrame()\n",
        "  img = cv2.imread(image, 0)\n",
        "  df1['gray']= img.reshape(-1)\n",
        "  df1['Image_Name'] = image.split('/')[-1]\n",
        "  df1['gabor1'] = gabor_feature_extraction(img,.8, .05 ).reshape(-1)\n",
        "  df1['gabor2'] = gabor_feature_extraction(img,1.6, .5 ).reshape(-1)\n",
        "  df1['blur1'], df1['blur2'], df1['sobelx'], df1['canny'] = preprocess_image(img)\n",
        "  df_image = pd.concat([df_image, df1])\n",
        "\n",
        "print(df_image.shape)"
      ],
      "metadata": {
        "id": "JyiSW3GnjnVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating test mask image Data Frame\n",
        "%%time\n",
        "df_mask = pd.DataFrame() \n",
        "for mask in train_labels[:100]:\n",
        "  df2 = pd.DataFrame()\n",
        "  msk = cv2.imread(mask, 0)\n",
        "  df2['label'] = msk.reshape(-1) \n",
        "  df2['Mask_Name'] = mask.split('/')[-1]  \n",
        "  df_mask = pd.concat([df_mask, df2])\n",
        "\n",
        "print(df_mask.shape)"
      ],
      "metadata": {
        "id": "TsuGEz7ywxkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_mask.shape"
      ],
      "metadata": {
        "id": "xtqkI8eO0kaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_image.shape"
      ],
      "metadata": {
        "id": "NhJz_KY1wxnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_image.head()"
      ],
      "metadata": {
        "id": "twuGHANAwxp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_mask.head()"
      ],
      "metadata": {
        "id": "0RgYil_50lAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([df_image, df_mask], axis=1)  "
      ],
      "metadata": {
        "id": "f4ygZJZZ1_T9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "z6LCxVyV1_Wp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "GYvH455R1_ZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_0 = df[df.label != 0]\n",
        "df_0.shape"
      ],
      "metadata": {
        "id": "CO_aNaES1_ct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_0.drop(labels = [\"Image_Name\", \"Mask_Name\", \"label\"], axis=1) "
      ],
      "metadata": {
        "id": "T177MN4P2eGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = df_0[\"label\"].values "
      ],
      "metadata": {
        "id": "zKAPhlFm2eJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, Y.shape"
      ],
      "metadata": {
        "id": "66q7Inub2eMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "Y = LabelEncoder().fit_transform(Y)\n",
        "Y.shape"
      ],
      "metadata": {
        "id": "8FEgcJoo2ePK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=20)"
      ],
      "metadata": {
        "id": "qC1UQ5qRteQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import training classifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "## Instantiate model with n number of decision trees\n",
        "model = RandomForestClassifier(n_estimators = 50, random_state = 42)\n",
        "\n"
      ],
      "metadata": {
        "id": "RW4UzbAk29JL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Train the model on training data\n",
        "model.fit(X, Y)"
      ],
      "metadata": {
        "id": "il3_TV0q29MC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_img = cv2.imread(train_images[100], 0)\n",
        "test_lab = cv2.imread(train_labels[100],0)"
      ],
      "metadata": {
        "id": "9bdOk11K4r0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(test_img)"
      ],
      "metadata": {
        "id": "YypgGCn45NES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(test_lab)"
      ],
      "metadata": {
        "id": "dHgrUvmm5NGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gabor1 = gabor_feature_extraction(test_img,.8, .05 )\n",
        "gabor2 = gabor_feature_extraction(test_img,1.6, .5 )\n",
        "blur1, blur2, sobele, canny = preprocess_image(test_img)\n",
        "print(blur1.shape, blur2.shape, sobele.shape, canny.shape )\n",
        "print(gabor1.shape, gabor2.shape)"
      ],
      "metadata": {
        "id": "EWtHypZd4r28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gray1=test_img.reshape(-1,1)\n",
        "features = np.hstack((gray1, gabor1, gabor2, blur1, blur2, sobele, canny))\n",
        "features.shape"
      ],
      "metadata": {
        "id": "zEegc-xV4w7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blur1.shape"
      ],
      "metadata": {
        "id": "QoM9hnfZ639N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(X)"
      ],
      "metadata": {
        "id": "5vfT6itF4w-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1sI7w19J6lKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.DataFrame()\n",
        "test_df['gray']= test_img.reshape(-1)#img.reshape(-1)\n",
        "#df1['Image_Name'] = image.split('/')[-1]  \n",
        "test_df['gabor1'] = gabor_feature_extraction(test_img,.8, .05 ).reshape(-1)\n",
        "test_df['gabor2'] = gabor_feature_extraction(test_img,1.6, .5 ).reshape(-1)\n",
        "test_df['blur1'], test_df['blur2'], test_df['sobelx'], test_df['canny'] = preprocess_image(test_img)"
      ],
      "metadata": {
        "id": "pCmPLXUo4xBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.shape"
      ],
      "metadata": {
        "id": "yS6o0qij4r6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "prediction_test = model.predict(test_df)"
      ],
      "metadata": {
        "id": "4IrroKTu29O3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_lab.reshape(-1).shape"
      ],
      "metadata": {
        "id": "1ipWx7uc8h8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_test.shape"
      ],
      "metadata": {
        "id": "1neRwBzN8h_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "utZ4h-Gl8iB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Accuracy = \", metrics.accuracy_score(test_lab.reshape(-1), prediction_test))"
      ],
      "metadata": {
        "id": "Ag0p_7WX29Rl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(test_lab)"
      ],
      "metadata": {
        "id": "qEPueDCb86L0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(prediction_test.reshape(test_lab.shape))"
      ],
      "metadata": {
        "id": "jZ5VpJdT86Or"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_lab.shape"
      ],
      "metadata": {
        "id": "2OOJgLA886Rn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_test.shape"
      ],
      "metadata": {
        "id": "lHQEIaqf29US"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "id": "TPJeyeiq29XN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vC-qzq5s3kVQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}