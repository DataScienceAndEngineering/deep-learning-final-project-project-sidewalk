{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "history_visible": true,
      "mount_file_id": "1ItgkBl74SABAlU2qeqLwzav-6BX_IwqS",
      "authorship_tag": "ABX9TyPSOD8g/BipJcY43b8Oo7Nk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DataScienceAndEngineering/deep-learning-final-project-project-sidewalk/blob/rabiul/notebooks/Rabiul/Cityscapes_data_exp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PX5satu0Mg5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Lib"
      ],
      "metadata": {
        "id": "XGHyHnxfMiFF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGYGKh7-n0l2"
      },
      "outputs": [],
      "source": [
        "#\n",
        "%%time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import PIL\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "from os.path import join, isdir\n",
        "from os import listdir, rmdir\n",
        "from shutil import move, rmtree, make_archive\n",
        "\n",
        "import cv2\n",
        "import glob\n",
        "import pickle\n",
        "\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers import Dense, Input, Dropout, Activation, Flatten, BatchNormalization, ReLU, LeakyReLU, concatenate\n",
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, AveragePooling2D, GlobalAveragePooling2D, Add"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#drive.mount('/gdrive')\n",
        "drive_root = '/content/drive/MyDrive/DL_Project/'\n",
        "\n",
        "\n",
        "COLAB_DIR = '/content/'\n",
        "GT_DIR = COLAB_DIR + 'gtFine/'\n",
        "IMG_DIR = COLAB_DIR + 'leftImg8bit/'"
      ],
      "metadata": {
        "id": "VAJX94nU0S5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initial Data processing"
      ],
      "metadata": {
        "id": "3IYRCuZwIZMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!gdown --id 1mIDcIT_7vP9cQDl_D8zgX9g4Pe18-g5q -O leftImg8bit_trainvaltest.zip\n",
        "!gdown --id 1ExL_qMIykksn_kpxZxi5DvltBgX-gHVn -O gtFine_trainvaltest.zip"
      ],
      "metadata": {
        "id": "l_PwhDStpdyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!unzip /content/drive/MyDrive/DL_Project/Data/gtFine_trainvaltest.zip\n",
        "!unzip /content/drive/MyDrive/DL_Project/Data/leftImg8bit_trainvaltest.zip"
      ],
      "metadata": {
        "id": "BjA41h_PoLsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "device = torch.device(device)\n",
        "print(device)"
      ],
      "metadata": {
        "id": "TKoj0JvQuaP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# collapse child directories\n",
        "for parent in listdir(GT_DIR):\n",
        "    parent_dir = GT_DIR + parent\n",
        "    for child in listdir(parent_dir):\n",
        "        if isdir(join(parent_dir, child)):\n",
        "            keep = glob.glob(join(parent_dir, child) + '/*_gtFine_color.png')\n",
        "            keep = [f.split('/')[-1] for f in keep]\n",
        "            for filename in list(set(listdir(join(parent_dir, child))) & set(keep)):\n",
        "                move(join(parent_dir, child, filename), join(parent_dir, filename))\n",
        "            rmtree(join(parent_dir, child))\n",
        "\n",
        "for parent in listdir(IMG_DIR):\n",
        "    parent_dir = IMG_DIR + parent\n",
        "    for child in listdir(parent_dir):\n",
        "        if isdir(join(parent_dir, child)):\n",
        "            for filename in listdir(join(parent_dir, child)):\n",
        "                move(join(parent_dir, child, filename), join(parent_dir, filename))\n",
        "            rmtree(join(parent_dir, child))"
      ],
      "metadata": {
        "id": "cymFa4ZEz9eM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# process anr archive image in smaller size\n",
        "IMG_SHAPE = 299, 299\n",
        "\n",
        "gt_train_paths = [GT_DIR+'train/' + path for path in listdir(GT_DIR+'train/')]\n",
        "gt_test_paths = [GT_DIR+'test/' + path for path in listdir(GT_DIR+'test/')]\n",
        "gt_val_paths = [GT_DIR+'val/' + path for path in listdir(GT_DIR+'val/')]\n",
        "gt_paths = gt_train_paths + gt_test_paths + gt_val_paths\n",
        "\n",
        "im_train_paths = [IMG_DIR+'train/' + path for path in listdir(IMG_DIR+'train/')]\n",
        "im_test_paths = [IMG_DIR+'test/' + path for path in listdir(IMG_DIR+'test/')]\n",
        "im_val_paths = [IMG_DIR+'val/' + path for path in listdir(IMG_DIR+'val/')]\n",
        "im_paths = im_train_paths + im_test_paths + im_val_paths\n",
        "\n",
        "def resize_image(path):\n",
        "    img = Image.open(path)\n",
        "    img.thumbnail(IMG_SHAPE)\n",
        "    out_file = join(path)\n",
        "    img.save(out_file, 'PNG')\n",
        "\n",
        "for img in gt_paths + im_paths:\n",
        "    resize_image(img)\n",
        "#saving the data for future use, avoding pre_processing task over and over \n",
        "make_archive('gtFine', 'zip', GT_DIR) \n",
        "make_archive('leftImg', 'zip', IMG_DIR)"
      ],
      "metadata": {
        "id": "Bs4aHv_O2Eyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Re-Load Pre_processed Data"
      ],
      "metadata": {
        "id": "vEaBXVZxM5-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#PreProcessed data is located in my personal Google Drive, its publically available. anyone can download it. \n",
        "!gdown --id 1kkmpZOGdncxjI6NEvFmZh85Wn2nrW3rK -O gtFine.zip\n",
        "!gdown --id 14MXcx8G3yRLljLb1K0PYX7yCl5viPP-8 -O leftImg.zip\n"
      ],
      "metadata": {
        "id": "gZT9OeDfTpWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!unzip /content/gtFine.zip -d '/content/gtFine/'\n",
        "!unzip /content/leftImg.zip -d '/content/leftImg/'"
      ],
      "metadata": {
        "id": "JR3X6yg6WCZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize image pixels\n",
        "%%time\n",
        "IMG_SIZE = 299\n",
        "BATCH_SIZE = 32\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "GT_DIR = COLAB_DIR + 'gtFine/'\n",
        "IMG_DIR = COLAB_DIR + 'leftImg/'\n",
        "\n",
        "def load_and_preprocess_image(path):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE])\n",
        "    img /= 255.0\n",
        "    return img\n",
        "\n",
        "def get_image_paths(dir):\n",
        "    return sorted([dir + path for path in listdir(dir)])\n",
        "\n",
        "# create tf.Dataset objects\n",
        "gt_train_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(GT_DIR+'train/'))\n",
        "gt_val_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(GT_DIR+'val/'))\n",
        "gt_test_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(GT_DIR+'test/'))\n",
        "\n",
        "gt_train_ds = gt_train_ds.map(load_and_preprocess_image)\n",
        "gt_val_ds = gt_val_ds.map(load_and_preprocess_image)\n",
        "gt_test_ds = gt_test_ds.map(load_and_preprocess_image)\n",
        "\n",
        "im_train_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(IMG_DIR+'train/'))\n",
        "im_val_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(IMG_DIR+'val/'))\n",
        "im_test_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(IMG_DIR+'test/'))\n",
        "\n",
        "im_train_ds = im_train_ds.map(load_and_preprocess_image)\n",
        "im_val_ds = im_val_ds.map(load_and_preprocess_image)\n",
        "im_test_ds = im_test_ds.map(load_and_preprocess_image)"
      ],
      "metadata": {
        "id": "L0w8jSOaZJix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s_B27b8NZJlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize Data"
      ],
      "metadata": {
        "id": "F69-KQ5xZcZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_images(img, gt, pred):\n",
        "    if pred is not None:\n",
        "        fig, axes = plt.subplots(1, 3, figsize=(12, 8))\n",
        "    else:\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(8, 8))\n",
        "\n",
        "    axes[0].imshow(img)\n",
        "    axes[0].set_title('Actual Image')\n",
        "\n",
        "    axes[1].imshow(gt)\n",
        "    axes[1].set_title('Masked Image')\n",
        "    \n",
        "    if pred is not None:\n",
        "        axes[2].imshow(pred)\n",
        "        axes[2].set_title('Predicted Image')"
      ],
      "metadata": {
        "id": "brniAA9N2E7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for img, gt in list(zip(im_train_ds.take(2), gt_train_ds.take(2))):\n",
        "    visualize_images(img, gt, None)"
      ],
      "metadata": {
        "id": "7oMIb8aA2E-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PQcLkHWe2FBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "bqOkQFb6O8Gk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(X,filters,block):\n",
        "    # resiudal block with dilated convolutions\n",
        "    # add skip connection at last after doing convoluion\n",
        "\n",
        "    b = 'block_'+str(block)+'_'\n",
        "    f1,f2,f3 = filters\n",
        "    X_skip = X\n",
        "\n",
        "    # block_a\n",
        "    X = Conv2D(filters=f1,kernel_size=(1,1),dilation_rate=(1,1),\n",
        "               padding='same',kernel_initializer='he_normal',name=b+'a')(X)\n",
        "    X = BatchNormalization(name=b+'batch_norm_a')(X)\n",
        "    X = LeakyReLU(alpha=0.2,name=b+'leakyrelu_a')(X)\n",
        "    # block_b\n",
        "    X = Conv2D(filters=f2,kernel_size=(3,3),dilation_rate=(2,2),\n",
        "               padding='same',kernel_initializer='he_normal',name=b+'b')(X)\n",
        "    X = BatchNormalization(name=b+'batch_norm_b')(X)\n",
        "    X = LeakyReLU(alpha=0.2,name=b+'leakyrelu_b')(X)\n",
        "    # block_c\n",
        "    X = Conv2D(filters=f3,kernel_size=(1,1),dilation_rate=(1,1),\n",
        "               padding='same',kernel_initializer='he_normal',name=b+'c')(X)\n",
        "    X = BatchNormalization(name=b+'batch_norm_c')(X)\n",
        "    # skip_conv\n",
        "    X_skip = Conv2D(filters=f3,kernel_size=(3,3),padding='same',name=b+'skip_conv')(X_skip)\n",
        "    X_skip = BatchNormalization(name=b+'batch_norm_skip_conv')(X_skip)\n",
        "    # block_c + skip_conv\n",
        "    X = Add(name=b+'add')([X,X_skip])\n",
        "    X = ReLU(name=b+'relu')(X)\n",
        "    return X\n",
        "    \n",
        "def base_feature_maps(input_layer):\n",
        "    # base covolution module to get input image feature maps \n",
        "    \n",
        "    # block_1\n",
        "    base = conv_block(input_layer,[16,16,32],'1')\n",
        "    # block_2\n",
        "    base = conv_block(base,[16,16,32],'2')\n",
        "    return base\n",
        "\n",
        "def pyramid_feature_maps(input_layer):\n",
        "    # pyramid pooling module\n",
        "    \n",
        "    base = base_feature_maps(input_layer)\n",
        "    # red\n",
        "    red = GlobalAveragePooling2D(name='red_pool')(base)\n",
        "    red = tf.keras.layers.Reshape((1,1,32))(red)\n",
        "    red = Conv2D(filters=32,kernel_size=(1,1),name='red_1_by_1')(red)\n",
        "    red = UpSampling2D(size=128,interpolation='bilinear',name='red_upsampling')(red)\n",
        "    red = tf.image.resize(red, [IMG_SIZE, IMG_SIZE])\n",
        "    # yellow\n",
        "    yellow = AveragePooling2D(pool_size=(2,2),name='yellow_pool')(base)\n",
        "    yellow = Conv2D(filters=32,kernel_size=(1,1),name='yellow_1_by_1')(yellow)\n",
        "    yellow = UpSampling2D(size=2,interpolation='bilinear',name='yellow_upsampling')(yellow)\n",
        "    yellow = tf.image.resize(yellow, [IMG_SIZE, IMG_SIZE])\n",
        "    # blue\n",
        "    blue = AveragePooling2D(pool_size=(4,4),name='blue_pool')(base)\n",
        "    blue = Conv2D(filters=32,kernel_size=(1,1),name='blue_1_by_1')(blue)\n",
        "    blue = UpSampling2D(size=4,interpolation='bilinear',name='blue_upsampling')(blue)\n",
        "    blue = tf.image.resize(blue, [IMG_SIZE, IMG_SIZE])\n",
        "    # green\n",
        "    green = AveragePooling2D(pool_size=(8,8),name='green_pool')(base)\n",
        "    green = Conv2D(filters=32,kernel_size=(1,1),name='green_1_by_1')(green)\n",
        "    green = UpSampling2D(size=8,interpolation='bilinear',name='green_upsampling')(green)\n",
        "    green = tf.image.resize(green, [IMG_SIZE, IMG_SIZE])\n",
        "    # base + red + yellow + blue + green\n",
        "    return tf.keras.layers.concatenate([base,red,yellow,blue,green])\n",
        "\n",
        "def last_conv_module(input_layer):\n",
        "    X = pyramid_feature_maps(input_layer)\n",
        "    X = Conv2D(filters=3,kernel_size=3,padding='same',name='last_conv_3_by_3')(X)\n",
        "    X = BatchNormalization(name='last_conv_3_by_3_batch_norm')(X)\n",
        "    X = Activation('sigmoid',name='last_conv_relu')(X)\n",
        "    return X"
      ],
      "metadata": {
        "id": "DzhcVr512FEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "input_shape = list(im_train_ds.take(1))[0].shape\n",
        "input_layer = tf.keras.Input(shape=input_shape, name='input')\n",
        "output_layer = last_conv_module(input_layer)\n",
        "\n",
        "model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Tqitrrk_2FHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yVlsnYWt2FKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "SmDb8up8PE0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train_ds = tf.data.Dataset.zip((im_train_ds, gt_train_ds))\n",
        "train_ds = train_ds.cache().batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "val_ds = tf.data.Dataset.zip((im_val_ds, gt_val_ds))\n",
        "val_ds = val_ds.cache().batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "test_ds = tf.data.Dataset.zip((im_test_ds, gt_test_ds))\n",
        "test_ds = test_ds.cache().batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "oejnRf5xPB3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "checkpoint_path = drive_root+'pspnet/cp.ckpt'\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2)\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics='accuracy')\n",
        "history = model.fit(train_ds, validation_data=val_ds, epochs=5, \n",
        "                    callbacks=[cp_callback, es_callback])\n",
        "model.save(drive_root + 'pspnet_trained.h5')"
      ],
      "metadata": {
        "id": "a1lSg-v1PB5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot(history):\n",
        "  acc = history.history['accuracy']\n",
        "  val_acc = history.history['val_accuracy']\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  epochs = range(1,len(acc)+1)\n",
        "\n",
        "  plt.title('Training and validation accuracy')\n",
        "  plt.plot(epochs, acc, color='blue', label='Train')\n",
        "  plt.plot(epochs, val_acc, color='orange', label='Val')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.legend()\n",
        "\n",
        "  _ = plt.figure()\n",
        "  plt.title('Training and validation loss')\n",
        "  plt.plot(epochs, loss, color='blue', label='Train')\n",
        "  plt.plot(epochs, val_loss, color='orange', label='Val')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  \n",
        "plot(history)"
      ],
      "metadata": {
        "id": "SZLKNl64OPdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(test_ds)\n",
        "print('Test Data Accuracy: ', acc)"
      ],
      "metadata": {
        "id": "7hFaFPxrOPgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9974eucIOPjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JoHjsrt5OWfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_test_ds = model.predict(train_ds)\n",
        "\n",
        "for img, gt, pred in list(zip(im_train_ds.take(5), gt_train_ds.take(5), pred_test_ds)):\n",
        "    visualize_images(img, gt, pred)"
      ],
      "metadata": {
        "id": "JdlYznsLOWh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gqAdFTBp6yJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3omd4nxE6yLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HlIDcrX56yQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fsv4S3QD6yS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unet"
      ],
      "metadata": {
        "id": "eV-sB9U56ycv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# normalize image pixels\n",
        "IMG_SIZE1 =200\n",
        "IMG_SIZE2 =256\n",
        "BATCH_SIZE = 32\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "GT_DIR = COLAB_DIR + 'gtFine/'\n",
        "IMG_DIR = COLAB_DIR + 'leftImg/'\n",
        "def load_and_preprocess_image(path):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, [IMG_SIZE1, IMG_SIZE2])\n",
        "    img /= 255.0\n",
        "    return img\n",
        "\n",
        "def get_image_paths(dir):\n",
        "    return sorted([dir + path for path in listdir(dir)])\n",
        "\n",
        "# data transformation using K-means\n",
        "def LayersToRGBImage(img):\n",
        "    colors = [(255,0,0), (0,255,0), (0,0,255), (255,255,0), (255,0,255), \n",
        "              (0,255,255), (255,255,255), (200,50,0),(50,200,0), (50,0,200), \n",
        "              (200,200,50), (0,50,200), (0,200,50), (0,0,0)]\n",
        "    \n",
        "    nimg = np.zeros((img.shape[0], img.shape[1], 3))\n",
        "    for i in range(img.shape[2]):\n",
        "        c = img[:,:,i]\n",
        "        col = colors[i]\n",
        "        \n",
        "        for j in range(3):\n",
        "            nimg[:,:,j]+=col[j]*c\n",
        "    nimg = nimg/255.0\n",
        "    return nimg\n",
        "    \n",
        "def train_kmeans(K=7):\n",
        "    colors = []\n",
        "    kmeans_gt_train_paths = [GT_DIR + 'train/' + path for path in listdir(GT_DIR + 'train/')[:20]]\n",
        "    kmeans_gt_train_ds = tf.data.Dataset.from_tensor_slices(kmeans_gt_train_paths)\n",
        "    kmeans_gt_train_ds = kmeans_gt_train_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "    for seg in kmeans_gt_train_ds:\n",
        "        colors.append(tf.reshape(seg, (seg.shape[0]*seg.shape[1], 3) ))\n",
        "    colors = tf.concat(colors, 0) \n",
        "    print(\"Training K means on colors data of shape :\",colors.shape)\n",
        "    km = KMeans(K)\n",
        "    km.fit(colors)\n",
        "    print(\"\\nK-means clustering trained\\n\", km)\n",
        "    return km\n",
        "\n",
        "# Traing a k-means classifier\n",
        "km=train_kmeans(13)\n",
        "\n",
        "def load_and_preprocess_segment(path):\n",
        "    seg = load_and_preprocess_image(path)\n",
        "    s = tf.reshape(seg, (seg.shape[0]*seg.shape[1],3))\n",
        "    s = km.predict(s)\n",
        "    s = tf.reshape(s, (seg.shape[0], seg.shape[1]))\n",
        "    n = len(km.cluster_centers_)\n",
        "    cls = np.zeros((seg.shape[0], seg.shape[1], n))\n",
        "    for i in range(n):\n",
        "        m = np.copy(s)\n",
        "        m[m!=i] = 0\n",
        "        m[m!=0] = 1\n",
        "        cls[:,:,i]=m\n",
        "\n",
        "    seg = tf.convert_to_tensor(cls, dtype=tf.float32)\n",
        "    return seg"
      ],
      "metadata": {
        "id": "wfXs3RS36z_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# train data\n",
        "im_train_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(IMG_DIR+'train/'))\n",
        "im_train_ds = im_train_ds.map(load_and_preprocess_image)\n",
        "gt_train_paths = get_image_paths(GT_DIR+'train/')\n",
        "gt_train_ds = map(load_and_preprocess_segment, gt_train_paths)"
      ],
      "metadata": {
        "id": "rpni2k_Q_zwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "gt_train_ds = tf.data.Dataset.from_tensor_slices([a for a in gt_train_ds])"
      ],
      "metadata": {
        "id": "jWcRsrdg_z7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KfOA-fAmA4px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yAeQ6kT2A4sT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SiicXBgOA4uz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# train data\n",
        "im_train_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(IMG_DIR+'train/'))\n",
        "im_train_ds = im_train_ds.map(load_and_preprocess_image)\n",
        "\n",
        "gt_train_paths = get_image_paths(GT_DIR+'train/')\n",
        "gt_train_ds = map(load_and_preprocess_segment, gt_train_paths)\n",
        "gt_train_ds = tf.data.Dataset.from_tensor_slices([a for a in gt_train_ds])\n",
        "train_ds = tf.data.Dataset.zip((im_train_ds, gt_train_ds))\n",
        "train_ds = train_ds.cache().batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "print('Training Data:\\n# of batches, Input batch shape, Ouput batch shape')\n",
        "print(len(train_ds), next(iter(train_ds))[0].shape, next(iter(train_ds))[1].shape)"
      ],
      "metadata": {
        "id": "uS8i9DCT7ss9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# val data\n",
        "im_val_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(IMG_DIR+'val/'))\n",
        "im_val_ds = im_val_ds.map(load_and_preprocess_image)\n",
        "\n",
        "gt_val_paths = get_image_paths(GT_DIR+'val/')\n",
        "gt_val_ds = map(load_and_preprocess_segment, gt_val_paths)\n",
        "gt_val_ds = tf.data.Dataset.from_tensor_slices([a for a in gt_val_ds])\n",
        "val_ds = tf.data.Dataset.zip((im_val_ds, gt_val_ds))\n",
        "val_ds = val_ds.cache().batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "\n",
        "print('Validation Data:\\n# of batches, Input batch shape, Ouput batch shape')\n",
        "print(len(val_ds), next(iter(val_ds))[0].shape, next(iter(val_ds))[1].shape)"
      ],
      "metadata": {
        "id": "UVjHuYz47syg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# test data\n",
        "im_test_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(IMG_DIR+'test/'))\n",
        "im_test_ds = im_test_ds.map(load_and_preprocess_image)\n",
        "\n",
        "gt_test_paths = get_image_paths(GT_DIR+'test/')\n",
        "gt_test_ds = map(load_and_preprocess_segment, gt_test_paths)\n",
        "gt_test_ds = tf.data.Dataset.from_tensor_slices([a for a in gt_test_ds])\n",
        "test_ds = tf.data.Dataset.zip((im_test_ds, gt_test_ds))\n",
        "test_ds = test_ds.cache().batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "print('Testing Data:\\n# of batches, Input batch shape, Ouput batch shape')\n",
        "print(len(test_ds), next(iter(test_ds))[0].shape, next(iter(test_ds))[1].shape)"
      ],
      "metadata": {
        "id": "gfQiIyNX7s1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time"
      ],
      "metadata": {
        "id": "qe3MSTYI7s4F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}