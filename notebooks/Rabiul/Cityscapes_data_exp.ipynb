{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DataScienceAndEngineering/deep-learning-final-project-project-sidewalk/blob/rabiul/notebooks/Rabiul/Cityscapes_data_exp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PX5satu0Mg5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Lib"
      ],
      "metadata": {
        "id": "XGHyHnxfMiFF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGYGKh7-n0l2"
      },
      "outputs": [],
      "source": [
        "#\n",
        "%%time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import PIL\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "from os.path import join, isdir\n",
        "from os import listdir, rmdir\n",
        "from shutil import move, rmtree, make_archive\n",
        "\n",
        "import cv2\n",
        "import glob\n",
        "import pickle\n",
        "\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers import Dense, Input, Dropout, Activation, Flatten, BatchNormalization, ReLU, LeakyReLU, concatenate\n",
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, AveragePooling2D, GlobalAveragePooling2D, Add"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#drive.mount('/gdrive')\n",
        "drive_root = '/content/drive/MyDrive/DL_Project/'\n",
        "\n",
        "\n",
        "COLAB_DIR = '/content/'\n",
        "GT_DIR = COLAB_DIR + 'gtFine/'\n",
        "IMG_DIR = COLAB_DIR + 'leftImg8bit/'"
      ],
      "metadata": {
        "id": "VAJX94nU0S5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initial Data processing"
      ],
      "metadata": {
        "id": "3IYRCuZwIZMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!gdown --id 1mIDcIT_7vP9cQDl_D8zgX9g4Pe18-g5q -O leftImg8bit_trainvaltest.zip\n",
        "!gdown --id 1ExL_qMIykksn_kpxZxi5DvltBgX-gHVn -O gtFine_trainvaltest.zip"
      ],
      "metadata": {
        "id": "l_PwhDStpdyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!unzip /content/drive/MyDrive/DL_Project/Data/gtFine_trainvaltest.zip\n",
        "!unzip /content/drive/MyDrive/DL_Project/Data/leftImg8bit_trainvaltest.zip"
      ],
      "metadata": {
        "id": "BjA41h_PoLsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "device = torch.device(device)\n",
        "print(device)"
      ],
      "metadata": {
        "id": "TKoj0JvQuaP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# collapse child directories\n",
        "for parent in listdir(GT_DIR):\n",
        "    parent_dir = GT_DIR + parent\n",
        "    for child in listdir(parent_dir):\n",
        "        if isdir(join(parent_dir, child)):\n",
        "            keep = glob.glob(join(parent_dir, child) + '/*_gtFine_color.png')\n",
        "            keep = [f.split('/')[-1] for f in keep]\n",
        "            for filename in list(set(listdir(join(parent_dir, child))) & set(keep)):\n",
        "                move(join(parent_dir, child, filename), join(parent_dir, filename))\n",
        "            rmtree(join(parent_dir, child))\n",
        "\n",
        "for parent in listdir(IMG_DIR):\n",
        "    parent_dir = IMG_DIR + parent\n",
        "    for child in listdir(parent_dir):\n",
        "        if isdir(join(parent_dir, child)):\n",
        "            for filename in listdir(join(parent_dir, child)):\n",
        "                move(join(parent_dir, child, filename), join(parent_dir, filename))\n",
        "            rmtree(join(parent_dir, child))"
      ],
      "metadata": {
        "id": "cymFa4ZEz9eM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# process anr archive image in smaller size\n",
        "IMG_SHAPE = 299, 299\n",
        "\n",
        "gt_train_paths = [GT_DIR+'train/' + path for path in listdir(GT_DIR+'train/')]\n",
        "gt_test_paths = [GT_DIR+'test/' + path for path in listdir(GT_DIR+'test/')]\n",
        "gt_val_paths = [GT_DIR+'val/' + path for path in listdir(GT_DIR+'val/')]\n",
        "gt_paths = gt_train_paths + gt_test_paths + gt_val_paths\n",
        "\n",
        "im_train_paths = [IMG_DIR+'train/' + path for path in listdir(IMG_DIR+'train/')]\n",
        "im_test_paths = [IMG_DIR+'test/' + path for path in listdir(IMG_DIR+'test/')]\n",
        "im_val_paths = [IMG_DIR+'val/' + path for path in listdir(IMG_DIR+'val/')]\n",
        "im_paths = im_train_paths + im_test_paths + im_val_paths\n",
        "\n",
        "def resize_image(path):\n",
        "    img = Image.open(path)\n",
        "    img.thumbnail(IMG_SHAPE)\n",
        "    out_file = join(path)\n",
        "    img.save(out_file, 'PNG')\n",
        "\n",
        "for img in gt_paths + im_paths:\n",
        "    resize_image(img)\n",
        "#saving the data for future use, avoding pre_processing task over and over \n",
        "make_archive('gtFine', 'zip', GT_DIR) \n",
        "make_archive('leftImg', 'zip', IMG_DIR)"
      ],
      "metadata": {
        "id": "Bs4aHv_O2Eyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Re-Load Pre_processed Data"
      ],
      "metadata": {
        "id": "vEaBXVZxM5-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#PreProcessed data is located in my personal Google Drive, its publically available. anyone can download it. \n",
        "!gdown --id 1kkmpZOGdncxjI6NEvFmZh85Wn2nrW3rK -O gtFine.zip\n",
        "!gdown --id 14MXcx8G3yRLljLb1K0PYX7yCl5viPP-8 -O leftImg.zip\n"
      ],
      "metadata": {
        "id": "gZT9OeDfTpWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!unzip /content/gtFine.zip -d '/content/gtFine/'\n",
        "!unzip /content/leftImg.zip -d '/content/leftImg/'"
      ],
      "metadata": {
        "id": "JR3X6yg6WCZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize image pixels\n",
        "%%time\n",
        "IMG_SIZE = 299\n",
        "BATCH_SIZE = 32\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "GT_DIR = COLAB_DIR + 'gtFine/'\n",
        "IMG_DIR = COLAB_DIR + 'leftImg/'\n",
        "\n",
        "def load_and_preprocess_image(path):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE])\n",
        "    img /= 255.0\n",
        "    return img\n",
        "\n",
        "def get_image_paths(dir):\n",
        "    return sorted([dir + path for path in listdir(dir)])\n",
        "\n",
        "# create tf.Dataset objects\n",
        "gt_train_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(GT_DIR+'train/'))\n",
        "gt_val_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(GT_DIR+'val/'))\n",
        "gt_test_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(GT_DIR+'test/'))\n",
        "\n",
        "gt_train_ds = gt_train_ds.map(load_and_preprocess_image)\n",
        "gt_val_ds = gt_val_ds.map(load_and_preprocess_image)\n",
        "gt_test_ds = gt_test_ds.map(load_and_preprocess_image)\n",
        "\n",
        "im_train_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(IMG_DIR+'train/'))\n",
        "im_val_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(IMG_DIR+'val/'))\n",
        "im_test_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(IMG_DIR+'test/'))\n",
        "\n",
        "im_train_ds = im_train_ds.map(load_and_preprocess_image)\n",
        "im_val_ds = im_val_ds.map(load_and_preprocess_image)\n",
        "im_test_ds = im_test_ds.map(load_and_preprocess_image)"
      ],
      "metadata": {
        "id": "L0w8jSOaZJix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s_B27b8NZJlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize Data"
      ],
      "metadata": {
        "id": "F69-KQ5xZcZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_images(img, gt, pred):\n",
        "    if pred is not None:\n",
        "        fig, axes = plt.subplots(1, 3, figsize=(12, 8))\n",
        "    else:\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(8, 8))\n",
        "\n",
        "    axes[0].imshow(img)\n",
        "    axes[0].set_title('Actual Image')\n",
        "\n",
        "    axes[1].imshow(gt)\n",
        "    axes[1].set_title('Masked Image')\n",
        "    \n",
        "    if pred is not None:\n",
        "        axes[2].imshow(pred)\n",
        "        axes[2].set_title('Predicted Image')"
      ],
      "metadata": {
        "id": "brniAA9N2E7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for img, gt in list(zip(im_train_ds.take(2), gt_train_ds.take(2))):\n",
        "    visualize_images(img, gt, None)"
      ],
      "metadata": {
        "id": "7oMIb8aA2E-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PQcLkHWe2FBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "bqOkQFb6O8Gk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(X,filters,block):\n",
        "    # resiudal block with dilated convolutions\n",
        "    # add skip connection at last after doing convoluion\n",
        "\n",
        "    b = 'block_'+str(block)+'_'\n",
        "    f1,f2,f3 = filters\n",
        "    X_skip = X\n",
        "\n",
        "    # block_a\n",
        "    X = Conv2D(filters=f1,kernel_size=(1,1),dilation_rate=(1,1),\n",
        "               padding='same',kernel_initializer='he_normal',name=b+'a')(X)\n",
        "    X = BatchNormalization(name=b+'batch_norm_a')(X)\n",
        "    X = LeakyReLU(alpha=0.2,name=b+'leakyrelu_a')(X)\n",
        "    # block_b\n",
        "    X = Conv2D(filters=f2,kernel_size=(3,3),dilation_rate=(2,2),\n",
        "               padding='same',kernel_initializer='he_normal',name=b+'b')(X)\n",
        "    X = BatchNormalization(name=b+'batch_norm_b')(X)\n",
        "    X = LeakyReLU(alpha=0.2,name=b+'leakyrelu_b')(X)\n",
        "    # block_c\n",
        "    X = Conv2D(filters=f3,kernel_size=(1,1),dilation_rate=(1,1),\n",
        "               padding='same',kernel_initializer='he_normal',name=b+'c')(X)\n",
        "    X = BatchNormalization(name=b+'batch_norm_c')(X)\n",
        "    # skip_conv\n",
        "    X_skip = Conv2D(filters=f3,kernel_size=(3,3),padding='same',name=b+'skip_conv')(X_skip)\n",
        "    X_skip = BatchNormalization(name=b+'batch_norm_skip_conv')(X_skip)\n",
        "    # block_c + skip_conv\n",
        "    X = Add(name=b+'add')([X,X_skip])\n",
        "    X = ReLU(name=b+'relu')(X)\n",
        "    return X\n",
        "    \n",
        "def base_feature_maps(input_layer):\n",
        "    # base covolution module to get input image feature maps \n",
        "    \n",
        "    # block_1\n",
        "    base = conv_block(input_layer,[16,16,32],'1')\n",
        "    # block_2\n",
        "    base = conv_block(base,[16,16,32],'2')\n",
        "    return base\n",
        "\n",
        "def pyramid_feature_maps(input_layer):\n",
        "    # pyramid pooling module\n",
        "    \n",
        "    base = base_feature_maps(input_layer)\n",
        "    # red\n",
        "    red = GlobalAveragePooling2D(name='red_pool')(base)\n",
        "    red = tf.keras.layers.Reshape((1,1,32))(red)\n",
        "    red = Conv2D(filters=32,kernel_size=(1,1),name='red_1_by_1')(red)\n",
        "    red = UpSampling2D(size=128,interpolation='bilinear',name='red_upsampling')(red)\n",
        "    red = tf.image.resize(red, [IMG_SIZE, IMG_SIZE])\n",
        "    # yellow\n",
        "    yellow = AveragePooling2D(pool_size=(2,2),name='yellow_pool')(base)\n",
        "    yellow = Conv2D(filters=32,kernel_size=(1,1),name='yellow_1_by_1')(yellow)\n",
        "    yellow = UpSampling2D(size=2,interpolation='bilinear',name='yellow_upsampling')(yellow)\n",
        "    yellow = tf.image.resize(yellow, [IMG_SIZE, IMG_SIZE])\n",
        "    # blue\n",
        "    blue = AveragePooling2D(pool_size=(4,4),name='blue_pool')(base)\n",
        "    blue = Conv2D(filters=32,kernel_size=(1,1),name='blue_1_by_1')(blue)\n",
        "    blue = UpSampling2D(size=4,interpolation='bilinear',name='blue_upsampling')(blue)\n",
        "    blue = tf.image.resize(blue, [IMG_SIZE, IMG_SIZE])\n",
        "    # green\n",
        "    green = AveragePooling2D(pool_size=(8,8),name='green_pool')(base)\n",
        "    green = Conv2D(filters=32,kernel_size=(1,1),name='green_1_by_1')(green)\n",
        "    green = UpSampling2D(size=8,interpolation='bilinear',name='green_upsampling')(green)\n",
        "    green = tf.image.resize(green, [IMG_SIZE, IMG_SIZE])\n",
        "    # base + red + yellow + blue + green\n",
        "    return tf.keras.layers.concatenate([base,red,yellow,blue,green])\n",
        "\n",
        "def last_conv_module(input_layer):\n",
        "    X = pyramid_feature_maps(input_layer)\n",
        "    X = Conv2D(filters=3,kernel_size=3,padding='same',name='last_conv_3_by_3')(X)\n",
        "    X = BatchNormalization(name='last_conv_3_by_3_batch_norm')(X)\n",
        "    X = Activation('sigmoid',name='last_conv_relu')(X)\n",
        "    return X"
      ],
      "metadata": {
        "id": "DzhcVr512FEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "input_shape = list(im_train_ds.take(1))[0].shape\n",
        "input_layer = tf.keras.Input(shape=input_shape, name='input')\n",
        "output_layer = last_conv_module(input_layer)\n",
        "\n",
        "model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Tqitrrk_2FHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yVlsnYWt2FKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "SmDb8up8PE0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train_ds = tf.data.Dataset.zip((im_train_ds, gt_train_ds))\n",
        "train_ds = train_ds.cache().batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "val_ds = tf.data.Dataset.zip((im_val_ds, gt_val_ds))\n",
        "val_ds = val_ds.cache().batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "test_ds = tf.data.Dataset.zip((im_test_ds, gt_test_ds))\n",
        "test_ds = test_ds.cache().batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "oejnRf5xPB3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "checkpoint_path = drive_root+'pspnet/cp.ckpt'\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2)\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics='accuracy')\n",
        "history = model.fit(train_ds, validation_data=val_ds, epochs=5, \n",
        "                    callbacks=[cp_callback, es_callback])\n",
        "model.save(drive_root + 'pspnet_trained.h5')"
      ],
      "metadata": {
        "id": "a1lSg-v1PB5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot(history):\n",
        "  acc = history.history['accuracy']\n",
        "  val_acc = history.history['val_accuracy']\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  epochs = range(1,len(acc)+1)\n",
        "\n",
        "  plt.title('Training and validation accuracy')\n",
        "  plt.plot(epochs, acc, color='blue', label='Train')\n",
        "  plt.plot(epochs, val_acc, color='orange', label='Val')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.legend()\n",
        "\n",
        "  _ = plt.figure()\n",
        "  plt.title('Training and validation loss')\n",
        "  plt.plot(epochs, loss, color='blue', label='Train')\n",
        "  plt.plot(epochs, val_loss, color='orange', label='Val')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  \n",
        "plot(history)"
      ],
      "metadata": {
        "id": "SZLKNl64OPdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(test_ds)\n",
        "print('Test Data Accuracy: ', acc)"
      ],
      "metadata": {
        "id": "7hFaFPxrOPgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9974eucIOPjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JoHjsrt5OWfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_test_ds = model.predict(train_ds)\n",
        "\n",
        "for img, gt, pred in list(zip(im_train_ds.take(5), gt_train_ds.take(5), pred_test_ds)):\n",
        "    visualize_images(img, gt, pred)"
      ],
      "metadata": {
        "id": "JdlYznsLOWh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gqAdFTBp6yJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3omd4nxE6yLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HlIDcrX56yQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fsv4S3QD6yS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unet"
      ],
      "metadata": {
        "id": "eV-sB9U56ycv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# normalize image pixels\n",
        "IMG_SIZE1 =200\n",
        "IMG_SIZE2 =256\n",
        "BATCH_SIZE = 32\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "GT_DIR = COLAB_DIR + 'gtFine/'\n",
        "IMG_DIR = COLAB_DIR + 'leftImg/'\n",
        "def load_and_preprocess_image(path):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, [IMG_SIZE1, IMG_SIZE2])\n",
        "    img /= 255.0\n",
        "    return img\n",
        "\n",
        "def get_image_paths(dir):\n",
        "    return sorted([dir + path for path in listdir(dir)])\n",
        "\n",
        "# data transformation using K-means\n",
        "def LayersToRGBImage(img):\n",
        "    colors = [(255,0,0), (0,255,0), (0,0,255), (255,255,0), (255,0,255), \n",
        "              (0,255,255), (255,255,255), (200,50,0),(50,200,0), (50,0,200), \n",
        "              (200,200,50), (0,50,200), (0,200,50), (0,0,0)]\n",
        "    \n",
        "    nimg = np.zeros((img.shape[0], img.shape[1], 3))\n",
        "    for i in range(img.shape[2]):\n",
        "        c = img[:,:,i]\n",
        "        col = colors[i]\n",
        "        \n",
        "        for j in range(3):\n",
        "            nimg[:,:,j]+=col[j]*c\n",
        "    nimg = nimg/255.0\n",
        "    return nimg\n",
        "    \n",
        "def train_kmeans(K=7):\n",
        "    colors = []\n",
        "    kmeans_gt_train_paths = [GT_DIR + 'train/' + path for path in listdir(GT_DIR + 'train/')[:20]]\n",
        "    kmeans_gt_train_ds = tf.data.Dataset.from_tensor_slices(kmeans_gt_train_paths)\n",
        "    kmeans_gt_train_ds = kmeans_gt_train_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "    for seg in kmeans_gt_train_ds:\n",
        "        colors.append(tf.reshape(seg, (seg.shape[0]*seg.shape[1], 3) ))\n",
        "    colors = tf.concat(colors, 0) \n",
        "    print(\"Training K means on colors data of shape :\",colors.shape)\n",
        "    km = KMeans(K)\n",
        "    km.fit(colors)\n",
        "    print(\"\\nK-means clustering trained\\n\", km)\n",
        "    return km\n",
        "\n",
        "# Traing a k-means classifier\n",
        "km=train_kmeans(13)\n",
        "\n",
        "def load_and_preprocess_segment(path):\n",
        "    seg = load_and_preprocess_image(path)\n",
        "    s = tf.reshape(seg, (seg.shape[0]*seg.shape[1],3))\n",
        "    s = km.predict(s)\n",
        "    s = tf.reshape(s, (seg.shape[0], seg.shape[1]))\n",
        "    n = len(km.cluster_centers_)\n",
        "    cls = np.zeros((seg.shape[0], seg.shape[1], n))\n",
        "    for i in range(n):\n",
        "        m = np.copy(s)\n",
        "        m[m!=i] = 0\n",
        "        m[m!=0] = 1\n",
        "        cls[:,:,i]=m\n",
        "\n",
        "    seg = tf.convert_to_tensor(cls, dtype=tf.float32)\n",
        "    return seg"
      ],
      "metadata": {
        "id": "wfXs3RS36z_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# train data\n",
        "im_train_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(IMG_DIR+'train/'))\n",
        "im_train_ds = im_train_ds.map(load_and_preprocess_image)\n",
        "gt_train_paths = get_image_paths(GT_DIR+'train/')\n",
        "gt_train_ds = map(load_and_preprocess_segment, gt_train_paths)"
      ],
      "metadata": {
        "id": "rpni2k_Q_zwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "gt_train_ds = tf.data.Dataset.from_tensor_slices([a for a in gt_train_ds])"
      ],
      "metadata": {
        "id": "jWcRsrdg_z7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KfOA-fAmA4px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yAeQ6kT2A4sT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SiicXBgOA4uz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# train data\n",
        "im_train_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(IMG_DIR+'train/'))\n",
        "im_train_ds = im_train_ds.map(load_and_preprocess_image)\n",
        "\n",
        "gt_train_paths = get_image_paths(GT_DIR+'train/')\n",
        "gt_train_ds = map(load_and_preprocess_segment, gt_train_paths)\n",
        "gt_train_ds = tf.data.Dataset.from_tensor_slices([a for a in gt_train_ds])\n",
        "train_ds = tf.data.Dataset.zip((im_train_ds, gt_train_ds))\n",
        "train_ds = train_ds.cache().batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "print('Training Data:\\n# of batches, Input batch shape, Ouput batch shape')\n",
        "print(len(train_ds), next(iter(train_ds))[0].shape, next(iter(train_ds))[1].shape)"
      ],
      "metadata": {
        "id": "uS8i9DCT7ss9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# val data\n",
        "im_val_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(IMG_DIR+'val/'))\n",
        "im_val_ds = im_val_ds.map(load_and_preprocess_image)\n",
        "\n",
        "gt_val_paths = get_image_paths(GT_DIR+'val/')\n",
        "gt_val_ds = map(load_and_preprocess_segment, gt_val_paths)\n",
        "gt_val_ds = tf.data.Dataset.from_tensor_slices([a for a in gt_val_ds])\n",
        "val_ds = tf.data.Dataset.zip((im_val_ds, gt_val_ds))\n",
        "val_ds = val_ds.cache().batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "\n",
        "print('Validation Data:\\n# of batches, Input batch shape, Ouput batch shape')\n",
        "print(len(val_ds), next(iter(val_ds))[0].shape, next(iter(val_ds))[1].shape)"
      ],
      "metadata": {
        "id": "UVjHuYz47syg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# test data\n",
        "im_test_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(IMG_DIR+'test/'))\n",
        "im_test_ds = im_test_ds.map(load_and_preprocess_image)\n",
        "\n",
        "gt_test_paths = get_image_paths(GT_DIR+'test/')\n",
        "gt_test_ds = map(load_and_preprocess_segment, gt_test_paths)\n",
        "gt_test_ds = tf.data.Dataset.from_tensor_slices([a for a in gt_test_ds])\n",
        "test_ds = tf.data.Dataset.zip((im_test_ds, gt_test_ds))\n",
        "test_ds = test_ds.cache().batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "print('Testing Data:\\n# of batches, Input batch shape, Ouput batch shape')\n",
        "print(len(test_ds), next(iter(test_ds))[0].shape, next(iter(test_ds))[1].shape)"
      ],
      "metadata": {
        "id": "gfQiIyNX7s1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time"
      ],
      "metadata": {
        "id": "qe3MSTYI7s4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UmGQ-e9Stfr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8oz-BgnStfuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline Model"
      ],
      "metadata": {
        "id": "td5Cz67Htf3U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Lib"
      ],
      "metadata": {
        "id": "7QcascrI7M07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import cv2\n",
        "import os\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from skimage.filters import sobel"
      ],
      "metadata": {
        "id": "PO2TnZE37PmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s2u0b8Xd7Ron"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KjR7TqDj7RuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Loading Data"
      ],
      "metadata": {
        "id": "fYPpYVlJ7ALs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!gdown --id 12rNfOiM4allOn8t4l0ErpvgmA9hEZPh2 -O processed_labels.zip\n",
        "!gdown --id 145Ul0rdbQcX98lQz8IO5eOtI0ZlvKwz6 -O processed_images.zip"
      ],
      "metadata": {
        "id": "nlkvBNXItiHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!unzip /content/processed_images.zip\n",
        "!unzip /content/processed_labels.zip"
      ],
      "metadata": {
        "id": "iRtqOCbcvSTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-Processing Data"
      ],
      "metadata": {
        "id": "tCDqzox07E_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = '/content/content/processed_images/*'\n",
        "lab_path = '/content/content/processed_labels/*'"
      ],
      "metadata": {
        "id": "J8gwWlhN8Oq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the data indo a list, numpy array\n",
        "\n",
        "train_images = glob.glob(img_path)\n",
        "train_label = glob.glob(lab_path)\n",
        "\n",
        "print(len(train_images))\n",
        "print(len(train_labels))"
      ],
      "metadata": {
        "id": "4ZMBHtR1veez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = train_images[0]\n",
        "lab = train_label[0]\n",
        "print(img)\n",
        "print(lab)"
      ],
      "metadata": {
        "id": "1vO6BgyV9GM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread(img, 0)\n",
        "print(img)"
      ],
      "metadata": {
        "id": "OKDINCu39JXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a data frame with orginal image \n",
        "img2 = img.reshape(-1)\n",
        "df = pd.DataFrame()\n",
        "df['Orginal_img'] = img2"
      ],
      "metadata": {
        "id": "taAzxviw-2Mh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "6YWhPRAH-2PU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#Generate Gabor features\n",
        "num = 1  #To count numbers up in order to give Gabor features a lable in the data frame\n",
        "kernels = []\n",
        "for theta in range(2):   #Define number of thetas\n",
        "    theta = theta / 4. * np.pi\n",
        "    for sigma in (1, 3):  #Sigma with 1 and 3\n",
        "        for lamda in np.arange(0, np.pi, np.pi / 4):   #Range of wavelengths\n",
        "            for gamma in (0.05, 0.5):   #Gamma values of 0.05 and 0.5\n",
        "            \n",
        "                \n",
        "                gabor_label = 'Gabor' + str(num)  #Label Gabor columns as Gabor1, Gabor2, etc.\n",
        "#                print(gabor_label)\n",
        "                ksize=9\n",
        "                kernel = cv2.getGaborKernel((ksize, ksize), sigma, theta, lamda, gamma, 0, ktype=cv2.CV_32F)    \n",
        "                kernels.append(kernel)\n",
        "                #Now filter the image and add values to a new column \n",
        "                fimg = cv2.filter2D(img, cv2.CV_8UC3, kernel)\n",
        "                filtered_img = fimg.reshape(-1)\n",
        "                df[gabor_label] = filtered_img  #Labels columns as Gabor1, Gabor2, etc.\n",
        "                print(gabor_label, ': theta=', theta, ': sigma=', sigma, ': lamda=', lamda, ': gamma=', gamma)\n",
        "                num += 1  #Increment for gabor column label"
      ],
      "metadata": {
        "id": "LxZF7j9o-2SD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "OJYJlq4F-8gI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########################################\n",
        "#Gerate OTHER FEATURES and add them to the data frame\n",
        "                \n",
        "#CANNY EDGE\n",
        "edges = cv2.Canny(img, 100,200)   #Image, min and max values\n",
        "edges1 = edges.reshape(-1)\n",
        "df['Canny Edge'] = edges1 #Add column to original dataframe\n",
        "\n",
        "from skimage.filters import roberts, sobel, scharr, prewitt\n",
        "\n",
        "#ROBERTS EDGE\n",
        "edge_roberts = roberts(img)\n",
        "edge_roberts1 = edge_roberts.reshape(-1)\n",
        "df['Roberts'] = edge_roberts1\n",
        "\n",
        "#SOBEL\n",
        "edge_sobel = sobel(img)\n",
        "edge_sobel1 = edge_sobel.reshape(-1)\n",
        "df['Sobel'] = edge_sobel1\n",
        "\n",
        "#SCHARR\n",
        "edge_scharr = scharr(img)\n",
        "edge_scharr1 = edge_scharr.reshape(-1)\n",
        "df['Scharr'] = edge_scharr1\n",
        "\n",
        "#PREWITT\n",
        "edge_prewitt = prewitt(img)\n",
        "edge_prewitt1 = edge_prewitt.reshape(-1)\n",
        "df['Prewitt'] = edge_prewitt1\n",
        "\n",
        "#GAUSSIAN with sigma=3\n",
        "from scipy import ndimage as nd\n",
        "gaussian_img = nd.gaussian_filter(img, sigma=3)\n",
        "gaussian_img1 = gaussian_img.reshape(-1)\n",
        "df['Gaussian s3'] = gaussian_img1\n",
        "\n",
        "#GAUSSIAN with sigma=7\n",
        "gaussian_img2 = nd.gaussian_filter(img, sigma=7)\n",
        "gaussian_img3 = gaussian_img2.reshape(-1)\n",
        "df['Gaussian s7'] = gaussian_img3\n",
        "\n",
        "#MEDIAN with sigma=3\n",
        "median_img = nd.median_filter(img, size=3)\n",
        "median_img1 = median_img.reshape(-1)\n",
        "df['Median s3'] = median_img1"
      ],
      "metadata": {
        "id": "jnADeMeE-8jV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VzVLyCJy-8lz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for directory_path in glob.glob(\"images/natural/train/*\"):\n",
        "    label = directory_path.split(\"\\\\\")[-1]\n",
        "    print(label)\n",
        "    for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
        "        print(img_path)\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_COLOR) #Reading color images\n",
        "        img = cv2.resize(img, (SIZE, SIZE)) #Resize images\n",
        "        #img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) #Optional step. Change BGR to RGB\n",
        "        train_images.append(img)\n",
        "        train_labels.append(label)\n",
        "        \n",
        "train_images = np.array(train_images)\n",
        "train_labels = np.array(train_labels)"
      ],
      "metadata": {
        "id": "aSL8N958wCa4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now, add a column in the data frame for the Labels\n",
        "#For this, we need to import the labeled image\n",
        "labeled_img = cv2.imread(lab)\n",
        "#Remember that you can load an image with partial labels \n",
        "#But, drop the rows with unlabeled data\n",
        "\n",
        "labeled_img = cv2.cvtColor(labeled_img, cv2.COLOR_BGR2GRAY)\n",
        "labeled_img1 = labeled_img.reshape(-1)\n",
        "df['Labels'] = labeled_img1\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "Kl8rpgFVwCdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_img_data = df.drop(labels = [\"Labels\"], axis=1) #Use for prediction\n",
        "#df.to_csv(\"Gabor.csv\")\n",
        "df = df[df.Labels != 0]"
      ],
      "metadata": {
        "id": "5mpc7b02wCg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the dependent variable that needs to be predicted (labels)\n",
        "Y = df[\"Labels\"].values\n",
        "\n",
        "#Encode Y values to 0, 1, 2, 3, .... (NOt necessary but makes it easy to use other tools like ROC plots)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "Y = LabelEncoder().fit_transform(Y)\n",
        "\n",
        "\n",
        "#Define the independent variables\n",
        "X = df.drop(labels = [\"Labels\"], axis=1) "
      ],
      "metadata": {
        "id": "CclVYTGmLjCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split data into train and test to verify accuracy after fitting the model. \n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=20)\n",
        "\n"
      ],
      "metadata": {
        "id": "QFzYSLgeLjFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# Instantiate model with n number of decision trees\n",
        "model = RandomForestClassifier(n_estimators = 20, random_state = 42)\n",
        "\n",
        "# Train the model on training data\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "3UlI1atsLjIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_list = list(X.columns)\n",
        "feature_imp = pd.Series(model.feature_importances_,index=feature_list).sort_values(ascending=False)\n",
        "print(feature_imp)"
      ],
      "metadata": {
        "id": "pwrd_OXDLjLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_RF = model.predict(X_test)"
      ],
      "metadata": {
        "id": "U3Tzh2FzMZfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "#Print the prediction accuracy\n",
        "#Check accuracy on test dataset. If this is too low compared to train it indicates overfitting on training data.\n",
        "print (\"Accuracy using Random Forest= \", metrics.accuracy_score(y_test, prediction_RF))"
      ],
      "metadata": {
        "id": "zZc0OU7cMbSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0LUuK4FXMbYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PjK6cjZlMbaa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}