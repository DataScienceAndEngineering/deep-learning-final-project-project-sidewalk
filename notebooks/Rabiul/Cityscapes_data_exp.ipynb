{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "3IYRCuZwIZMe",
        "WoXAEEd0sJk6"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DataScienceAndEngineering/deep-learning-final-project-project-sidewalk/blob/rabiul/notebooks/Rabiul/Cityscapes_data_exp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Lib"
      ],
      "metadata": {
        "id": "XGHyHnxfMiFF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGYGKh7-n0l2"
      },
      "outputs": [],
      "source": [
        "#\n",
        "%%time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import PIL\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "from os.path import join, isdir\n",
        "from os import listdir, rmdir\n",
        "from shutil import move, rmtree, make_archive\n",
        "\n",
        "import cv2\n",
        "import glob\n",
        "import pickle\n",
        "\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers import Dense, Input, Dropout, Activation, Flatten, BatchNormalization, ReLU, LeakyReLU, concatenate\n",
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, AveragePooling2D, GlobalAveragePooling2D, Add"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#drive.mount('/gdrive')\n",
        "drive_root = '/content/drive/MyDrive/DL_Project/'\n",
        "\n",
        "COLAB_DIR = '/content/'\n",
        "GT_DIR = COLAB_DIR + 'gtFine/'\n",
        "IMG_DIR = COLAB_DIR + 'leftImg8bit/'"
      ],
      "metadata": {
        "id": "VAJX94nU0S5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initial Data processing"
      ],
      "metadata": {
        "id": "3IYRCuZwIZMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!gdown --id 1mIDcIT_7vP9cQDl_D8zgX9g4Pe18-g5q -O leftImg8bit_trainvaltest.zip\n",
        "!gdown --id 1ExL_qMIykksn_kpxZxi5DvltBgX-gHVn -O gtFine_trainvaltest.zip"
      ],
      "metadata": {
        "id": "l_PwhDStpdyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!unzip /content/drive/MyDrive/DL_Project/Data/gtFine_trainvaltest.zip\n",
        "!unzip /content/drive/MyDrive/DL_Project/Data/leftImg8bit_trainvaltest.zip"
      ],
      "metadata": {
        "id": "BjA41h_PoLsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "device = torch.device(device)\n",
        "print(device)"
      ],
      "metadata": {
        "id": "TKoj0JvQuaP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# collapse child directories\n",
        "for parent in listdir(GT_DIR):\n",
        "    parent_dir = GT_DIR + parent\n",
        "    for child in listdir(parent_dir):\n",
        "        if isdir(join(parent_dir, child)):\n",
        "            keep = glob.glob(join(parent_dir, child) + '/*_gtFine_color.png')\n",
        "            keep = [f.split('/')[-1] for f in keep]\n",
        "            for filename in list(set(listdir(join(parent_dir, child))) & set(keep)):\n",
        "                move(join(parent_dir, child, filename), join(parent_dir, filename))\n",
        "            rmtree(join(parent_dir, child))\n",
        "\n",
        "for parent in listdir(IMG_DIR):\n",
        "    parent_dir = IMG_DIR + parent\n",
        "    for child in listdir(parent_dir):\n",
        "        if isdir(join(parent_dir, child)):\n",
        "            for filename in listdir(join(parent_dir, child)):\n",
        "                move(join(parent_dir, child, filename), join(parent_dir, filename))\n",
        "            rmtree(join(parent_dir, child))"
      ],
      "metadata": {
        "id": "cymFa4ZEz9eM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# process anr archive image in smaller size\n",
        "IMG_SHAPE = 299, 299\n",
        "\n",
        "gt_train_paths = [GT_DIR+'train/' + path for path in listdir(GT_DIR+'train/')]\n",
        "gt_test_paths = [GT_DIR+'test/' + path for path in listdir(GT_DIR+'test/')]\n",
        "gt_val_paths = [GT_DIR+'val/' + path for path in listdir(GT_DIR+'val/')]\n",
        "gt_paths = gt_train_paths + gt_test_paths + gt_val_paths\n",
        "\n",
        "im_train_paths = [IMG_DIR+'train/' + path for path in listdir(IMG_DIR+'train/')]\n",
        "im_test_paths = [IMG_DIR+'test/' + path for path in listdir(IMG_DIR+'test/')]\n",
        "im_val_paths = [IMG_DIR+'val/' + path for path in listdir(IMG_DIR+'val/')]\n",
        "im_paths = im_train_paths + im_test_paths + im_val_paths\n",
        "\n",
        "def resize_image(path):\n",
        "    img = Image.open(path)\n",
        "    img.thumbnail(IMG_SHAPE)\n",
        "    out_file = join(path)\n",
        "    img.save(out_file, 'PNG')\n",
        "\n",
        "for img in gt_paths + im_paths:\n",
        "    resize_image(img)\n",
        "#saving the data for future use, avoding pre_processing task over and over \n",
        "make_archive('gtFine', 'zip', GT_DIR) \n",
        "make_archive('leftImg', 'zip', IMG_DIR)"
      ],
      "metadata": {
        "id": "Bs4aHv_O2Eyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Re-Load Pre_processed Data"
      ],
      "metadata": {
        "id": "vEaBXVZxM5-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#PreProcessed data is located in my personal Google Drive, its publically available. anyone can download it. \n",
        "!gdown --id 1kkmpZOGdncxjI6NEvFmZh85Wn2nrW3rK -O gtFine.zip\n",
        "!gdown --id 14MXcx8G3yRLljLb1K0PYX7yCl5viPP-8 -O leftImg.zip\n"
      ],
      "metadata": {
        "id": "gZT9OeDfTpWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!unzip /content/gtFine.zip -d '/content/gtFine/'\n",
        "!unzip /content/leftImg.zip -d '/content/leftImg/'"
      ],
      "metadata": {
        "id": "JR3X6yg6WCZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize image pixels\n",
        "%%time\n",
        "IMG_SIZE = 299\n",
        "BATCH_SIZE = 32\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "GT_DIR = COLAB_DIR + 'gtFine/'\n",
        "IMG_DIR = COLAB_DIR + 'leftImg/'\n",
        "\n",
        "def load_and_preprocess_image(path):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE])\n",
        "    img /= 255.0\n",
        "    return img\n",
        "\n",
        "def get_image_paths(dir):\n",
        "    return sorted([dir + path for path in listdir(dir)])\n",
        "\n",
        "# create tf.Dataset objects\n",
        "gt_train_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(GT_DIR+'train/'))\n",
        "gt_val_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(GT_DIR+'val/'))\n",
        "gt_test_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(GT_DIR+'test/'))\n",
        "\n",
        "gt_train_ds = gt_train_ds.map(load_and_preprocess_image)\n",
        "gt_val_ds = gt_val_ds.map(load_and_preprocess_image)\n",
        "gt_test_ds = gt_test_ds.map(load_and_preprocess_image)\n",
        "\n",
        "im_train_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(IMG_DIR+'train/'))\n",
        "im_val_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(IMG_DIR+'val/'))\n",
        "im_test_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(IMG_DIR+'test/'))\n",
        "\n",
        "im_train_ds = im_train_ds.map(load_and_preprocess_image)\n",
        "im_val_ds = im_val_ds.map(load_and_preprocess_image)\n",
        "im_test_ds = im_test_ds.map(load_and_preprocess_image)"
      ],
      "metadata": {
        "id": "L0w8jSOaZJix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize Data"
      ],
      "metadata": {
        "id": "F69-KQ5xZcZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for img, gt in list(zip(im_train_ds.take(2), gt_train_ds.take(2))):\n",
        "    visualize_images(img, gt, None)"
      ],
      "metadata": {
        "id": "7oMIb8aA2E-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot(history)"
      ],
      "metadata": {
        "id": "-wAcptKrFTUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "bqOkQFb6O8Gk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "input_shape = list(im_train_ds.take(1))[0].shape\n",
        "input_layer = tf.keras.Input(shape=input_shape, name='input')\n",
        "output_layer = last_conv_module(input_layer)\n",
        "\n",
        "model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Tqitrrk_2FHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "SmDb8up8PE0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train_ds = tf.data.Dataset.zip((im_train_ds, gt_train_ds))\n",
        "train_ds = train_ds.cache().batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "val_ds = tf.data.Dataset.zip((im_val_ds, gt_val_ds))\n",
        "val_ds = val_ds.cache().batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "test_ds = tf.data.Dataset.zip((im_test_ds, gt_test_ds))\n",
        "test_ds = test_ds.cache().batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "oejnRf5xPB3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "checkpoint_path = drive_root+'pspnet/cp.ckpt'\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2)\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics='accuracy')\n",
        "history = model.fit(train_ds, validation_data=val_ds, epochs=5, \n",
        "                    callbacks=[cp_callback, es_callback])\n",
        "model.save(drive_root + 'pspnet_trained.h5')"
      ],
      "metadata": {
        "id": "a1lSg-v1PB5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(test_ds)\n",
        "print('Test Data Accuracy: ', acc)"
      ],
      "metadata": {
        "id": "7hFaFPxrOPgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_test_ds = model.predict(train_ds)\n",
        "\n",
        "for img, gt, pred in list(zip(im_train_ds.take(5), gt_train_ds.take(5), pred_test_ds)):\n",
        "    visualize_images(img, gt, pred)"
      ],
      "metadata": {
        "id": "JdlYznsLOWh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline Model"
      ],
      "metadata": {
        "id": "td5Cz67Htf3U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading Lib"
      ],
      "metadata": {
        "id": "7QcascrI7M07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import cv2\n",
        "import os\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from skimage.filters import roberts, sobel, scharr, prewitt\n",
        "from scipy import ndimage as nd"
      ],
      "metadata": {
        "id": "PO2TnZE37PmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Loading Data"
      ],
      "metadata": {
        "id": "fYPpYVlJ7ALs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!gdown --id 12rNfOiM4allOn8t4l0ErpvgmA9hEZPh2 -O processed_labels.zip\n",
        "!gdown --id 145Ul0rdbQcX98lQz8IO5eOtI0ZlvKwz6 -O processed_images.zip"
      ],
      "metadata": {
        "id": "nlkvBNXItiHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!unzip /content/processed_images.zip\n",
        "!unzip /content/processed_labels.zip"
      ],
      "metadata": {
        "id": "iRtqOCbcvSTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-Processing Data"
      ],
      "metadata": {
        "id": "tCDqzox07E_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "/content/content/processed_images/aachen_000000_000019.png\n",
        "/content/content/processed_labels/aachen_000000_000019.png"
      ],
      "metadata": {
        "id": "AgJMIX2_dDHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = '/content/content/processed_images/*'\n",
        "lab_path = '/content/content/processed_labels/*'"
      ],
      "metadata": {
        "id": "J8gwWlhN8Oq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the data indo a list, numpy array\n",
        "%%time\n",
        "train_images = glob.glob(img_path)\n",
        "train_labels = glob.glob(lab_path)\n",
        "\n",
        "print(len(train_images))\n",
        "print(len(train_labels))"
      ],
      "metadata": {
        "id": "4ZMBHtR1veez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_img = []\n",
        "dim = (200,200)\n",
        "for img in train_images:\n",
        "  m = cv2.imread(img, 0)\n",
        "  train_img.append(cv2.resize(m, dim).reshape(-1))\n",
        "print(len(train_img), train_img[0].shape)"
      ],
      "metadata": {
        "id": "bbW2YZ5ISEeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_img(train_img[0].reshape(dim))"
      ],
      "metadata": {
        "id": "wT8dMhUNTtgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_lab = []\n",
        "dim = (200,200)\n",
        "for img in train_labels:\n",
        "  m = cv2.imread(img, 0)\n",
        "  train_lab.append(cv2.resize(m, dim).reshape(-1))\n",
        "print(len(train_lab), train_lab[0].shape)"
      ],
      "metadata": {
        "id": "O9MdCuVsS6iW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = np.array(train_img)\n",
        "train_labels = np.array(train_lab)\n",
        "print(train_images.shape, train_labels.shape)"
      ],
      "metadata": {
        "id": "Wz_UDUT_U_xX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_img(train_lab[0].reshape(dim))"
      ],
      "metadata": {
        "id": "B7ZDQ9xcS6k2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1"
      ],
      "metadata": {
        "id": "cCsykJ2qUSY7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Now, add a column in the data frame for the Labels\n",
        "#For this, we need to import the labeled image\n",
        "labeled_img = cv2.imread(lab)\n",
        "#Remember that you can load an image with partial labels \n",
        "#But, drop the rows with unlabeled data\n",
        "\n",
        "labeled_img = cv2.cvtColor(labeled_img, cv2.COLOR_BGR2GRAY)\n",
        "labeled_img1 = labeled_img.reshape(-1)\n"
      ],
      "metadata": {
        "id": "Kl8rpgFVwCdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_img1.shape"
      ],
      "metadata": {
        "id": "Y9hXL4e6vPiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "Y = LabelEncoder().fit_transform(labeled_img1)"
      ],
      "metadata": {
        "id": "AhA6nqbPvPtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y.shape"
      ],
      "metadata": {
        "id": "L03PnDg0vibh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ")"
      ],
      "metadata": {
        "id": "rCWw0O_hviiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_img_data = df.drop(labels = [\"Labels\"], axis=1) #Use for prediction\n",
        "#df.to_csv(\"Gabor.csv\")\n",
        "df = df[df.Labels != 0]"
      ],
      "metadata": {
        "id": "5mpc7b02wCg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the dependent variable that needs to be predicted (labels)\n",
        "Y = df[\"Labels\"].values\n",
        "\n",
        "#Encode Y values to 0, 1, 2, 3, .... (NOt necessary but makes it easy to use other tools like ROC plots)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "Y = LabelEncoder().fit_transform(Y)\n",
        "\n",
        "\n",
        "#Define the independent variables\n",
        "X = df.drop(labels = [\"Labels\"], axis=1) "
      ],
      "metadata": {
        "id": "CclVYTGmLjCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split data into train and test to verify accuracy after fitting the model. \n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=20)\n",
        "\n"
      ],
      "metadata": {
        "id": "QFzYSLgeLjFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features.shape, Y.shape"
      ],
      "metadata": {
        "id": "kyHdtZiHv0Ld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IfK64jjZv0N-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LvcDxVq6v0Q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# Instantiate model with n number of decision trees\n",
        "model = RandomForestClassifier(n_estimators = 20, random_state = 42)\n",
        "\n",
        "# Train the model on training data\n",
        "model.fit(features, Y)"
      ],
      "metadata": {
        "id": "3UlI1atsLjIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_list = list(X.columns)\n",
        "feature_imp = pd.Series(model.feature_importances_,index=feature_list).sort_values(ascending=False)\n",
        "print(feature_imp)"
      ],
      "metadata": {
        "id": "pwrd_OXDLjLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_RF = model.predict(features)"
      ],
      "metadata": {
        "id": "DEErx15mwJ7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_RF.shape"
      ],
      "metadata": {
        "id": "zr4VigQVwJ-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(prediction_RF.reshape(gray.shape))"
      ],
      "metadata": {
        "id": "4g9LO-otwKBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lab = cv2.imread('/content/content/processed_labels/aachen_000159_000019.png',0)\n",
        "print(lab.shape)"
      ],
      "metadata": {
        "id": "jMRK2XxfwKE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(lab)"
      ],
      "metadata": {
        "id": "f2_mkt9DwKHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img1 = train_images[11]\n",
        "lab1 = train_labels[11]\n",
        "lab1 = cv2.imread(lab1,0)\n",
        "img1 = cv2.imread(img1,0)\n",
        "print(lab1.shape, img1.shape)"
      ],
      "metadata": {
        "id": "a7H4Wgw4xFus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(img1)"
      ],
      "metadata": {
        "id": "BLzXet14xFxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(lab1)"
      ],
      "metadata": {
        "id": "O_6nPirExF0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VytN3dk4xF3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evl"
      ],
      "metadata": {
        "id": "xB6BhtLyx2oo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gabor1 = gabor_feature_extraction(img1,.8, .05 )\n",
        "gabor2 = gabor_feature_extraction(img1,1.6, .5 )\n",
        "blur1, blur2, sobele, canny = preprocess_image(img1)\n",
        "print(blur1.shape, blur2.shape, sobele.shape, canny.shape )\n",
        "print(gabor1.shape, gabor2.shape)"
      ],
      "metadata": {
        "id": "KWf9sj7exF6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = np.hstack((gray1, gabor1, gabor2, blur1, blur2, sobele, canny))\n",
        "features.shape"
      ],
      "metadata": {
        "id": "s8wExb7xxF9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lab1.shape"
      ],
      "metadata": {
        "id": "ckhw-2B4xGAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B3c1qsFPxGCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0SbpT0zQxGFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_RF = model.predict(features)"
      ],
      "metadata": {
        "id": "U3Tzh2FzMZfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(prediction_RF.reshape(gray.shape))"
      ],
      "metadata": {
        "id": "J362DmiZyRnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(lab1)"
      ],
      "metadata": {
        "id": "JHtj_ry9yRqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2f1A5kXCyRs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K8U6UNDryRvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "#Print the prediction accuracy\n",
        "#Check accuracy on test dataset. If this is too low compared to train it indicates overfitting on training data.\n",
        "print (\"Accuracy using Random Forest= \", metrics.accuracy_score(y_test, prediction_RF))"
      ],
      "metadata": {
        "id": "zZc0OU7cMbSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = load_img('/content/aachen_000000_000019.png')\n",
        "display_img(i)"
      ],
      "metadata": {
        "id": "0LUuK4FXMbYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "0WUMhdD1SnST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PjK6cjZlMbaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# new approach"
      ],
      "metadata": {
        "id": "XoDeUCnxtFBB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "/content/content/processed_images/dusseldorf_000143_000019.png\n",
        "/content/content/processed_labels/dusseldorf_000143_000019.png"
      ],
      "metadata": {
        "id": "C6kaCKy-pTJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, lab"
      ],
      "metadata": {
        "id": "36ps1Q3Zo8RB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n"
      ],
      "metadata": {
        "id": "NjbUst4ppUde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(img):\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    \n",
        "    # Apply Canny edge detection\n",
        "    edges = cv2.Canny(gray, 100, 200)\n",
        "    \n",
        "    # Apply Gaussian blur to reduce noise\n",
        "    blur = cv2.GaussianBlur(edges, (5, 5), 0)\n",
        "    \n",
        "    return blur"
      ],
      "metadata": {
        "id": "Frgj8ryJpnzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def npreprocess_image(img):\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY).reshape(-1,1)\n",
        "    sobels = sobel(gray)\n",
        "    \n",
        "    # Apply Canny edge detection\n",
        "    edges = cv2.Canny(gray, 100, 200)\n",
        "    \n",
        "    # Apply Gaussian blur to reduce noise\n",
        "    blur = cv2.GaussianBlur(edges, (5, 5), 0)\n",
        "    \n",
        "    return np.hstack((gray, sobels,edges,blur))"
      ],
      "metadata": {
        "id": "fA5NZfMH4RLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(img):\n",
        "    # Extract RGB color features\n",
        "    r, g, b = cv2.split(img)\n",
        "    features = np.dstack((r, g, b)).reshape(-1, 3)\n",
        "    \n",
        "    # Extract texture features using Gabor filter\n",
        "    kernel = cv2.getGaborKernel((5, 5), 4, np.pi/4, 8, 0.5, 0, ktype=cv2.CV_32F)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    filtered = cv2.filter2D(gray, cv2.CV_8UC3, kernel)\n",
        "    texture_features = filtered.reshape(-1, 1)\n",
        "    \n",
        "    # Combine color and texture features\n",
        "    features = np.hstack((features, texture_features))\n",
        "    \n",
        "    return features"
      ],
      "metadata": {
        "id": "MNK_9amPpn2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def segment_image(img):\n",
        "    # Preprocess the image\n",
        "    preprocessed = preprocess_image(img)\n",
        "    \n",
        "    # Extract features from the preprocessed image\n",
        "    features = extract_features(img)\n",
        "    \n",
        "    # Cluster the features using k-means\n",
        "    kmeans = KMeans(n_clusters=3, random_state=0).fit(features)\n",
        "    labels = kmeans.labels_.reshape(preprocessed.shape[:2])\n",
        "    \n",
        "    # Train a Random Forest classifier on the labeled features\n",
        "    flat_features = features.reshape(-1, features.shape[-1])\n",
        "    clf = RandomForestClassifier(n_estimators=50, random_state=0)\n",
        "    clf.fit(flat_features, labels.ravel())\n",
        "    \n",
        "    # Predict the segmentation for the preprocessed image\n",
        "    flat_preprocessed = preprocessed.reshape(-1, preprocessed.shape[-1])\n",
        "    segmentation = clf.predict(flat_preprocessed).reshape(preprocessed.shape[:2])\n",
        "    \n",
        "    # Convert the segmentation to a binary mask\n",
        "    mask = np.zeros_like(segmentation)\n",
        "    mask[segmentation == 1] = 255\n",
        "    \n",
        "    return mask"
      ],
      "metadata": {
        "id": "MTV8Bwogpn5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load an example image\n",
        "img = cv2.imread('/content/content/processed_images/dusseldorf_000143_000019.png')"
      ],
      "metadata": {
        "id": "VrAQ7mHypn8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Preprocess the image\n",
        "preprocessed = preprocess_image(img)\n",
        "npreprocessed = npreprocess_image(img)\n",
        "print(preprocessed.shape, npreprocessed.shape)"
      ],
      "metadata": {
        "id": "lVe4LTA5qEQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract features from the preprocessed image\n",
        "features = extract_features(img)\n",
        "features.shape"
      ],
      "metadata": {
        "id": "5v8BzWOFqXiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cluster the features using k-means\n",
        "kmeans = KMeans(n_clusters=21, random_state=0).fit(features)\n",
        "labels = kmeans.labels_.reshape(preprocessed.shape[:2])\n",
        "labels.shape"
      ],
      "metadata": {
        "id": "BO842IGgque-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed.shape[:2]"
      ],
      "metadata": {
        "id": "mkjs7aUW7B-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cluster the features using k-means\n",
        "kmeans = KMeans(n_clusters=21, random_state=0).fit(features)\n",
        "labels = kmeans.labels_.reshape(npreprocessed.shape[:2])\n",
        "labels.shape"
      ],
      "metadata": {
        "id": "kghPRnmb646b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels[10]"
      ],
      "metadata": {
        "id": "VXwwckSZqukV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flat_features = features.reshape(-1, features.shape[-1])\n",
        "print(flat_features.shape)"
      ],
      "metadata": {
        "id": "60nrFxflrAeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = RandomForestClassifier(n_estimators=50, random_state=0)"
      ],
      "metadata": {
        "id": "YknkhHYarAg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels.ravel().shape"
      ],
      "metadata": {
        "id": "h1_R3Qg5rbDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(flat_features, labels.ravel())"
      ],
      "metadata": {
        "id": "aKCSNj5orTrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "flat_features = features.reshape(-1, features.shape[-1])\n",
        "print(flat_features.shape)"
      ],
      "metadata": {
        "id": "GGlnvVdvtnRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the segmentation for the preprocessed image\n",
        "#flat_preprocessed = preprocessed.reshape(-1, preprocessed.shape[-1])\n",
        "flat_preprocessed = preprocessed.reshape(-1, preprocessed.shape[-1])\n",
        "flat_preprocessed.shape"
      ],
      "metadata": {
        "id": "rCBwrZHFrvIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#segmentation = clf.predict(flat_preprocessed).reshape(preprocessed.shape[:2])   \n",
        "segmentation = clf.predict(npreprocessed)\n",
        "\n",
        "segmentation.shape"
      ],
      "metadata": {
        "id": "FX0Uh4X1rvLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "segmentation = segmentation.reshape(preprocessed.shape[:2]) \n",
        "segmentation.shape"
      ],
      "metadata": {
        "id": "jLoAL_-B8MOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(segmentation)"
      ],
      "metadata": {
        "id": "fTqG6RYyyx0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the segmentation to a binary mask\n",
        "mask = np.zeros_like(segmentation)\n",
        "mask[segmentation == 1] = 255"
      ],
      "metadata": {
        "id": "4pN7FMSGrvNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "segmentation = clf.predict(flat_preprocessed).reshape(preprocessed.shape[:2])\n",
        "\n",
        "# Convert the segmentation to a binary mask\n",
        "mask = np.zeros_like(segmentation)\n",
        "mask[segmentation == 1] = 255\n"
      ],
      "metadata": {
        "id": "baRZGRcQqXos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9nkXV8BWqETg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Segment the image\n",
        "##mask = segment_image(img)\n",
        "\n"
      ],
      "metadata": {
        "id": "X5ZiZgNvpn_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask.shape, img.shape"
      ],
      "metadata": {
        "id": "MFgTMFQ1vVLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(img)"
      ],
      "metadata": {
        "id": "i3WpiOBhve49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(mask)"
      ],
      "metadata": {
        "id": "6fOz8ihjvi8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the results\n",
        "cv2.imshow('Input Image', img)\n",
        "cv2.imshow('Segmentation Mask', mask)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "Si-OjAnbpoDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IabTxXxZzG_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8LwvkhEKzHCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(img):\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY).reshape(-1,1)\n",
        "    sobels = sobel(gray)\n",
        "    \n",
        "    # Apply Canny edge detection\n",
        "    edges = cv2.Canny(gray, 100, 200)\n",
        "    \n",
        "    # Apply Gaussian blur to reduce noise\n",
        "    blur = cv2.GaussianBlur(edges, (5, 5), 0)\n",
        "    \n",
        "    return np.hstack((gray, sobels,edges,blur))"
      ],
      "metadata": {
        "id": "Gn5vTQ1PzHFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = preprocess_image(img)\n"
      ],
      "metadata": {
        "id": "5DotSurPzHgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.shape"
      ],
      "metadata": {
        "id": "_uLTyRMq4MJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "gray.shape\n",
        "g= gray.reshape(-1, 1)\n",
        "g.shape"
      ],
      "metadata": {
        "id": "bn-WZ2uzzHi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SOBEL\n",
        "s = sobel(g)\n",
        "#s = s.reshape(-1,1)\n",
        "s.shape"
      ],
      "metadata": {
        "id": "V8SVnV8u1cwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Apply Canny edge detection\n",
        "edges = cv2.Canny(gray, 100, 200)\n",
        "edges.shape\n",
        "e= edges.reshape(-1,1)"
      ],
      "metadata": {
        "id": "5DYpoSydzayC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blur = cv2.GaussianBlur(edges, (5, 5), 0)\n",
        "blur.shape\n",
        "b= blur.reshape(-1,1)"
      ],
      "metadata": {
        "id": "ll2Hyh0GzHli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blur.reshape(-1).shape"
      ],
      "metadata": {
        "id": "n58EgUl7zXBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blur.shape"
      ],
      "metadata": {
        "id": "4pvRXRxz0AOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = np.hstack((g, e,b,s))\n",
        "f.shape"
      ],
      "metadata": {
        "id": "qNcEAGUqzyAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "segmentation = clf.predict(f).reshape(preprocessed.shape[:2])\n",
        "    "
      ],
      "metadata": {
        "id": "t-uNC0GM0HAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask = np.zeros_like(segmentation)\n",
        "mask[segmentation == 1] = 255"
      ],
      "metadata": {
        "id": "7kAOVmzQ2Jp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(mask)"
      ],
      "metadata": {
        "id": "P_1kiryS2Jsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lab = train_label[0]\n",
        "lab = cv2.imread(lab, 0)\n"
      ],
      "metadata": {
        "id": "jroX29UB46pe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(lab)\n"
      ],
      "metadata": {
        "id": "74qm9w5p2Jvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    segmentation = clf.predict(flat_preprocessed).reshape(preprocessed.shape[:2])\n",
        "    \n",
        "    # Convert the segmentation to a binary mask\n",
        "    mask = np.zeros_like(segmentation)\n",
        "    mask[segmentation == 1] = 255\n",
        "    \n",
        "    return mask\n",
        "\n",
        "# Load an example image\n",
        "img = cv2.imread('example.jpg')\n",
        "\n",
        "# Segment the image\n",
        "mask = segment_image(img)\n",
        "\n",
        "# Display the results\n",
        "cv2.imshow('Input Image', img)\n",
        "cv2.imshow('Segmentation Mask', mask)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "5af0w3bl2Jyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F2rbJri5sJMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "WoXAEEd0sJk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gabor_feature_extraction(img, lamda, gamma):\n",
        "  kernel = cv2.getGaborKernel((8, 8), 1, 0, lamda, gamma, 0, ktype=cv2.CV_32F)\n",
        "  gabor_img = cv2.filter2D(img, cv2.CV_8UC3, kernel)\n",
        "  return gabor_img.reshape(-1,1)/255\n"
      ],
      "metadata": {
        "id": "-vv5vreOsLXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(img):\n",
        "  #function will accept a numpy.ndarray\n",
        "\n",
        "  #GAUSSIAN blur 1\n",
        "  gblur = cv2.GaussianBlur(img, (5,5),7)\n",
        "  #Laplacian\n",
        "  laplacian = cv2.Laplacian(img, cv2.CV_64F, ksize=7) \n",
        "  #SOBEL\n",
        "  sobele = cv2.Sobel(img,cv2.CV_64F, 0,1,ksize=5)\n",
        "  #CANNY \n",
        "  cany = cv2.Canny(np.uint8(sobele), 100,200)\n",
        "\n",
        "  #return cany\n",
        "  return (gblur.reshape(-1)/255,laplacian.reshape(-1)/255,sobele.reshape(-1)/255,cany.reshape(-1)/255)"
      ],
      "metadata": {
        "id": "CZ_JrjPPsLz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image_org(img):\n",
        "  #GAUSSIAN blur 1\n",
        "  blur1 = nd.gaussian_filter(img, sigma=3)\n",
        "  #GAUSSIAN blur2\n",
        "  blur2 = nd.gaussian_filter(img, sigma=7)\n",
        "  #SOBEL\n",
        "  sobele = sobel(blur2)\n",
        "  #CANNY \n",
        "  cany = cv2.Canny(np.uint8(sobele), 100,200)\n",
        "  #return cany\n",
        "  return (blur1.reshape(-1,1),blur2.reshape(-1,1),sobele.reshape(-1,1),cany.reshape(-1,1))"
      ],
      "metadata": {
        "id": "BVCA-uLQsL2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_img(img):\n",
        "  fig = plt.figure(figsize=(8,8))\n",
        "  ax = fig.add_subplot(111)\n",
        "  ax.imshow(img,cmap='gray')"
      ],
      "metadata": {
        "id": "00mkCqMssL5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_img(image_path):\n",
        "  return cv2.imread(image_path, 0).astype(np.float32)/255\n"
      ],
      "metadata": {
        "id": "1ocjCADFplBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_one_test_image(image_dir):\n",
        "  img = cv2.imread(image_dir, 0)\n",
        "  g1 = img/255\n",
        "  _,thresh3  = cv2.threshold(img, 80, 255, cv2.THRESH_BINARY_INV)\n",
        "  binay_inv = thresh3/255\n",
        "  adaptive_thresh = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,11, 11)/255\n",
        "  gb1 = gabor_feature_extraction(img,.8, .05 )/255\n",
        "  gb2 = gabor_feature_extraction(img,1.6, .5 )/255\n",
        "  blur, laplacian, sobel, cany = preprocess_image(img)\n",
        "  return np.hstack((g1.reshape(-1,1), binay_inv.reshape(-1,1), adaptive_thresh.reshape(-1,1), \n",
        "                    gb1.reshape(-1,1), gb2.reshape(-1,1), blur.reshape(-1,1), \n",
        "                    laplacian.reshape(-1,1), sobel.reshape(-1,1), cany.reshape(-1,1)))\n"
      ],
      "metadata": {
        "id": "1zQxJi2WplEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_one_test_image_df(image_dir):\n",
        "  test_df = pd.DataFrame()\n",
        "  img = cv2.imread(image_dir, 0)\n",
        "  g1 = img/255\n",
        "  _,thresh3  = cv2.threshold(img, 80, 255, cv2.THRESH_BINARY_INV)\n",
        "  binay_inv = thresh3/255\n",
        "  adaptive_thresh = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,11, 11)/255\n",
        "  gb1 = gabor_feature_extraction(img,.8, .05 )/255\n",
        "  gb2 = gabor_feature_extraction(img,1.6, .5 )/255\n",
        "  blur, laplacian, sobel, cany = preprocess_image(img)\n",
        "\n",
        "  test_df['gray']= g1.reshape(-1)\n",
        "  test_df['binay_inv']= binay_inv.reshape(-1)\n",
        "  test_df['adaptive_thresh']=adaptive_thresh.reshape(-1)\n",
        "  test_df['gabor1'] = gabor_feature_extraction(img,.8, .05 ).reshape(-1)\n",
        "  test_df['gabor2'] = gabor_feature_extraction(img,1.6, .5 ).reshape(-1)\n",
        "  test_df['blur'], test_df['laplacian'], test_df['sobelx'], test_df['canny'] = blur.reshape(-1), laplacian.reshape(-1), sobel.reshape(-1), cany.reshape(-1)\n",
        "\n",
        "  return test_df\n"
      ],
      "metadata": {
        "id": "rx5nfg_-plH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_one_test_image_df_a(image_dir):\n",
        "  #this function is getting an image as an input \n",
        "  test_df = pd.DataFrame()\n",
        "  #img = cv2.imread(image_dir, 0)\n",
        "  img = image_dir\n",
        "  g1 = img/255\n",
        "  _,thresh3  = cv2.threshold(img, 80, 255, cv2.THRESH_BINARY_INV)\n",
        "  binay_inv = thresh3/255\n",
        "  adaptive_thresh = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,11, 11)/255\n",
        "  gb1 = gabor_feature_extraction(img,.8, .05 )/255\n",
        "  gb2 = gabor_feature_extraction(img,1.6, .5 )/255\n",
        "  blur, laplacian, sobel, cany = preprocess_image(img)\n",
        "\n",
        "  test_df['gray']= g1.reshape(-1)\n",
        "  test_df['binay_inv']= binay_inv.reshape(-1)\n",
        "  test_df['adaptive_thresh']=adaptive_thresh.reshape(-1)\n",
        "  test_df['gabor1'] = gabor_feature_extraction(img,.8, .05 ).reshape(-1)\n",
        "  test_df['gabor2'] = gabor_feature_extraction(img,1.6, .5 ).reshape(-1)\n",
        "  test_df['blur'], test_df['laplacian'], test_df['sobelx'], test_df['canny'] = blur.reshape(-1), laplacian.reshape(-1), sobel.reshape(-1), cany.reshape(-1)\n",
        "\n",
        "  return test_df"
      ],
      "metadata": {
        "id": "qvBiGJ_nek2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_images(img, gt, pred):\n",
        "    if pred is not None:\n",
        "        fig, axes = plt.subplots(1, 3, figsize=(12, 8))\n",
        "    else:\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(8, 8))\n",
        "\n",
        "    axes[0].imshow(img)\n",
        "    axes[0].set_title('Actual Image')\n",
        "\n",
        "    axes[1].imshow(gt)\n",
        "    axes[1].set_title('Masked Image')\n",
        "    \n",
        "    if pred is not None:\n",
        "        axes[2].imshow(pred)\n",
        "        axes[2].set_title('Predicted Image')"
      ],
      "metadata": {
        "id": "L5OnUvljBEEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(X,filters,block):\n",
        "    # resiudal block with dilated convolutions\n",
        "    # add skip connection at last after doing convoluion\n",
        "\n",
        "    b = 'block_'+str(block)+'_'\n",
        "    f1,f2,f3 = filters\n",
        "    X_skip = X\n",
        "\n",
        "    # block_a\n",
        "    X = Conv2D(filters=f1,kernel_size=(1,1),dilation_rate=(1,1),\n",
        "               padding='same',kernel_initializer='he_normal',name=b+'a')(X)\n",
        "    X = BatchNormalization(name=b+'batch_norm_a')(X)\n",
        "    X = LeakyReLU(alpha=0.2,name=b+'leakyrelu_a')(X)\n",
        "    # block_b\n",
        "    X = Conv2D(filters=f2,kernel_size=(3,3),dilation_rate=(2,2),\n",
        "               padding='same',kernel_initializer='he_normal',name=b+'b')(X)\n",
        "    X = BatchNormalization(name=b+'batch_norm_b')(X)\n",
        "    X = LeakyReLU(alpha=0.2,name=b+'leakyrelu_b')(X)\n",
        "    # block_c\n",
        "    X = Conv2D(filters=f3,kernel_size=(1,1),dilation_rate=(1,1),\n",
        "               padding='same',kernel_initializer='he_normal',name=b+'c')(X)\n",
        "    X = BatchNormalization(name=b+'batch_norm_c')(X)\n",
        "    # skip_conv\n",
        "    X_skip = Conv2D(filters=f3,kernel_size=(3,3),padding='same',name=b+'skip_conv')(X_skip)\n",
        "    X_skip = BatchNormalization(name=b+'batch_norm_skip_conv')(X_skip)\n",
        "    # block_c + skip_conv\n",
        "    X = Add(name=b+'add')([X,X_skip])\n",
        "    X = ReLU(name=b+'relu')(X)\n",
        "    return X\n",
        "    \n",
        "def base_feature_maps(input_layer):\n",
        "    # base covolution module to get input image feature maps \n",
        "    \n",
        "    # block_1\n",
        "    base = conv_block(input_layer,[16,16,32],'1')\n",
        "    # block_2\n",
        "    base = conv_block(base,[16,16,32],'2')\n",
        "    return base\n",
        "\n",
        "def pyramid_feature_maps(input_layer):\n",
        "    # pyramid pooling module\n",
        "    \n",
        "    base = base_feature_maps(input_layer)\n",
        "    # red\n",
        "    red = GlobalAveragePooling2D(name='red_pool')(base)\n",
        "    red = tf.keras.layers.Reshape((1,1,32))(red)\n",
        "    red = Conv2D(filters=32,kernel_size=(1,1),name='red_1_by_1')(red)\n",
        "    red = UpSampling2D(size=128,interpolation='bilinear',name='red_upsampling')(red)\n",
        "    red = tf.image.resize(red, [IMG_SIZE, IMG_SIZE])\n",
        "    # yellow\n",
        "    yellow = AveragePooling2D(pool_size=(2,2),name='yellow_pool')(base)\n",
        "    yellow = Conv2D(filters=32,kernel_size=(1,1),name='yellow_1_by_1')(yellow)\n",
        "    yellow = UpSampling2D(size=2,interpolation='bilinear',name='yellow_upsampling')(yellow)\n",
        "    yellow = tf.image.resize(yellow, [IMG_SIZE, IMG_SIZE])\n",
        "    # blue\n",
        "    blue = AveragePooling2D(pool_size=(4,4),name='blue_pool')(base)\n",
        "    blue = Conv2D(filters=32,kernel_size=(1,1),name='blue_1_by_1')(blue)\n",
        "    blue = UpSampling2D(size=4,interpolation='bilinear',name='blue_upsampling')(blue)\n",
        "    blue = tf.image.resize(blue, [IMG_SIZE, IMG_SIZE])\n",
        "    # green\n",
        "    green = AveragePooling2D(pool_size=(8,8),name='green_pool')(base)\n",
        "    green = Conv2D(filters=32,kernel_size=(1,1),name='green_1_by_1')(green)\n",
        "    green = UpSampling2D(size=8,interpolation='bilinear',name='green_upsampling')(green)\n",
        "    green = tf.image.resize(green, [IMG_SIZE, IMG_SIZE])\n",
        "    # base + red + yellow + blue + green\n",
        "    return tf.keras.layers.concatenate([base,red,yellow,blue,green])\n",
        "\n",
        "def last_conv_module(input_layer):\n",
        "    X = pyramid_feature_maps(input_layer)\n",
        "    X = Conv2D(filters=3,kernel_size=3,padding='same',name='last_conv_3_by_3')(X)\n",
        "    X = BatchNormalization(name='last_conv_3_by_3_batch_norm')(X)\n",
        "    X = Activation('sigmoid',name='last_conv_relu')(X)\n",
        "    return X"
      ],
      "metadata": {
        "id": "LnYFbrjZBM02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot(history):\n",
        "  acc = history.history['accuracy']\n",
        "  val_acc = history.history['val_accuracy']\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  epochs = range(1,len(acc)+1)\n",
        "\n",
        "  plt.title('Training and validation accuracy')\n",
        "  plt.plot(epochs, acc, color='blue', label='Train')\n",
        "  plt.plot(epochs, val_acc, color='orange', label='Val')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.legend()\n",
        "\n",
        "  _ = plt.figure()\n",
        "  plt.title('Training and validation loss')\n",
        "  plt.plot(epochs, loss, color='blue', label='Train')\n",
        "  plt.plot(epochs, val_loss, color='orange', label='Val')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n"
      ],
      "metadata": {
        "id": "h3aNpbOIBZ44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M8iJi35OBZ7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#New Approach"
      ],
      "metadata": {
        "id": "EDp0BG_4jURb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yBTsEFStt924"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4zoxFNv8t95x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ALOfrH9St98j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_images = np.array(train_img)\n",
        "#train_labels = np.array(train_lab)\n",
        "print(train_images.shape, train_labels.shape)"
      ],
      "metadata": {
        "id": "jHPgNFi7VkLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_dataset = pd.DataFrame() "
      ],
      "metadata": {
        "id": "mo8LaR7ksL7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_images = glob.glob(img_path)\n",
        "#train_labels = glob.glob(lab_path)\n",
        "print(len(train_images))\n",
        "print(len(train_labels))\n",
        "print(int(len(train_images)*.7))"
      ],
      "metadata": {
        "id": "1KL1J4e-jZZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = train_images[0].reshape(dim)\n",
        "display_img(m)"
      ],
      "metadata": {
        "id": "lOIB53qgkn8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Thresholding\n",
        "_,thresh2  = cv2.threshold(m, 80, 255, cv2.THRESH_BINARY_INV)\n",
        "plt.imshow(thresh2, cmap='gray')"
      ],
      "metadata": {
        "id": "fs0eA3zUk_va"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#image is reshaped to (-1)\n",
        "m2 = train_images[0]/255\n",
        "blur, laplacian, sobel, cany = preprocess_image(m2)\n",
        "print(blur.shape, laplacian.shape, sobel.shape, cany.shape)\n",
        "print(blur.max(), laplacian.max(), sobel.max(), cany.max())\n",
        "print(blur.min(), laplacian.min(), sobel.min(), cany.min())"
      ],
      "metadata": {
        "id": "kIbGHfldpoVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a data frame with test data image - using a numpy array\n",
        "%%time\n",
        "df_image = pd.DataFrame() \n",
        "for img in train_images[:100]:\n",
        "  df1 = pd.DataFrame()\n",
        "  #img = cv2.imread(image, 0)\n",
        "  df1['gray']= img/255\n",
        "  #df1['Image_Name'] = image.split('/')[-1]\n",
        "\n",
        "  _,thresh2  = cv2.threshold(img, 80, 255, cv2.THRESH_BINARY_INV)\n",
        "  thresh2 = thresh2/255\n",
        "  df1['binay_inv']= thresh2.reshape(-1)\n",
        "  df1['adaptive_thresh']=(cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,11, 11)/255).reshape(-1)\n",
        "  df1['gabor1'] = gabor_feature_extraction(img,.8, .05 ).reshape(-1)\n",
        "  df1['gabor2'] = gabor_feature_extraction(img,1.6, .5 ).reshape(-1)\n",
        "  df1['blur'], df1['laplacian'], df1['sobelx'], df1['canny'] = preprocess_image(img)\n",
        "  df_image = pd.concat([df_image, df1])\n",
        "\n",
        "print(df_image.shape)"
      ],
      "metadata": {
        "id": "JyiSW3GnjnVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_XAgfvd6WYtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating test mask image Data Frame\n",
        "%%time\n",
        "df_mask = pd.DataFrame() \n",
        "for mask in train_labels[:100]:\n",
        "  df2 = pd.DataFrame()\n",
        "  #msk = cv2.imread(mask, 0)\n",
        "  df2['label'] = mask #msk.reshape(-1) \n",
        "  #df2['Mask_Name'] = mask.split('/')[-1]  \n",
        "  df_mask = pd.concat([df_mask, df2])\n",
        "print(df_mask.shape)"
      ],
      "metadata": {
        "id": "TsuGEz7ywxkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_image.head()"
      ],
      "metadata": {
        "id": "twuGHANAwxp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_mask.head()"
      ],
      "metadata": {
        "id": "0RgYil_50lAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([df_image, df_mask], axis=1)\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "f4ygZJZZ1_T9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_0 = df"
      ],
      "metadata": {
        "id": "DHsAjhl9EAk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pre processing DF"
      ],
      "metadata": {
        "id": "TKTRjTQq_R6B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_0 = df[df.label != 0]\n",
        "print(df_0.shape)"
      ],
      "metadata": {
        "id": "CO_aNaES1_ct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#X = df_0.drop(labels = [\"Image_Name\", \"Mask_Name\", \"label\"], axis=1) \n",
        "X = df_0.drop(labels = [\"label\"], axis=1) "
      ],
      "metadata": {
        "id": "T177MN4P2eGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = df_0[\"label\"].values "
      ],
      "metadata": {
        "id": "zKAPhlFm2eJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, Y.shape"
      ],
      "metadata": {
        "id": "66q7Inub2eMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "Y = LabelEncoder().fit_transform(Y)\n",
        "Y.shape"
      ],
      "metadata": {
        "id": "8FEgcJoo2ePK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import training classifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "## Instantiate model with n number of decision trees\n",
        "model = RandomForestClassifier(n_estimators = 50, random_state = 42)"
      ],
      "metadata": {
        "id": "RW4UzbAk29JL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#cd '/content/drive/MyDrive/DeepLearning'"
      ],
      "metadata": {
        "id": "ezfLp2QxQDbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "id": "U_f-zv_SaCSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Train the model on training data\n",
        "model.fit(X, Y)"
      ],
      "metadata": {
        "id": "il3_TV0q29MC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "#Save the trained model as pickle string to disk for future use\n",
        "filename = \"sandstone_model_withoutZero\"\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ],
      "metadata": {
        "id": "euEnyJ0KH8hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### evl"
      ],
      "metadata": {
        "id": "hazyGcpGH8qS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = np.array(train_img)\n",
        "train_labels = np.array(train_lab)\n",
        "print(train_images.shape, train_labels.shape)"
      ],
      "metadata": {
        "id": "Ka5m9Kbod0aB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test_img = cv2.imread('/content/content/processed_images/aachen_000000_000019.png', 0)\n",
        "#test_lab = cv2.imread('/content/content/processed_labels/aachen_000000_000019.png',0)\n",
        "\n",
        "test_img = train_images[210].reshape(dim)\n",
        "test_lab= train_labels[210].reshape(dim)\n",
        "train_img = train_images[68].reshape(dim)\n",
        "train_lab= train_labels[68].reshape(dim)"
      ],
      "metadata": {
        "id": "9bdOk11K4r0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_img(test_img)"
      ],
      "metadata": {
        "id": "8FuDK6pwdZqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_img(test_lab)"
      ],
      "metadata": {
        "id": "UmFmEaP2dZ0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fX = generate_one_test_image_df(train_images[201])\n",
        "fX_test = generate_one_test_image_df_a(test_img)\n",
        "fX_test.shape"
      ],
      "metadata": {
        "id": "BpX87NLRIAAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fX = generate_one_test_image_df(train_images[201])\n",
        "fX_train = generate_one_test_image_df_a(train_img)\n",
        "fX_train.shape"
      ],
      "metadata": {
        "id": "DxEeQ1ukgPXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "#prediction_test = model.predict(fX)"
      ],
      "metadata": {
        "id": "4IrroKTu29O3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_test = model.predict(fX_test)"
      ],
      "metadata": {
        "id": "0auJH93AgVHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_lab.reshape(-1).shape"
      ],
      "metadata": {
        "id": "1ipWx7uc8h8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_test.shape"
      ],
      "metadata": {
        "id": "1neRwBzN8h_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_lab.reshape(dim)"
      ],
      "metadata": {
        "id": "utZ4h-Gl8iB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Testing Accuracy = \", metrics.accuracy_score(test_lab.reshape(dim), prediction_test.reshape(dim)))"
      ],
      "metadata": {
        "id": "Ag0p_7WX29Rl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import jaccard_score"
      ],
      "metadata": {
        "id": "I8-O9m_zjOEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Training Accuracy = \", jaccard_score(test_lab.reshape(dim), prediction_test.reshape(dim),average='samples'))"
      ],
      "metadata": {
        "id": "_cF0vQENjQ28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(test_lab)"
      ],
      "metadata": {
        "id": "qEPueDCb86L0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(prediction_test.reshape(dim),cmap='gray')"
      ],
      "metadata": {
        "id": "jZ5VpJdT86Or"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "|prediction_test.max(), prediction_test.min()"
      ],
      "metadata": {
        "id": "2OOJgLA886Rn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_test.shape"
      ],
      "metadata": {
        "id": "lHQEIaqf29US"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "id": "TPJeyeiq29XN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training image "
      ],
      "metadata": {
        "id": "vC-qzq5s3kVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_img(test_img)"
      ],
      "metadata": {
        "id": "2OPuGApXfgmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_img(test_lab)"
      ],
      "metadata": {
        "id": "eYPgHrsqfky6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_train = model.predict(fX_train)"
      ],
      "metadata": {
        "id": "SRXHx743flRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(prediction_train.reshape(dim),cmap='gray')"
      ],
      "metadata": {
        "id": "UfOyeA3pfrrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "On9-pDUsghHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Training Accuracy = \", metrics.accuracy_score(train_lab.reshape(dim), prediction_train.reshape(dim)))"
      ],
      "metadata": {
        "id": "xBlmEv99ghJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3lovB0fgt-5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New data"
      ],
      "metadata": {
        "id": "1rZorVuzutIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = np.hstack((gray1, gabor1, gabor2, blur1, blur2, sobele, canny))\n",
        "features.shape"
      ],
      "metadata": {
        "id": "MyyaujZTt-73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KFCVnmesvvzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a data frame with test data image - using a numpy array\n",
        "%%time\n",
        "a = []\n",
        "for img in train_images[:10]:\n",
        "  m = img.reshape(-1,1)\n",
        "\n",
        "  _,thresh2  = cv2.threshold(img, 80, 255, cv2.THRESH_BINARY_INV)\n",
        "  thresh2 = thresh2.reshape(-1,1)\n",
        "\n",
        "  adaptive_thresh=(cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,11, 11)/255).reshape(-1,1)\n",
        "  f = np.hstack((m, thresh2, adaptive_thresh))\n",
        "  a.append(f)\n"
      ],
      "metadata": {
        "id": "lbfkHiYmt-_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(a)"
      ],
      "metadata": {
        "id": "BE6bOUFxvpQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b = np.array(a)"
      ],
      "metadata": {
        "id": "xQG6oVm3vxcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b.shape"
      ],
      "metadata": {
        "id": "yw15lyKhv3Pe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import training classifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "## Instantiate model with n number of decision trees\n",
        "rf = RandomForestClassifier(n_estimators = 50, random_state = 42)"
      ],
      "metadata": {
        "id": "MDE6oXb2v3yW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, Y)"
      ],
      "metadata": {
        "id": "TuUAaOnwwGr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = load_img('/content/content/processed_labels/aachen_000000_000019.png')"
      ],
      "metadata": {
        "id": "bvmNQgVawGwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_img(a)"
      ],
      "metadata": {
        "id": "XaegmaCOKENP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(a)"
      ],
      "metadata": {
        "id": "ZjTT0ecGKHds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pnf0BBV5KPmZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}