{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "DATA_DIR = os.path.join(ROOT_DIR, 'data/processed')\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio as iio\n",
    "import json\n",
    "from skimage.draw import polygon\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "from typing import Union\n",
    "import helper as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for labels of interest\n",
    "# labels of interest\n",
    "keeplabels ={'sidewalk':8,\n",
    "            'rail track':10,\n",
    "            'wall':12,\n",
    "            'fence':13,\n",
    "            'guard rail':14,\n",
    "            'pole':17,\n",
    "            'polegroup':18,\n",
    "            'vegetation': 21,\n",
    "            'car':26,\n",
    "            'bicycle':33}\n",
    "            \n",
    "inv_keeplabels =  {\n",
    "    8: 'sidewalk',\n",
    "    10: 'rail track',\n",
    "    12: 'wall',\n",
    "    13: 'fence',\n",
    "    14: 'guard rail',\n",
    "    17: 'pole',\n",
    "    18:  'polegroup',\n",
    "    21: 'vegetation',\n",
    "    26: 'car',\n",
    "    33: 'bicycle'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_DIR = os.path.join(DATA_DIR, 'images')\n",
    "LBL_DIR = os.path.join(DATA_DIR, 'segmentations')\n",
    "\n",
    "# x_train, y_train = IMG_DIR + '/train', LBL_DIR+'/train'\n",
    "# x_test, y_test = IMG_DIR + '/test', LBL_DIR+'/test'\n",
    "# x_val , y_val =IMG_DIR + '/val', LBL_DIR+'/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import Union\n",
    "# def parse_json(filename: str, keep:Union[tuple,list,dict]=['sidewalk']):\n",
    "#     polygons = []\n",
    "#     labels = []\n",
    "#     with open(filename) as f:\n",
    "#         data = json.load(f)\n",
    "#         im_h, im_w = data['imgHeight'], data['imgWidth']\n",
    "#         objects = data[\"objects\"]\n",
    "#         for i in objects:\n",
    "#             if i['label'] in keep:\n",
    "#                 # if isinstance(keep, dict):\n",
    "#                 #     labels.append(keep[i['label']])\n",
    "#                 # else:\n",
    "#                 #     labels.append(i['label'])\n",
    "#                 poly_coords = i['polygon']\n",
    "#                 tmp = list(zip(*poly_coords))\n",
    "#             # NOTE: The following line assumes that the point coordinates are given as (x,y). \n",
    "#             #       Change the order of the indices if needed.\n",
    "#                 polygons.append((np.array(tmp[1])-1, np.array(tmp[0])-1))\n",
    "#     # return (im_h, im_w), labels, polygons\n",
    "#     return (im_h, im_w), polygons\n",
    "\n",
    "# # https://stackoverflow.com/questions/72168663/setting-a-list-of-x-y-cooordinates-into-an-array-so-polygons-are-drawn\n",
    "# def drawMask(imgsize: tuple, poly:tuple):\n",
    "#     img = np.zeros(imgsize)\n",
    "#     r = poly[0]\n",
    "#     c = poly[1]\n",
    "#     r_index, c_index = polygon(r, c)\n",
    "#     img[r_index,c_index] = 1\n",
    "#     return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test parse and mask\n",
    "\n",
    "# imdim, polygons = parse_json(os.path.join(DATA_DIR,'segmentations/aachen_000001_000019.json'))\n",
    "# m = drawMask(imdim, polygons[0])\n",
    "# plt.imshow(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = os.path.join(DATA_DIR, 'keep_img_ids.txt')\n",
    "with open(txt,'r') as f:\n",
    "    keep_ids = f.readlines()\n",
    "    keep_ids = [k[:-1] for k in keep_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get a list of file names from x\n",
    "# # find y json file \n",
    "# # find # of instances no need to generate masks yet\n",
    "# # img path | json path | class\n",
    "\n",
    "# def getIds(subset:list):\n",
    "#     cities = os.listdir(subset)\n",
    "#     ids = []\n",
    "#     for city in cities:\n",
    "#         for p in os.listdir(os.path.join(subset, city)): \n",
    "#             id = '_'.join(p.split('_')[:3])\n",
    "#             ids.append(id)   \n",
    "#     return ids\n",
    "\n",
    "\n",
    "def getInstances(filename:str, labelsToKeep:dict):\n",
    "    labels = []\n",
    "    keys = labelsToKeep.keys()\n",
    "    data = json.load(open(filename))\n",
    "    data = data[\"objects\"]\n",
    "    for d in data:\n",
    "        l = d['label']\n",
    "        if l in keys:\n",
    "            labels.append(labelsToKeep[l])\n",
    "    return labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ids = getIds(x_train)\n",
    "# test_ids = getIds(x_test)\n",
    "# val_ids = getIds(x_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLabels(ids, y_directory,keepLabels=keeplabels):\n",
    "    labels = []\n",
    "    for id in ids:\n",
    "        # city= id.split('_')[0]\n",
    "        # im_path = os.path.join(x,city,id+'_leftImg8bit.png')\n",
    "        lb_path = os.path.join(y_directory, id+'.json')\n",
    "        labels.append(getInstances(lb_path,keepLabels))\n",
    "    return labels\n",
    "\n",
    "def generateCSV(filepath:str, ids, labels):\n",
    "    df = pd.DataFrame(data=list(zip(ids, labels)),columns=['ID','LABEL'])\n",
    "    df.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = hp.getLabels(keep_ids,LBL_DIR)\n",
    "generateCSV('/Users/csea/Desktop/deep-learning-final-project-project-sidewalk/data/processed/labels.csv',keep_ids,val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.maskrcnn.mrcnn import visualize\n",
    "from models.maskrcnn.mrcnn import model\n",
    "# from models.maskrcnn.mrcnn import log\n",
    "from models.maskrcnn.mrcnn import config\n",
    "from models.maskrcnn.mrcnn.config import Config\n",
    "from models.maskrcnn.mrcnn import model as modellib, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomConfig(Config):\n",
    "  NAME = 'sidewalks'\n",
    "  GPU_COUNT = 1\n",
    "\n",
    "  # 12GB GPU can typical handle 2 images (1024 x 1024)\n",
    "  # ColabPro High Ram has roughly 27GB GPU\n",
    "  IMAGES_PER_GPU = 4\n",
    "\n",
    "  # Background + 1 sidewalk class \n",
    "  NUM_CLASSES = 2\n",
    "\n",
    "  # Number of training steps per epoch\n",
    "  STEPS_PER_EPOCH = 10\n",
    "\n",
    "  # Number of validation steps to runa tt eh end of \n",
    "  # every epoch,larger number improves better accuracy\n",
    "  # but slows down training\n",
    "  VALIDATION_STEPS = 50\n",
    "\n",
    "  # ROIs belwo this threshold are skipped\n",
    "  DETECTION_MIN_CONFIDENCE = .7   \n",
    "  DETECTION_NMS_THRESHOLD = 0.3\n",
    "  LEARNING_RATE =0.0005\n",
    "  BACKBONE = 'resnet101'\n",
    "  IMAGE_MAX_DIM = 512\n",
    "  IMAGE_MIN_DIM = 512\n",
    "  \n",
    "class CustomDataset(utils.Dataset):\n",
    " \n",
    "  def add_image(self, source, image_id, path, **kwargs):\n",
    "        image_info = {image_id:\n",
    "            {\"source\": source,\n",
    "            \"path\": path,\n",
    "            }\n",
    "        }\n",
    "        image_info[image_id].update(kwargs)\n",
    "        self.image_info.update(image_info)\n",
    "\n",
    "  def add_class(self, source, class_id, class_name):\n",
    "    assert \".\" not in source, \"Source name cannot contain a dot\"\n",
    "    # Does the class exist already?\n",
    "    if class_id in self.class_info.keys():\n",
    "       return\n",
    "\n",
    "    # Add the class\n",
    "    self.class_info.update({ class_id:\n",
    "       { \"source\": source,\n",
    "        \"name\": class_name,\n",
    "        'id': class_id}\n",
    "    })\n",
    "        \n",
    "  def load_dataset(self,dataset_dir,subset):\n",
    "    self.image_info = {}\n",
    "    self.class_info = {}\n",
    "    self.data_directory = dataset_dir\n",
    "\n",
    "    classes = pd.read_csv(os.path.join(dataset_dir,'classes.csv'))\n",
    "    IDs, LABELS = classes['CLASS_ID'].tolist(), classes['CLASS_NAME'].tolist()\n",
    "    classes = dict(zip(IDs, LABELS))\n",
    "\n",
    "    for i,c in enumerate(classes):\n",
    "      self.add_class(source='cityscape',\n",
    "                   class_id = c,\n",
    "                   class_name=classes[c])\n",
    "      \n",
    "    self.class_names = [d['name'] for d in self.class_info.values()]\n",
    "    \n",
    "    # iterating to get the image ids\n",
    "    if subset == 'validation':\n",
    "      subset = 'val'\n",
    "\n",
    "    data = pd.read_csv(os.path.join(dataset_dir, subset+'.csv'))  \n",
    "\n",
    "    for i in range(len(data)):\n",
    "      ID, LABELS = data.loc[i]\n",
    "      city = ID.split('_')[0]\n",
    "      img_path = os.path.join(dataset_dir, f'leftImg8bit/{subset}/{city}/{ID}_leftImg8bit.png')\n",
    "      classes = [int(i) if i!='' else 0 for i in LABELS.strip('[]').split(',')]\n",
    "      self.add_image(source='cityscape',\n",
    "                     image_id = ID,\n",
    "                     path = img_path,\n",
    "                     classes = classes)\n",
    "      \n",
    "  def load_mask(self,id):\n",
    "    img_info = self.image_info[id]\n",
    "    path = img_info['path']\n",
    "    subset = path.split('/')[-3]\n",
    "    mask_dir = os.path.join(self.data_directory, f'gtFine/{subset}')\n",
    "    \n",
    "    city = id.split('_')[0]\n",
    "    mask_path = os.path.join(mask_dir, city,f'{id}_gtFine_polygons.json')\n",
    "    # mask_path = os.path.join(mask_dir, city,f'{id}_gtFine_labelIds.png')\n",
    "    def parse_json(filename: str, keep=self.class_names) :\n",
    "        polygons = []\n",
    "        with open(filename) as f:\n",
    "            data = json.load(f)\n",
    "            im_h, im_w = data['imgHeight'], data['imgWidth']\n",
    "            objects = data[\"objects\"]\n",
    "            for i in objects:\n",
    "                if i['label'] in keep:\n",
    "                    print(i['label'])\n",
    "                    poly_coords = i['polygon']\n",
    "                    tmp = list(zip(*poly_coords))\n",
    "                    polygons.append((np.array(tmp[1])-1, np.array(tmp[0])-1))\n",
    "        # return (im_h, im_w), labels, polygons\n",
    "        return (im_h, im_w), polygons\n",
    "\n",
    "    # https://stackoverflow.com/questions/72168663/setting-a-list-of-x-y-cooordinates-into-an-array-so-polygons-are-drawn\n",
    "    def drawMask(imgsize: tuple, poly:tuple):\n",
    "        img = np.zeros(imgsize)\n",
    "        row, col = polygon(poly[0], poly[1])\n",
    "        img[row,col] = 1\n",
    "        return img\n",
    "    \n",
    "    masks = []\n",
    "    \n",
    "    imsize, polygons = parse_json(mask_path)\n",
    "    for p in polygons:\n",
    "       mask = drawMask(imsize, p)\n",
    "       masks.append(mask)\n",
    "      \n",
    "    masks = np.stack(masks, axis=-1)\n",
    "    return masks, img_info['classes']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m d \u001b[39m=\u001b[39m CustomDataset()\n\u001b[1;32m      2\u001b[0m d\u001b[39m.\u001b[39mload_dataset(DATA_DIR,\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m d\u001b[39m.\u001b[39;49mprepare()\n",
      "File \u001b[0;32m~/Desktop/deep-learning-final-project-project-sidewalk/models/maskrcnn/mrcnn/utils.py:308\u001b[0m, in \u001b[0;36mDataset.prepare\u001b[0;34m(self, class_map)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_classes \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_info)\n\u001b[1;32m    307\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_ids \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_classes)\n\u001b[0;32m--> 308\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_names \u001b[39m=\u001b[39m [clean_name(c[\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_info]\n\u001b[1;32m    309\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_images \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage_info)\n\u001b[1;32m    310\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_image_ids \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_images)\n",
      "File \u001b[0;32m~/Desktop/deep-learning-final-project-project-sidewalk/models/maskrcnn/mrcnn/utils.py:308\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_classes \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_info)\n\u001b[1;32m    307\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_ids \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_classes)\n\u001b[0;32m--> 308\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_names \u001b[39m=\u001b[39m [clean_name(c[\u001b[39m\"\u001b[39;49m\u001b[39mname\u001b[39;49m\u001b[39m\"\u001b[39;49m]) \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_info]\n\u001b[1;32m    309\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_images \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage_info)\n\u001b[1;32m    310\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_image_ids \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_images)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "d = CustomDataset()\n",
    "d.load_dataset(DATA_DIR,'train')\n",
    "d.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m a,b \u001b[39m=\u001b[39m d\u001b[39m.\u001b[39mload_mask(\u001b[39m'\u001b[39m\u001b[39maachen_000000_000019\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m c \u001b[39m=\u001b[39m d\u001b[39m.\u001b[39mload_image(\u001b[39m'\u001b[39m\u001b[39maachen_000000_000019\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m visualize\u001b[39m.\u001b[39mdisplay_top_masks(c,a,b,d\u001b[39m.\u001b[39mclass_info)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'd' is not defined"
     ]
    }
   ],
   "source": [
    "a,b = d.load_mask('aachen_000000_000019')\n",
    "c = d.load_image('aachen_000000_000019')\n",
    "visualize.display_top_masks(c,a,b,d.class_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_name(name):\n",
    "            \"\"\"Returns a shorter version of object names for cleaner display.\"\"\"\n",
    "            return \",\".join(name.split(\",\")[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{8: {'source': 'cityscape', 'name': 'sidewalk', 'id': 8}}"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.class_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sidewalk\n"
     ]
    }
   ],
   "source": [
    "for i in d.class_info:\n",
    "    print(d.class_info[i]['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sidewalk']"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[clean_name(d.class_info[c]['name']) for c in d.class_info]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.num_classes = len(d.class_info)\n",
    "d.class_ids = np.arange(d.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = d.image_info\n",
    "image_ids = np.arange(len(d.image_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[258], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m {\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(d\u001b[39m.\u001b[39mimage_info[info][\u001b[39m'\u001b[39m\u001b[39msource\u001b[39m\u001b[39m'\u001b[39m], d\u001b[39m.\u001b[39mimage_info[info][\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m]): \u001b[39mid\u001b[39m\n\u001b[1;32m      2\u001b[0m                                       \u001b[39mfor\u001b[39;00m info, \u001b[39mid\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(d\u001b[39m.\u001b[39mimage_info, image_ids)}\n",
      "Cell \u001b[0;32mIn[258], line 1\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m {\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(d\u001b[39m.\u001b[39mimage_info[info][\u001b[39m'\u001b[39m\u001b[39msource\u001b[39m\u001b[39m'\u001b[39m], d\u001b[39m.\u001b[39;49mimage_info[info][\u001b[39m'\u001b[39;49m\u001b[39mid\u001b[39;49m\u001b[39m'\u001b[39;49m]): \u001b[39mid\u001b[39m\n\u001b[1;32m      2\u001b[0m                                       \u001b[39mfor\u001b[39;00m info, \u001b[39mid\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(d\u001b[39m.\u001b[39mimage_info, image_ids)}\n",
      "\u001b[0;31mKeyError\u001b[0m: 'id'"
     ]
    }
   ],
   "source": [
    "{\"{}.{}\".format(d.image_info[info]['source'], info): id\n",
    "                                      for info, id in zip(d.image_info, image_ids)}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes = utils.extract_bboxes(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     4\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 4\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  512\n",
      "IMAGE_META_SIZE                14\n",
      "IMAGE_MIN_DIM                  512\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [512 512   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.0005\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           sidewalks\n",
      "NUM_CLASSES                    2\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                10\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[264], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m dataset \u001b[39m=\u001b[39m CustomDataset()\n\u001b[1;32m      5\u001b[0m dataset\u001b[39m.\u001b[39mload_dataset(DATA_DIR,\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m dataset\u001b[39m.\u001b[39;49mprepare()\n\u001b[1;32m      8\u001b[0m val_set \u001b[39m=\u001b[39m CustomDataset()\n\u001b[1;32m      9\u001b[0m val_set\u001b[39m.\u001b[39mload_dataset(DATA_DIR,\u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/deep-learning-final-project-project-sidewalk/models/maskrcnn/mrcnn/utils.py:308\u001b[0m, in \u001b[0;36mDataset.prepare\u001b[0;34m(self, class_map)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_classes \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_info)\n\u001b[1;32m    307\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_ids \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_classes)\n\u001b[0;32m--> 308\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_names \u001b[39m=\u001b[39m [clean_name(c[\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_info]\n\u001b[1;32m    309\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_images \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage_info)\n\u001b[1;32m    310\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_image_ids \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_images)\n",
      "File \u001b[0;32m~/Desktop/deep-learning-final-project-project-sidewalk/models/maskrcnn/mrcnn/utils.py:308\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_classes \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_info)\n\u001b[1;32m    307\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_ids \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_classes)\n\u001b[0;32m--> 308\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_names \u001b[39m=\u001b[39m [clean_name(c[\u001b[39m\"\u001b[39;49m\u001b[39mname\u001b[39;49m\u001b[39m\"\u001b[39;49m]) \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_info]\n\u001b[1;32m    309\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_images \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage_info)\n\u001b[1;32m    310\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_image_ids \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_images)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "config = CustomConfig()\n",
    "config.display()\n",
    "\n",
    "dataset = CustomDataset()\n",
    "dataset.load_dataset(DATA_DIR,'train')\n",
    "dataset.prepare()\n",
    "\n",
    "val_set = CustomDataset()\n",
    "val_set.load_dataset(DATA_DIR,'val')\n",
    "# val_set.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not build a TypeSpec for <KerasTensor: shape=(None, None, 4) dtype=float32 (created by layer 'tf.math.truediv_1')> with type KerasTensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[225], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m temp_log \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(ROOT_DIR,\u001b[39m'\u001b[39m\u001b[39mdata/external\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m model \u001b[39m=\u001b[39m modellib\u001b[39m.\u001b[39;49mMaskRCNN(mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtraining\u001b[39;49m\u001b[39m'\u001b[39;49m,config\u001b[39m=\u001b[39;49mconfig, model_dir\u001b[39m=\u001b[39;49mtemp_log)\n\u001b[1;32m      3\u001b[0m model_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(ROOT_DIR,\u001b[39m'\u001b[39m\u001b[39mmodels/maskrcnn/mask_rcnn_coco.h5\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/deep-learning-final-project-project-sidewalk/models/maskrcnn/mrcnn/model.py:1837\u001b[0m, in \u001b[0;36mMaskRCNN.__init__\u001b[0;34m(self, mode, config, model_dir)\u001b[0m\n\u001b[1;32m   1835\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_dir \u001b[39m=\u001b[39m model_dir\n\u001b[1;32m   1836\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_log_dir()\n\u001b[0;32m-> 1837\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkeras_model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuild(mode\u001b[39m=\u001b[39;49mmode, config\u001b[39m=\u001b[39;49mconfig)\n",
      "File \u001b[0;32m~/Desktop/deep-learning-final-project-project-sidewalk/models/maskrcnn/mrcnn/model.py:1875\u001b[0m, in \u001b[0;36mMaskRCNN.build\u001b[0;34m(self, mode, config)\u001b[0m\n\u001b[1;32m   1872\u001b[0m input_gt_boxes \u001b[39m=\u001b[39m KL\u001b[39m.\u001b[39mInput(\n\u001b[1;32m   1873\u001b[0m     shape\u001b[39m=\u001b[39m[\u001b[39mNone\u001b[39;00m, \u001b[39m4\u001b[39m], name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minput_gt_boxes\u001b[39m\u001b[39m\"\u001b[39m, dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m   1874\u001b[0m \u001b[39m# Normalize coordinates\u001b[39;00m\n\u001b[0;32m-> 1875\u001b[0m gt_boxes \u001b[39m=\u001b[39m KL\u001b[39m.\u001b[39;49mLambda(\u001b[39mlambda\u001b[39;49;00m x: norm_boxes_graph(\n\u001b[1;32m   1876\u001b[0m     x, K\u001b[39m.\u001b[39;49mshape(input_image)[\u001b[39m1\u001b[39;49m:\u001b[39m3\u001b[39;49m]))(input_gt_boxes)\n\u001b[1;32m   1877\u001b[0m \u001b[39m# 3. GT Masks (zero padded)\u001b[39;00m\n\u001b[1;32m   1878\u001b[0m \u001b[39m# [batch, height, width, MAX_GT_INSTANCES]\u001b[39;00m\n\u001b[1;32m   1879\u001b[0m \u001b[39mif\u001b[39;00m config\u001b[39m.\u001b[39mUSE_MINI_MASK:\n",
      "File \u001b[0;32m~/miniconda/envs/tf_m1/lib/python3.8/site-packages/keras/engine/base_layer.py:976\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[39m# Functional Model construction mode is invoked when `Layer`s are called on\u001b[39;00m\n\u001b[1;32m    971\u001b[0m \u001b[39m# symbolic `KerasTensor`s, i.e.:\u001b[39;00m\n\u001b[1;32m    972\u001b[0m \u001b[39m# >> inputs = tf.keras.Input(10)\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[39m# >> outputs = MyLayer()(inputs)  # Functional construction mode.\u001b[39;00m\n\u001b[1;32m    974\u001b[0m \u001b[39m# >> model = tf.keras.Model(inputs, outputs)\u001b[39;00m\n\u001b[1;32m    975\u001b[0m \u001b[39mif\u001b[39;00m _in_functional_construction_mode(\u001b[39mself\u001b[39m, inputs, args, kwargs, input_list):\n\u001b[0;32m--> 976\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_functional_construction_call(inputs, args, kwargs,\n\u001b[1;32m    977\u001b[0m                                             input_list)\n\u001b[1;32m    979\u001b[0m \u001b[39m# Maintains info about the `Layer.call` stack.\u001b[39;00m\n\u001b[1;32m    980\u001b[0m call_context \u001b[39m=\u001b[39m base_layer_utils\u001b[39m.\u001b[39mcall_context()\n",
      "File \u001b[0;32m~/miniconda/envs/tf_m1/lib/python3.8/site-packages/keras/engine/base_layer.py:1114\u001b[0m, in \u001b[0;36mLayer._functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1109\u001b[0m     training_arg_passed_by_framework \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1111\u001b[0m \u001b[39mwith\u001b[39;00m call_context\u001b[39m.\u001b[39menter(\n\u001b[1;32m   1112\u001b[0m     layer\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, inputs\u001b[39m=\u001b[39minputs, build_graph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39mtraining_value):\n\u001b[1;32m   1113\u001b[0m   \u001b[39m# Check input assumptions set after layer building, e.g. input shape.\u001b[39;00m\n\u001b[0;32m-> 1114\u001b[0m   outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_keras_tensor_symbolic_call(\n\u001b[1;32m   1115\u001b[0m       inputs, input_masks, args, kwargs)\n\u001b[1;32m   1117\u001b[0m   \u001b[39mif\u001b[39;00m outputs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1118\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mA layer\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39ms `call` method should return a \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1119\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39mTensor or a list of Tensors, not None \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1120\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39m(layer: \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m).\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda/envs/tf_m1/lib/python3.8/site-packages/keras/engine/base_layer.py:848\u001b[0m, in \u001b[0;36mLayer._keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    846\u001b[0m   \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mmap_structure(keras_tensor\u001b[39m.\u001b[39mKerasTensor, output_signature)\n\u001b[1;32m    847\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 848\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_infer_output_signature(inputs, args, kwargs, input_masks)\n",
      "File \u001b[0;32m~/miniconda/envs/tf_m1/lib/python3.8/site-packages/keras/engine/base_layer.py:893\u001b[0m, in \u001b[0;36mLayer._infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    890\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n\u001b[1;32m    891\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_mask_metadata(inputs, outputs, input_masks,\n\u001b[1;32m    892\u001b[0m                           build_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 893\u001b[0m   outputs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mmap_structure(\n\u001b[1;32m    894\u001b[0m       keras_tensor\u001b[39m.\u001b[39;49mkeras_tensor_from_tensor, outputs)\n\u001b[1;32m    896\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m_set_inputs\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minputs:\n\u001b[1;32m    897\u001b[0m   \u001b[39m# TODO(kaftan): figure out if we need to do this at all\u001b[39;00m\n\u001b[1;32m    898\u001b[0m   \u001b[39m# Subclassed network: explicitly set metadata normally set by\u001b[39;00m\n\u001b[1;32m    899\u001b[0m   \u001b[39m# a call to self._set_inputs().\u001b[39;00m\n\u001b[1;32m    900\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_inputs(inputs, outputs)\n",
      "File \u001b[0;32m~/miniconda/envs/tf_m1/lib/python3.8/site-packages/tensorflow/python/util/nest.py:869\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    866\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    868\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    870\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/miniconda/envs/tf_m1/lib/python3.8/site-packages/tensorflow/python/util/nest.py:869\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    865\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    866\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    868\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    870\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/miniconda/envs/tf_m1/lib/python3.8/site-packages/keras/engine/keras_tensor.py:584\u001b[0m, in \u001b[0;36mkeras_tensor_from_tensor\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m    581\u001b[0m     keras_tensor_cls \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\n\u001b[1;32m    582\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 584\u001b[0m out \u001b[39m=\u001b[39m keras_tensor_cls\u001b[39m.\u001b[39;49mfrom_tensor(tensor)\n\u001b[1;32m    586\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(tensor, \u001b[39m'\u001b[39m\u001b[39m_keras_mask\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    587\u001b[0m   out\u001b[39m.\u001b[39m_keras_mask \u001b[39m=\u001b[39m keras_tensor_from_tensor(tensor\u001b[39m.\u001b[39m_keras_mask)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/tf_m1/lib/python3.8/site-packages/keras/engine/keras_tensor.py:172\u001b[0m, in \u001b[0;36mKerasTensor.from_tensor\u001b[0;34m(cls, tensor)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m   \u001b[39m# Fallback to the generic arbitrary-typespec KerasTensor\u001b[39;00m\n\u001b[1;32m    171\u001b[0m   name \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(tensor, \u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m--> 172\u001b[0m   type_spec \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mtype_spec_from_value(tensor)\n\u001b[1;32m    173\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(type_spec, name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[0;32m~/miniconda/envs/tf_m1/lib/python3.8/site-packages/tensorflow/python/framework/type_spec.py:609\u001b[0m, in \u001b[0;36mtype_spec_from_value\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    606\u001b[0m   logging\u001b[39m.\u001b[39mvlog(\n\u001b[1;32m    607\u001b[0m       \u001b[39m3\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mFailed to convert \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m to tensor: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mtype\u001b[39m(value)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, e))\n\u001b[0;32m--> 609\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCould not build a TypeSpec for \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m with type \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m    610\u001b[0m                 (value, \u001b[39mtype\u001b[39m(value)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m))\n",
      "\u001b[0;31mTypeError\u001b[0m: Could not build a TypeSpec for <KerasTensor: shape=(None, None, 4) dtype=float32 (created by layer 'tf.math.truediv_1')> with type KerasTensor"
     ]
    }
   ],
   "source": [
    "temp_log = os.path.join(ROOT_DIR,'data/external')\n",
    "model = modellib.MaskRCNN(mode='training',config=config, model_dir=temp_log)\n",
    "model_path = os.path.join(ROOT_DIR,'models/maskrcnn/mask_rcnn_coco.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv(os.path.join(DATA_DIR,'train.csv'),index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hamburg_000000_079376.png.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aachen_000056_000019.png.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bochum_000000_031477.png.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>erfurt_000061_000019.png.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aachen_000080_000019.png.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2616</th>\n",
       "      <td>weimar_000077_000019.png.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2617</th>\n",
       "      <td>frankfurt_000001_025713.png.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2618</th>\n",
       "      <td>strasbourg_000001_061384.png.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2619</th>\n",
       "      <td>frankfurt_000001_019854.png.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2620</th>\n",
       "      <td>darmstadt_000040_000019.png.npy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2621 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     0\n",
       "0        hamburg_000000_079376.png.npy\n",
       "1         aachen_000056_000019.png.npy\n",
       "2         bochum_000000_031477.png.npy\n",
       "3         erfurt_000061_000019.png.npy\n",
       "4         aachen_000080_000019.png.npy\n",
       "...                                ...\n",
       "2616      weimar_000077_000019.png.npy\n",
       "2617   frankfurt_000001_025713.png.npy\n",
       "2618  strasbourg_000001_061384.png.npy\n",
       "2619   frankfurt_000001_019854.png.npy\n",
       "2620   darmstadt_000040_000019.png.npy\n",
       "\n",
       "[2621 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
